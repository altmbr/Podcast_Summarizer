# [6 Months Later, How Our AI SDRs Actually Work as AI Runs GTM with SaaStr's CEO and Chief AI Officer](https://www.youtube.com/watch?v=6YrzIuvhi5k)

**Podcast:** SaaStr
**Date:** 2025-11-23
**Participants:** Jason Lemkin, Amelia Ibarra
**Region:** Western
**Video ID:** 6YrzIuvhi5k
**Video URL:** https://www.youtube.com/watch?v=6YrzIuvhi5k
**Transcript:** [View Transcript](./transcript.md)

---

# Six Months of AI Running GTM: SaaStr's Deep Dive

## 1. Key Themes

### AI Agents Scale Best Practices, Not Magic Solutions

The fundamental insight is that AI agents amplify what already works rather than fixing broken processes. "What your agents can do, and it is so powerful, is they can take your best practices and scale them out almost infinitely. Figure out what works, figure out what campaigns work, what messaging, whatever works is already working. You have to have something that's working. An agent can't today figure out, make something that isn't working at work." [[00:08:18]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=8m8s) This represents a critical shift from expecting AI to solve problems to using it as a force multiplier for proven strategies.

SaaStr demonstrated this by replacing two human SDRs with AI agents, achieving "roughly similar" open and response rates but with "10 times the scale." [[00:57:25]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=57m15s) The key wasn't that AI performed better on individual interactions, but that it provided infinite capacity to execute proven approaches consistently.

### Hands-On Training is Non-Negotiable for AI Success

The most successful AI implementations require daily human oversight and continuous training, not set-and-forget deployment. "Our agents will ebb and flow oddly, depending on how much time the humans put in. It's the war time I put in with our agent. Wow, shocker, the better the output is." [[00:12:10]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=12m0s) This challenges the narrative of immediate ROI and headcount reduction.

Amelia specifically noted that her AI agents' performance directly correlates with her availability: "Sometimes that ends in flows, right? Like we get busy, we have saster London coming up. So I can't always spend the amount of time I would like to with the agents. Right? And so that obviously does translate to the results." [[00:12:16]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=12m6s)

### The A-Player Amplification Strategy

Rather than hiring dedicated AI specialists, the most effective approach is empowering existing top performers with AI tools. "Take your A player, take somebody that is the best person on your sales off steam, your rev off steam, your best marketer, your best SDR, your best AE. Sit down with that figure out what tools you want to use together." [[00:13:42]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=13m32s) 

This approach has proven so successful that organizations are naturally evolving roles: "Everyone I talk to you that says they go this route of using the best A tier players and injecting AI and figuring it out with them have now they have now changed their job roles. Like in the way that my job role has changed into an out chief AI officer." [[00:14:17]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=14m7s)

## 2. Contrarian Perspectives

### Don't Replace Headcount, Replace Budget Through Attrition

"You don't fire anyone good to replace them with AI if you haven't learned anything. If someone's failed, if they can't close anything or if your AI SGR is instead a single appointment, I mean your human SGR maybe just replace that page with your SGR can't do anything, you know, you can't do worse than zero." [[00:14:14]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=14m4s) This pushes against the narrative of mass AI-driven layoffs.

Instead, SaaStr replaced "the budget from two permanents to support our agents. We didn't fire anybody." [[01:03:10]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h3m0s) The strategic approach involves reallocating budgets from natural attrition rather than forced reductions, maintaining team morale while gaining AI capabilities.

### More Specialized Tools Beat All-in-One Platforms

Counter to the consolidation trend, Amelia advocates for specialized best-of-breed tools despite integration complexity. "My flash art theory is I like to go deep now with specialized tools where I can just keep adding use cases and add agents within certain tools. I don't use it all in one tool, but I feel like the results are worth it." [[00:42:10]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=42m0s)

She acknowledges the friction: "Sometimes I have to put stuff in artisan and qualified separately. Is it a little annoying? Of course, it's a little bit annoying. It's time consuming. Am I going to do it because the response rates I think will be better in the long run for inbound versus outbound? Yeah." [[00:42:26]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=42m16s)

### Skip the Beta Bake-Off Madness

Against conventional wisdom of testing multiple vendors, there's a warning about over-testing: When discussing a CMO running "10 betas," the advice was stark: "Maybe don't do that... I think in trying to save money, you're actually spending a lot more time than you really would just appoint these that getting the outputs of AI by doing these 10 different betas." [[00:57:47]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=57m37s)

The recommendation: "I wouldn't do 10 because you won't put the energy into training them. The bake off will fail with 10. I would do two, just like in the old days." [[00:58:51]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=58m41s) This challenges the risk-mitigation instinct and emphasizes that execution beats evaluation.

### Demand Technical Expertise Over Sales Reps

"Don't get bamboozled by a sales rep that doesn't know the product or isn't technical. Ask to talk to an FDE or a solution architect or an onboarding specialist. Don't waste your time with an idiot sales rep." [[01:09:47]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h9m37s) Jason recounted passing on a vendor entirely because "we were routed to a very mediocre sales slash onboarding person who really didn't want our business." [[01:09:23]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h9m13s)

This perspective asserts that in the AI era, traditional sales processes are inadequate: "Some of the very best AI companies across the globe... have really mediocre sales teams that do not understand the products they're selling. They just don't understand how AI coding tools work." [[01:10:04]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h9m54s)

### Data Governance Paralysis is a Trap

"Don't get to hung up on this data governance thing. A lot of folks, I talked to now, especially at bigger org. Give very concerned. Okay, if I add so many agents, I'm going to need governance as a layer. I'm going to need to clean up all my data and cleaning up all my data or getting all the process we've got to take two years before I can even think about implementing. I think too much data, too much data." [[00:15:56]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=15m46s)

This directly contradicts enterprise best practices that prioritize data quality before AI implementation, arguing that speed of deployment trumps perfection.

## 3. Companies Identified

### Artisan

**Description**: AI-powered outbound SDR platform specializing in automated, personalized email sequences at scale.

**Why Mentioned**: Primary outbound agent for SaaStr, sending 3,000 emails per month (versus 75-285 from human SDRs previously). Achieved 7% overall response rate and 4% positive response rate - double typical industry averages. Responsible for 10% of SaaStr AI London ticket revenue through one agent alone. [[00:17:47]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=17m37s)

**Quote**: "Our Albound emails per rep across the board... On the average band six months ago, with anywhere between 75, you know, let's say at the low end to 285 at the high and depending on the person, some people are faster than others. Now our AI is blowing that scale out of the water. It does 3000 on its own per month in one, this is just one platform." [[00:56:50]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=56m40s)

### Qualified (Replic)

**Description**: Inbound AI agent platform (previously mentioned as "Replic") for website visitor engagement, conversation, and meeting booking with deep contextual intelligence.

**Why Mentioned**: Deployed in August, handled 700,000 sessions and 1,000 conversations in 3.5 months. Generated $1M in revenue and was responsible for 70% of October closed-won deals. Provides discovery-level context before human sales engagement. [[00:31:05]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=30m55s)

**Quote**: "The meeting is instant. But it's having a conversation with this person. So that when I give it to the sales team, it literally means they have to go through, like, what do they say to the agent? Do they say anything? Interesting. The agent can also show you other people who open on the website... We don't really have to do discovery anymore because the AI has already done it." [[00:35:32]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=35m22s)

### Salesforce (Agentforce)

**Description**: Salesforce's native AI agent platform, building on existing CRM data for personalized outbound follow-up and engagement.

**Why Mentioned**: Deployed most recently (post-Dreamforce, about one month before recording). Used to rescue 1,000 ghosted leads that sales team never followed up with. Achieving 72% open rate and higher response rates than other platforms despite being newest deployment. [[00:47:51]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=47m41s)

**Quote**: "The magic, I would say, the agent force is that it knows everything your sales force knows, which sometimes they say that to people and they're surprised. I'm like, what? That's the beauty of it. Like, it has all your sales force data." [[00:46:12]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=46m2s)

### HappyFox

**Description**: Omnichannel AI-first support stack with pre-built AI agents (Autopilot) for support automation.

**Why Mentioned**: Sponsor mentioned for their Autopilot agents that deploy in 60 seconds and run for as low as 2 cents per successful action. Represents the support AI category that SaaStr will cover in part two. [[00:01:26]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1m16s)

**Quote**: "These pre-built AI agents deploying about 60 seconds and run for as low as two cents per successful action. All of it sits inside the Happy Fox Omnichannel AI First Support Stack. Chatbot, Co-Pilot, and Autofilet working as one." [[00:01:38]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1m28s)

## 4. People Identified

### Jasper Soccio

**Description**: Team member at Artisan involved in customer success and deployment.

**Why Mentioned**: Cited as the contact who emphasized the importance of the two-to-three week warm-up period for deliverability optimization with Artisan's platform. This warm-up ensures emails reach inbox rather than promotions folder. [[00:23:35]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=23m25s)

**Quote**: "There is a, which I fully believe it. I've talked to Jasper, Succio, part of the, there is a two to three week warm-up period with artists and so that they can get your deliverability as close to perfect as possible." [[00:23:33]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=23m23s)

### Mark Benioff

**Description**: CEO of Salesforce

**Why Mentioned**: Referenced for his vision on AI deployment philosophy during a SaaStr interview approximately 1.5 months prior. His perspective shapes how SaaStr thinks about vendor selection and deployment speed.

**Quote**: "We had Mark Benioff on about a month and a half ago and we talked about what's the number one thing you wanted it sells for us... He said he wished obviously it's not practical at 44 billion in ARR. He wished every company could deploy their agent and have value before they sign their contract." [[01:11:19]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h11m9s)

### Rory Hitski (Harry and Rory)

**Description**: Co-host of Jason Lemkin's podcast, creator of State of GTM AI report

**Why Mentioned**: Produced the State of GTM AI report that Amelia used to frame SaaStr's positioning relative to broader market adoption. The report shows most companies are at baseline adoption levels while SaaStr has moved to sophisticated 2.0 deployments. [[00:09:38]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=9m28s)

**Quote**: "This is from Jason's co-host Rory Hitski. This is their state of GTMAI. It's actually fairly short but concise, so I like it, you can just go to those that you can download it." [[00:09:40]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=9m30s)

## 5. Operating Insights

### The 800-1,000 Contact Sweet Spot

Through experimentation, Amelia discovered optimal campaign sizing: "I've seen this I don't know if this is like a again a platform thing or a methane but I've played different sizes in order to have really different campaigns and different audiences but I see 800 to a thousand as the sweet spot." [[01:21:17]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h21m7s) This tactical insight suggests that campaign performance degrades outside this band, likely due to how AI agents handle context and personalization at scale.

### Multi-Agent Training Architecture

Rather than one general agent, create specialized sub-agents for different audiences: "I have an agent basically for lab sponsors. I got what for current sponsors. I've got one for people who previously attended SASTRA. Now I now I have one for people who are opening our emails, but maybe not taking any actions with us. And then I have one purely for cold outbound." [[00:18:49]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=18m39s) Each agent receives different training, messaging, and collateral aligned to its specific goal, dramatically improving relevance.

### Universal AI Training Concepts Transfer

Once you master one AI platform, subsequent platforms become dramatically easier: "Once you kind of learn how to do it in one, it is easier to do the others... You just start to learn how to talk to AI and talk to the agents and the models with your data in a way that again, no one can do you." [[00:53:10]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=53m0s) This suggests the learning curve investment in the first platform pays exponential dividends across the entire stack.

### CSV Upload for Control and Consistency

Despite available automation, manual CSV uploads provide superior control: "The way I do it that's the reason to do it now... I just export or again I don't want the contacts to be a matter to agent I export the contact I upload them that's the way I do it." [[01:20:42]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=1h20m32s) This seemingly inefficient process ensures precise audience selection and prevents the 800-1,000 contact band from being exceeded.

### Spot-Check vs. Full Review Evolution

Agent trust should evolve over time based on performance: "At the start, we had a review. I was nervous. I wanted to review all the emails myself. But now I just spot check, right? I spot check it." [[00:24:23]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=24m13s) However, this varies by use case—some agents (like Artisan for complex multi-product inquiries) still require full review while others (like Qualified for straightforward ticket sales) can operate with just spot-checking.

## 6. Overlooked Insights

### The AI-Powered Discount Code Follow-Up Loop

Buried in the Qualified discussion was a remarkably sophisticated automated sales tactic: "Because the agent was on our website, it will know if you come back. And if you don't have for a couple days, it will actually even like, Hey, Jason, I give you the code. We have this nice conversation as Amelia AI, you didn't use it. And then it reached out to the code, Hey, are you still interested in people then use that code?" [[00:39:51]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=39m41s)

This represents a complete closed-loop nurture system for low-ASP products that operates autonomously: awareness (website visit) → engagement (chat) → offer (discount code) → tracking (usage monitoring) → re-engagement (reminder) → conversion. The agent maintains context across multiple sessions and proactively re-engages based on behavioral signals. This level of persistent, personalized follow-up would be prohibitively time-consuming for humans but drives material revenue (20% of London ticket revenue across two agents). It suggests a new category of "AI-native sales motions" that simply weren't possible before.

### The Human Authenticity Gap in Multi-CC Coordination

A subtle but critical limitation emerged around high-value prospect outreach: "The biggest issue I have right now in the AI is not that it's not working or that we have high value contacts that it can't draft an email to pretty good and apparently customize. It's that don't want to send it just to see you. If I'm an email, the CEO of Databricks, like I want to copy his press team, his chief of staff, his CM, if it's for something speaking, probably the CMO too for visibility." [[00:29:28]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=29m18s)

This reveals that current AI agents fundamentally operate as one-to-one communicators, lacking the political and organizational intelligence for complex enterprise selling. The inability to intelligently identify and include relevant stakeholders beyond the primary contact represents a significant constraint on AI's ability to fully automate high-value sales motions. Amelia noted: "There's no way to really do that in the, like there's no good way right now in any AI to find those additional contacts. And also include them in the sequence." [[00:29:45]](https://www.youtube.com/watch?v=6YrzIuvhi5k&t=29m35s) This gap—identifying the constellation of stakeholders around a buying decision—remains firmly in the human domain and likely explains why the highest-value deals still require substantial human involvement despite AI's efficiency gains elsewhere.