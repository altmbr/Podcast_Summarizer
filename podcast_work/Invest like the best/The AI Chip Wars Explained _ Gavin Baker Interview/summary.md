# [The AI Chip Wars Explained | Gavin Baker Interview](https://www.youtube.com/watch?v=cmUo4841KQw)

**Podcast:** Invest like the best
**Date:** 2025-12-09
**Participants:** Unknown Guest, Patrick O'Shaughnessy, Gavin Baker
**Region:** Western
**Video ID:** cmUo4841KQw
**Video URL:** https://www.youtube.com/watch?v=cmUo4841KQw
**Transcript:** [View Transcript](./transcript.md)

---

# Podcast Summary: Gavin Baker on AI Infrastructure, Frontier Models, and the Great Tech Battle

## 1. Key Themes

### The Hidden Gift of Reasoning Models: Bridging the Hardware Gap and Enabling Data Flywheels

Reasoning models emerged as an unexpected savior for AI progress during a critical 18-month hardware transition period. Without reasoning, AI advancement would have stalled completely between mid-2024 and the arrival of Gemini 3, creating what could have been a devastating market environment. More importantly, reasoning fundamentally transformed the competitive dynamics of frontier labs by enabling a powerful flywheel previously absent in AI: users generate data through verified rewards that can be fed back into models to make them better—the same increasing returns to scale that powered dominant internet companies for over a decade.

"Had reasoning not come along, there would have been no AI progress from mid-2024 through essentially Gemini 3. There would have been none. Everything would have stalled. And you could imagine what that would have meant to the markets. Like for sure, we would have lived in a very different environment. So reasoning kind of bridged this like 18 month gap, reasoning kind of saved AI." [[00:08:42]](https://www.youtube.com/watch?v=cmUo4841KQw&t=8m32s)

"With reasoning, it's early, but that flywheel is started to spin. And that is really profound for these frontier labs. So one, reasoning fundamentally changed the industry dynamics of frontier labs." [[00:42:02]](https://www.youtube.com/watch?v=cmUo4841KQw&t=41m52s)

### The Low-Cost Producer Finally Matters: Google's Temporary Advantage and the Coming Power Shift

For the first time in tech investing history, being the low-cost producer actually matters. Google has been leveraging their TPU advantage to operate as the lowest-cost token producer, pursuing a rational but aggressive strategy of "sucking the economic oxygen out of the AI ecosystem" by running AI potentially at negative margins. However, this advantage is temporary—once GB300 and MI450 chips are deployed at scale, companies using these will become the new low-cost producers, fundamentally changing the strategic calculus and potentially forcing Google to abandon their margin-destructive approach.

"And this is really important because AI's the first time in my career as a tech investor that being the low cost producers ever mattered. Apple is not worth trillions because they're low cost producer of phones. Microsoft is not worth trillions because they're low cost producer of software. And video's not worth trillions because they're the low cost producer of AI accelerators. It's never mattered." [[00:11:26]](https://www.youtube.com/watch?v=cmUo4841KQw&t=11m16s)

"What Google has been doing has the low cost producer as they have been, I would say, sucking the economic oxygen out of the AI ecosystem, which is an extremely rational strategy for them. And for anyone is the low cost producer, you know, let's just, let's make life really hard for our competitors." [[00:11:42]](https://www.youtube.com/watch?v=cmUo4841KQw&t=11m32s)

"While that calculus changes, once Google is no longer the low cost producer, which I think will be the case, the black wells are now being used for training." [[00:15:00]](https://www.youtube.com/watch?v=cmUo4841KQw&t=14m50s)

### The Impossible Complexity of Product Transitions: Why Blackwell Nearly Broke Everything

The transition from Hopper to Blackwell represented the most complex product transition in technology history—going from air-cooled to liquid-cooled, tripling rack weight from 1,000 to 3,000 pounds, and increasing power consumption from 30 to 130 kilowatts per rack. To put this in perspective for consumers: imagine needing to change all outlets to 220 volts, install Tesla Powerwalls, generators, solar panels, whole-home humidification systems, and reinforce floors just to get a new iPhone. This complexity explains why even well-resourced companies like Meta and Microsoft completely failed to build competitive frontier models despite massive investments.

"Going from hopper to Blackwell, first you go from air cooled to liquid cooled. The rack goes from weighing round numbers of 1,000 pounds to 3,000 pounds. Goes from round numbers 30 kilowatts, which is 30 American homes, 230 kilowatts, which is 130 American homes. So I analogize it to imagine if to get a new iPhone, you had to change all the outlets in your house to 220 volts, put in a Tesla power wall, put in a generator, put in solar panels, that's the power, put in a whole home humidification system, and then reinforce the floor, because the floor can't handle this." [[00:07:47]](https://www.youtube.com/watch?v=cmUo4841KQw&t=7m37s)

"I think the first thing is you have to use it yourself. And I would just say I'm amazed at how many famous and August investors are reaching really definitive conclusions about using it. When they're based on the free tier, the free tier is like you're dealing with the tin year olds. And you're making conclusions about the tin year olds, capabilities as an adult." [[00:01:51]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1m41s)

## 2. Contrarian Perspectives

### Edge AI as the Quiet Threat: The Bear Case Nobody Wants to Discuss

While everyone focuses on scaling laws continuing, the most plausible bear case is edge AI making cloud-based models obsolete. In three years, phones (albeit bigger and bulkier) will run pruned versions of frontier models at 30-60 tokens per second locally—completely free. If a 115 IQ running at those speeds on-device proves "good enough," the massive infrastructure buildout for cloud-based AI could face existential risk. This represents a fundamental challenge to the entire thesis driving hundreds of billions in data center investment.

"There's one really obvious bear case. And it is just edge AI. And it's connected to the economic returns to ASI. In three years, on a bigger and bulkier phone to fit the amount of DRAM necessary, in the battery won't part of the last as long, you will be able to probably run a pruned down version of something like Gemini 5 or GROC4, GROC4.1, or Chatchy PT, Adam, I don't know, 30, 60 tokens per second. And then that's free. And this is clearly Apple's strategy." [[00:52:03]](https://www.youtube.com/watch?v=cmUo4841KQw&t=51m53s)

"If that happens, if like 30 to 60 tokens, like on one, whatever it is, a 115, 30 to 60 tokens a second, at a 115 IQ is good enough, I think that's a bear case." [[00:52:31]](https://www.youtube.com/watch?v=cmUo4841KQw&t=52m21s)

### SaaS Companies Are Repeating Retail's Fatal E-Commerce Mistake

Application SaaS companies are committing the exact same strategic error brick-and-mortar retailers made with e-commerce: refusing to embrace a transformative technology because it threatens current margin structures. Just as retailers avoided e-commerce due to unfavorable unit economics (only to watch Amazon eventually achieve higher margins), SaaS companies refuse to build agents because AI gross margins run 40% versus their traditional 80%+. This is a "life or death decision" and every company except Microsoft is failing it.

"Applications, SaaS companies are making the exact same mistake that Brick and Mortar retailers did with e-commerce. So Brick and Mortar retailers, you know, particularly after the telecom bubble crashed. You know, they looked at Amazon and they said, oh, it's losing money. You know, e-commerce is going to be a low-martred business. You know, how can just, you know, from first principles, how can it ever be more efficient as a business?" [[01:09:12]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h9m2s)

"Like, you want to have an agent? It's never going to succeed if you're not willing to run it at a sub 35% gross margin. Because that's what the AI natives are ready to add. Maybe they're ready in a 40. So if you were trying to preserve an 80% gross margin structure, you are guaranteed that you will not succeed at AI. Absolute guarantee." [[01:12:27]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h12m17s)

"This is a life for death decision. And essentially, everyone except Microsoft is failing it." [[01:15:42]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h15m32s)

### Meta and Microsoft's Billion-Dollar Failures Prove Building Frontier Models is Harder Than Anyone Thought

Mark Zuckerberg confidently predicted Meta would have the best AI model in 2025—he wasn't even in the top 100. Microsoft bought Inflection AI expecting quick progress on internal models. Amazon acquired Dept AI with similar hopes. All three companies, despite massive resources and top talent, completely failed to build competitive frontier models. This demonstrates that what OpenAI, Anthropic, Google, and xAI have accomplished is far more difficult and defensible than markets appreciate—a crucial fact for understanding competitive moats.

"I think it's really important that meta, Mark Zuckerberg, at the beginning of this year and January, said, I anticipate, you know, I'm highly confident, I'm going to get the quote wrong, that at some point in 2025, we're going to have the best and most performant AI. I don't know if he's in the top 100, OK? So he was as wrong as it was possible to be. And I think that is a really important fact, because it suggests that what these four companies have done is really hard to do. Because meta threw a lot of money at it. And they failed." [[00:43:14]](https://www.youtube.com/watch?v=cmUo4841KQw&t=43m4s)

"By the way, Microsoft also failed. They did not make such an unequivocal prediction. But they bought inflection AI. And there were a lot of comments from them that we anticipate our internal models quickly getting better. And we're going to run more and more of our AI on our internal models. As an Amazon, they bought a company called the Dept AI. They have their models called Nova. I don't think they're in the top 20." [[00:43:32]](https://www.youtube.com/watch?v=cmUo4841KQw&t=43m22s)

### Data Centers in Space Are Inevitable: The Ultimate First-Principles Solution

From first principles, data centers should exist in space, not on Earth. Space offers six times more solar irradiance (constant sunlight, 30% more intense), free cooling via radiators facing absolute zero, elimination of massive cooling infrastructure, and faster networking through laser communication in vacuum versus fiber optics. Combined with Starlink's direct-to-cell capability eliminating terrestrial routing, space-based inference offers superior economics and user experience. This has "really profound implications for everyone building a power plant or a data center on planet Earth."

"In every way, data centers in space from a first principles perspective are superior to data centers on Earth. So in space, you can keep a satellite in the sun 24 hours a day. And the sun is 30% more intense. You know, you can keep it in the sun just because like if the sun's here, here's this, you know, you can have the satellite, you know, always kind of catching the light. Catching the light. The sun is 30% more intense. And this results in six times more irradiance and outer space than on planet Earth." [[00:53:02]](https://www.youtube.com/watch?v=cmUo4841KQw&t=52m52s)

"For cooling. And one of these racks, a majority of the mass in the weight is cooling. And the cooling in these data centers is incredibly complicated, you know, I mean, the HVAC, the CDU, the liquid cooling. It's very cool to see. It's amazing to see. And space cooling is free. You just put a radiator on the dark side of the satellite and go all the way. And as close to absolute zero as you can get." [[00:53:51]](https://www.youtube.com/watch?v=cmUo4841KQw&t=53m41s)

## 3. Companies Identified

### **xAI**
Fast-growing AI company building frontier models and data centers

**Why mentioned:** Will likely release first Blackwell-trained model in early 2026 due to fastest data center construction. Now has dominant API share on OpenRouter (1.35 trillion tokens vs Google's 800-900 billion and Anthropic's 700 billion).

"I think the first Blackwell model will come from XAI. And the reason for that is just, it's a, according to Jensen, no one builds data centers faster than Elon. Jensen has said this on the record. Even once you have the Blackwells, it takes six to nine months to get them performing at the level of hopper." [[00:12:14]](https://www.youtube.com/watch?v=cmUo4841KQw&t=12m4s)

"But it is funny, like, you know, if you go on OpenRouter, you can just look. They have dominant share now, OpenRouter is whatever it is. It's 1% of API tokens. But it's an indication. They process 1.35 trillion tokens. Google did like 800, 900 billion. This is like whatever it is, last seven days or last month. You know, Anthropic was at 700 billion. Like XAI is doing really, really well." [[00:49:37]](https://www.youtube.com/watch?v=cmUo4841KQw&t=49m27s)

### **Anthropic**
Leading AI lab building Claude models

**Why mentioned:** Despite being well-funded, they're burning "dramatically less cash than OpenAI and growing faster." Recently signed $5 billion deal with Nvidia, showing strategic shift recognizing Blackwell/Rubin advantages over TPUs. Has benefited from same cost advantages as Google through TPU access.

"Anthropic is a good company. You know, they're burning dramatically less cash than OpenAI and growing faster. So I think you have to give in, anthropic a lot of credit. And a lot of that is their relationship with Google and Amazon for the TPUs and the trainings. And so Anthropic has been able to benefit from the same dynamics that Google has." [[00:50:40]](https://www.youtube.com/watch?v=cmUo4841KQw&t=50m30s)

"Anthropic just signed the $5 billion deal within video. That is because Dario is a smart man and he understands these dynamics about Black, Wall, and Rubid relative to TPU. And so Nvidia now goes from having two of the fighters, two fighters, XAI and OpenAI, two three fighters." [[00:51:10]](https://www.youtube.com/watch?v=cmUo4841KQw&t=51m0s)

### **C.H. Robinson**
Freight brokerage company matching shippers with trucking capacity

**Why mentioned:** First Fortune 500 company outside tech to demonstrate quantitative AI-driven uplift. Stock jumped 20% after showing AI reduced quote times from 15-45 minutes to seconds while increasing quote rate from 60% to 100% of inbound requests—clear example of AI productivity gains hitting traditional industries.

"So C. A. Robinson went up something like 20% on earnings. Let's just say truck goes from Chicago to Denver. And then the trucker lives in Chicago. So it's going to go back from Denver to Chicago. There's an empty load. And C. A. Robinson has all these relationships with truckers and trucking companies. And they match shippers demand with that empty load supply to make the trucking more efficient." [[00:36:15]](https://www.youtube.com/watch?v=cmUo4841KQw&t=36m5s)

"With AI, they're quoting 100% and doing it in seconds. And so they printed a great quarter and stock went up 20%. And it was a cuss of AI driven productivity that's impacting the revenue line, the cost line, everything. And so I actually think that's pretty important." [[00:37:08]](https://www.youtube.com/watch?v=cmUo4841KQw&t=36m58s)

### **Fortell**
Hearing aid company using AI for product design

**Why mentioned:** Example of AI being used for core product design function, creating remarkable improvements. Represents how AI will enable product innovation across every vertical through better engineering.

"We both invested in Fortell, the hearing aid company, which is just absolutely remarkable. Yeah, and I think it's something I never would have thought of. And we're going to see, I think, something like that in every vertical. And that's AI being used for the most core function of any company, which is designing the product." [[00:33:58]](https://www.youtube.com/watch?v=cmUo4841KQw&t=33m48s)

### **Intel**
Semiconductor manufacturer with foundry business

**Why mentioned:** Under new CEO Leap Boo, positioned to benefit from compute shortage due to empty fabs that will eventually be filled. Previous CEO Patrick Helsinger put company on "the only strategy that could result in success" before being fired by board.

"But now you have this guy, Leap Boo, who's a really good executive and really understands that business. I mean, by the way, Patrick Helsinger, I think was also a good executive. And he put intel on the only strategy that could result in success. And I actually think it's shameful that the intel board fired him when they did it. But Leap Boo is a good executive and now he's reaping the benefits of Patrick's strategy. And Intel has all these empty fabs. And eventually, given the shortages we have of compute, those fabs are going to be filled." [[01:00:19]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h0m9s)

## 4. People Identified

### **Andre Carpathi**
AI researcher and former Tesla AI director

**Why mentioned:** Made fundamental insight about AI capabilities: "With software, anything you can specify, you can automate. With AI, anything you can verify, you can automate." Everything he writes "you have to read three times."

"Like one of Carpathi's great things was with software. Anything you can specify, you can automate. With AI, anything you can verify, you can automate. It's such an important concept, and I think it's an important distinction." [[00:09:38]](https://www.youtube.com/watch?v=cmUo4841KQw&t=9m28s)

"Everything Andre Carpathi writes, you have to read it three times. Yeah. Minimum." [[00:03:29]](https://www.youtube.com/watch?v=cmUo4841KQw&t=3m19s)

### **Jensen Huang**
CEO of Nvidia

**Why mentioned:** Stated publicly that "no one builds data centers faster than Elon," validating xAI's infrastructure advantage. Leading Nvidia's aggressive response to ASIC competition with annual GPU cadence.

"According to Jensen, no one builds data centers faster than Elon. Jensen has said this on the record." [[00:12:18]](https://www.youtube.com/watch?v=cmUo4841KQw&t=12m8s)

### **Mark Zuckerberg**
CEO of Meta

**Why mentioned:** Made confident but completely wrong prediction that Meta would have best AI model in 2025. This failure demonstrates how difficult frontier model development truly is, even for well-resourced companies. Yamakoun had to leave Meta's AI efforts.

"I think it's really important that meta, Mark Zuckerberg, at the beginning of this year and January, said, I anticipate, you know, I'm highly confident, I'm going to get the quote wrong, that at some point in 2025, we're going to have the best and most performant AI. I don't know if he's in the top 100, OK? So he was as wrong as it was possible to be." [[00:43:03]](https://www.youtube.com/watch?v=cmUo4841KQw&t=42m53s)

### **Eric Fisheria**
Tech investor and analyst

**Why mentioned:** Coined phrase "foundation models are the fastest appreciating assets in history." Gavin modified this to "foundation models without unique data and internet scale distribution are the fastest appreciating assets in history."

"In 2023 and 24, I was fond of quoting Eric Fisheria. And Eric Fisheria's statement, our friend, brilliant man. And Eric would always say foundation models are the fastest appreciating assets in history. And I would say he was 90% right. I modified the statement." [[00:40:24]](https://www.youtube.com/watch?v=cmUo4841KQw&t=40m14s)

### **David George (Iconic/a16z)**
Venture capitalist

**Why mentioned:** Good friend who has documented data showing AI productivity gains in startups—for given revenue levels, companies today have significantly fewer employees than two years ago due to AI handling sales, support, and product development.

"By the way, David George is a good friend. Great guy. He has his model busters thing. So there's very clear data that this is happening. So people who have a lens into the world of venture see this." [[00:35:49]](https://www.youtube.com/watch?v=cmUo4841KQw&t=35m39s)

## 5. Operating Insights

### Use AI Itself to Master AI: The Meta-Learning Advantage

The best way to keep up with AI developments is to use AI itself. Listen to podcasts from frontier lab researchers, then discuss the interesting parts with AI models to deepen understanding. Minimize friction—have AI instantly accessible (voice or button). The most sophisticated investors are using $200/month pro tiers, not free tiers which represent "tin year olds" compared to "fully fledged 30, 35 year olds."

"And then for me, one of the best use cases of AI is to keep up with all of this. Just like, listen to a podcast. And then if there are parts that I thought were interesting, just talk about it with AI. And I think it's really important to have as little friction as possible." [[00:03:51]](https://www.youtube.com/watch?v=cmUo4841KQw&t=3m41s)

"You have to pay for the highest tier, whether it's Gemini Ultra, SuperGrock, whatever it is, you have to pay the $200 per month tiers. Whereas those are like a fully fledged 30, 35 year old, it's really hard to extrapolate from a native or a 10 year old to the 35 year old, and yet a lot of people are doing that." [[00:02:11]](https://www.youtube.com/watch?v=cmUo4841KQw&t=2m1s)

### Young AI-Native Entrepreneurs Get Polished Faster Through AI Coaching

Young founders today are remarkably more polished and develop faster than previous generations because they're constantly consulting AI for guidance—on investor pitches, HR situations, product strategy, sales challenges. This explains why VCs see "massive AI productivity" in portfolio companies: 23-24 year old founders are where 30-something founders used to be in capabilities.

"These young CEOs, they're just so impressive in all ways. And they get more polished faster. And I think the reason is, is they're talking to the AI. How should I deal with pitching this investor? I'm meeting with Patrick O'Shaughnessy. What do you think the best ways I should pitch a mark? Yeah, and it works. Do a deep research. And it's good." [[01:04:51]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h4m41s)

### Run Customer Support and Sales at Negative Margins When You Have Strategic Advantages

If you're the low-cost producer with other revenue streams (like Google with Search), the rational strategy is to run AI at negative 30% margins to "suck the economic oxygen out of the environment." This makes it impossible for competitors who need external funding to raise capital, eventually securing dominant position. Strategic positioning matters more than unit economics in winner-take-all markets.

"If you have a decisive cost advantage in your Google and you have search and all these other businesses, why not run AI at a negative 30% margin? It is by far the rational decision you take the economic oxygen out of the environment. You eventually make it hard for your competitors who need funding unlike you to raise the capital they need. And then on the other side of that, maybe you have an extremely dominant chair position." [[00:14:38]](https://www.youtube.com/watch?v=cmUo4841KQw&t=14m28s)

### The 1,000 Clean Stores Principle Applies to AI Infrastructure

Successfully running 1,000 stores that are clean, well-lit, stocked with relevant goods at good prices, and staffed by friendly non-stealing employees makes you a $20-30 billion company—only 15 companies have done it. The same principle applies to AI: running GPUs at high utilization across massive clusters, making smart experimental choices with limited runs, and executing well on pre-training, post-training, and test-time compute is incredibly difficult execution that few can master.

"I used to have the saying, like, hey, I was retelling on this long ago. Pick any vertical in America. If you can just run 1,000 stores and have them clean, well-lit, stocked with relevant goods at good prices and staffed by friendly employees who are not stealing from you, you're going to be a $20 billion company, a $30 billion company. Like, 15 companies have been able to do that. It's really hard. And it's the same thing. Doing all of these things well is really hard." [[01:08:36]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h8m26s)

## 6. Overlooked Insights

### Taiwan Semi as Accidental Market Governor: The Cautious Gatekeeper Preventing Bubble

Taiwan Semiconductor's paranoid conservatism about overbuilding capacity may be single-handedly preventing an AI bubble. Despite customer demands for faster expansion, TSMC remains skeptical (they "laughed" at Sam Altman, calling him "a podcast bro"). Their cautious approach to capacity expansion acts as a natural "brake on the bubble" or "governor" on the entire AI infrastructure buildout—a powerful but rarely discussed force moderating the pace of AI investment.

"I think Taiwan Simmy is in the process of making mistakes, but they're just so paranoid about an overbuilt. And they're so skeptical. They're the guys who met with Sim Altman and laughed at said, he's a podcast, bro. He has no idea what he's talking about. They're terrified of an overbuilt. So it may be that Taiwan Simmy, single-handedly that they're cautious. It's the brakes on the bubble. It's the governor." [[01:00:48]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h0m38s)

"It's good that powers a governor. It's good that Taiwan Simmy is a governor." [[01:01:01]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h0m51s)

### Whatever AI Needs, It Gets: The Uncanny Timing of Constraint Relief

A pattern has emerged that whenever AI faces a potential bottleneck, solutions mysteriously appear at exactly the right moment. Public opinion on nuclear power changed faster than on any issue in U.S. history—precisely when AI needed power. Reasoning emerged during the Blackwell delay gap. Data centers in space concepts are emerging as terrestrial power constraints bite. This uncanny timing raises deeper questions about whether AI's "wants" are somehow being fulfilled by broader forces—a subtle but profound observation about technological momentum.

"I have just been fascinated that for the last two years, whatever AI needs to keep growing and advancing, it gets. Have you ever seen public opinion change so fast in the United States on any issue has nuclear power? Just happen like that. Like that. And like, why did that happen like right when AI needed it to happen? Now we're running up on boundaries of power and earth, you know? All of a sudden, data centers in space, you know, just it's just a little strange to me that whenever there is something, a bottleneck that might sew it down, everything accelerates." [[01:18:02]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h17m52s)

"I get just whatever AI needs, it gets." [[01:19:11]](https://www.youtube.com/watch?v=cmUo4841KQw&t=1h19m1s)