# Amjad Masad & Adam Dâ€™Angelo: How Far Are We From AGI?

**Podcast:** A16z Podcast
**Date:** 2025-11-08
**Video ID:** 191Ojd7Rq6s
**Video URL:** https://www.youtube.com/watch?v=191Ojd7Rq6s

---

[00:00:00] Nothing seems fundamentally so hard that it couldn't be solved by the smartest people in the world
[00:00:05] SPEAKER_00: working incredibly hard for the next five years.
[00:00:08] SPEAKER_00: Humanity went through the agriculture revolution and industrial revolution.
[00:00:12] SPEAKER_01: We're going through another revolution.
[00:00:14] SPEAKER_01: We will not be able to call it something.
[00:00:16] SPEAKER_01: It's a feature people, we will call it something.
[00:00:18] SPEAKER_01: But we are going through something.
[00:00:20] SPEAKER_01: The number of solo entrepreneurs that this technology is going to enable.
[00:00:25] SPEAKER_00: It's vastly increased what a single person can do.
[00:00:28] SPEAKER_00: For the first time,
[00:00:30] SPEAKER_01: opportunity is massively double for everyone.
[00:00:32] SPEAKER_01: Just the ability for more people to be able to become entrepreneurs.
[00:00:36] SPEAKER_01: Yeah, that's amazing.
[00:00:41] Adam Amjad, welcome to the podcast.
[00:00:43] SPEAKER_02: Thank you.
[00:00:43] SPEAKER_02: Yeah, thanks for having us.
[00:00:44] SPEAKER_02: So a lot of people have been throwing cold water over LLM lately.
[00:00:48] SPEAKER_02: So in some general bearishness, people talking with the limitations of LLM's why they won't get a stage AI.
[00:00:54] SPEAKER_02: Well, maybe what we thought was just a couple years away is now maybe 10 years away.
[00:00:58] SPEAKER_02: Adam, you seem a bit more optimistic.
[00:01:00] SPEAKER_02: Why don't you share your broad general overview?
[00:01:02] SPEAKER_02: Yeah, I mean, I actually honestly don't know what people are talking about.
[00:01:07] SPEAKER_00: I think if you look a year ago,
[00:01:10] SPEAKER_00: the world was very different.
[00:01:12] SPEAKER_00: And so just judging on how much progress we've made in the last year with things like reasoning models,
[00:01:19] SPEAKER_00: things like the improvement in code generation ability,
[00:01:24] SPEAKER_00: the improvements in video gen,
[00:01:26] SPEAKER_00: it seems like things are going faster than ever.
[00:01:29] SPEAKER_00: And so I don't really understand where the kind of bearishness is coming from.
[00:01:35] SPEAKER_00: Well, I think there's some sense that we hoped that they would be able to
[00:01:39] SPEAKER_02: replace all of tasks or all the jobs.
[00:01:42] SPEAKER_02: And maybe there's some sense that it's like middle to middle but not end to end.
[00:01:45] SPEAKER_02: And maybe labor won't be automated in the same way that we thought it would on the same timeline.
[00:01:50] SPEAKER_02: Yeah, I mean, I don't know what the previous timelines people were thinking or, but I think if you're
[00:01:55] SPEAKER_00: going to go five years out from now, we're in a very different world.
[00:01:59] SPEAKER_00: I think I think a lot of what's holding back the models these days is not actually intelligence.
[00:02:05] SPEAKER_00: It's getting the right context into the model so that it can
[00:02:10] be able to use its intelligence.
[00:02:13] SPEAKER_00: And then there's some things like computer use that are still not quite there.
[00:02:17] SPEAKER_00: But I think we'll almost definitely get there in the next year or two.
[00:02:22] SPEAKER_00: And when you have that, I think we're going to be able to automate a large portion of what
[00:02:28] SPEAKER_00: people do. I don't think I don't know if I would call that EGI, but I think it's going to
[00:02:34] SPEAKER_00: satisfy a lot of the critiques that people are making right now.
[00:02:38] SPEAKER_00: I think they won't be valid in year two.
[00:02:42] What is your definition of EGI?
[00:02:44] I don't know. Everyone thinks it's something different.
[00:02:47] SPEAKER_00: I think, I mean, one definition I kind of like is if you say that you have a remote worker,
[00:02:55] SPEAKER_00: a human, any job that could be done by someone whose job can be done remotely,
[00:03:02] SPEAKER_00: that that's EGI. You can then say, does it have to be better than the best person in the world
[00:03:08] SPEAKER_00: at every single job? Some people call that ASI. Does it have to be better than teams of people?
[00:03:14] SPEAKER_00: You can argue with those different definitions. But I think once we get to be better than a typical
[00:03:21] SPEAKER_00: remote worker at the job they're doing, we're living in a very different world. And I think that's
[00:03:26] SPEAKER_00: effectively what people, that's a very useful anchor point for these definitions.
[00:03:33] SPEAKER_02: So you're not sensing the same limitations of LLMs and other people. You think there's a lot
[00:03:37] SPEAKER_02: more room that LMs can go from here? We don't need like a brand new architecture or other
[00:03:41] SPEAKER_02: breakthrough. I don't think so. I mean, I think there are certain things like
[00:03:46] SPEAKER_00: memory and learning, like continuous learning that are not very easy with the current
[00:03:52] SPEAKER_00: architectures. I think even those you can sort of fake and maybe we're going to be able to get
[00:03:58] SPEAKER_00: them to work well enough. But we just don't seem to be hitting any kind of limits. The progress
[00:04:06] SPEAKER_00: in reasoning models is incredible. And I think the progress in pre-training is also
[00:04:13] SPEAKER_00: going pretty quickly, maybe not as quickly as people had expected, but certainly fast enough
[00:04:19] SPEAKER_00: that you can expect a lot of progress over the next few years.
[00:04:22] SPEAKER_00: I'm John. What's your reaction here in all this?
[00:04:25] SPEAKER_01: Yeah, I think I've been pretty consistent and consistently right perhaps.
[00:04:31] SPEAKER_01: Do I say?
[00:04:34] Because I'm a bit of a more public doubter of things around the time when the AI safety
[00:04:52] SPEAKER_01: discussion was reaching its height back in maybe 2223. I thought it was important for us to be
[00:05:01] SPEAKER_01: realistic about the progress because otherwise we're going to scare politicians, we're going to
[00:05:07] SPEAKER_01: scare everyone. DC will descend on Silicon Valley. They'll shut everything down. So my criticism
[00:05:16] SPEAKER_01: of the idea of like AGI 2027, that paper that I think is called Alexander, someone else wrote.
[00:05:22] SPEAKER_01: And then in this situation awareness and all this hype papers that are not really science,
[00:05:31] SPEAKER_01: they're just vibed. Here's what I think will happen. The whole economy will get automated. Jobs
[00:05:39] SPEAKER_01: are going to disappear. All of that stuff is that again, it's unrealistic. It is not following
[00:05:46] SPEAKER_01: the kind of progress that we're seeing and it is going to lead to just bad policy.
[00:05:52] SPEAKER_01: My view is LM's are amazing machines. I don't think they are exactly human intelligence
[00:06:03] SPEAKER_01: equivalent. You can still trick LM's with things like they might have solved the strawberry one,
[00:06:10] SPEAKER_01: but you can still trick it with single sentence questions like how many Rs are in this sentence.
[00:06:17] SPEAKER_01: I think I tweeted about it out of there which was like three out of the four models couldn't
[00:06:21] SPEAKER_01: didn't get it. And then GPT-5 with high thinking had to think for like 15 seconds in order to
[00:06:28] SPEAKER_01: get a question like that. So LM's are I think a different kind of intelligence than what humans are.
[00:06:37] SPEAKER_01: And also they have clear limitations and we're papering over the limitations and we're kind of
[00:06:46] SPEAKER_01: working around them in all sorts of ways whether it's in the LM itself and the training data
[00:06:51] SPEAKER_01: or in the infrastructure around and everything that we're doing to make them work.
[00:06:57] SPEAKER_01: But that makes me less optimistic that we're we've cracked intelligence. And I think once we
[00:07:04] SPEAKER_01: truly crack intelligence it'll feel a lot more scalable in that you can and that the idea behind
[00:07:14] SPEAKER_01: the better lesson will actually be true in that you can just pour more power more resources
[00:07:20] SPEAKER_01: more compute into them and they'll just scale more naturally. I think right now
[00:07:26] SPEAKER_01: there's a lot of manual work going into making these models better.
[00:07:31] SPEAKER_01: In the true pre-training scaling era to the GPT-2, 3.5 maybe up to four,
[00:07:38] SPEAKER_01: it felt like you can just put more data in there and just it just got better. Whereas now it feels
[00:07:48] SPEAKER_01: like there's a lot of labeling work happening. There's a lot of contracting work happening. A lot of
[00:07:52] SPEAKER_01: these contrived RL environments are getting created in order to make LM's good at coding and becoming
[00:08:01] SPEAKER_01: coding agents. And they're going to go do that I think the news from OpenAI that they're going to do
[00:08:05] SPEAKER_01: that for investment banking. And so I try to coin this term I call functional AGI which is the idea
[00:08:13] SPEAKER_01: that you can automate a lot of aspects of a lot of jobs by just going in and like collecting as
[00:08:18] SPEAKER_01: much data and creating these RL environments. It's going to take enormous efforts and money and
[00:08:23] SPEAKER_01: data and all of that in order to do. And I think where yeah I agree with that I'm that you know
[00:08:29] SPEAKER_01: things are going to get better. 100% over the next three months, six months, clot 4.5 was a huge jump.
[00:08:36] SPEAKER_01: I don't think it's appreciated how much of a jump it was over over four. There's really really
[00:08:41] SPEAKER_01: amazing things about clot 4.5. So the rest progress we're going to continue to see progress. I don't
[00:08:47] SPEAKER_01: think LM's as they can understand are on the way to AGI and my definition for AGI is I think the
[00:08:55] SPEAKER_01: old school RL definition which is a machine that can go into any environment and learn efficiently.
[00:09:02] SPEAKER_01: In the same way that a human could go into you can put a human into a pool game and you know
[00:09:09] SPEAKER_01: within two hours they can like shoot pool and be able to do it. Right now there's no way for us to
[00:09:15] SPEAKER_01: have machines learn skills like that on the fly. You know everything requires enormous amount of
[00:09:20] SPEAKER_01: data and compute and time and effort and more importantly it requires human expertise which is
[00:09:28] SPEAKER_01: the non-bitter lesson idea which is you know human expertise is not skillful and we are reliant.
[00:09:36] SPEAKER_01: Today we are in a human expertise regime. Yeah I mean I think that
[00:09:41] humans are certainly better at learning a new skill from a limited amount of data in a new
[00:09:49] SPEAKER_00: environment than the current models are. I think that on the other hand human intelligence is
[00:09:57] SPEAKER_00: the product of evolution which used a massive amount of effective computation and so this is a
[00:10:07] SPEAKER_00: different kind of intelligence and so because it didn't have this massive
[00:10:15] equivalent of evolution it just has pre-training for that which is not as good. You then need more
[00:10:22] SPEAKER_00: data to learn everything every new skill but I guess I think in terms of like the functional
[00:10:29] SPEAKER_00: consequence. So if you're like when will the world, when will the job landscape change, when will
[00:10:36] SPEAKER_00: the economic growth hit? I think that's going to be more a function of when we can produce something
[00:10:44] SPEAKER_00: that is as good as human intelligence even if it takes a lot more compute a lot more energy,
[00:10:49] SPEAKER_00: a lot more training data we could just put in all that energy and still get to software that's
[00:10:57] SPEAKER_00: as good as the average person at doing a typical job. So I don't disagree with that and it feels
[00:11:05] SPEAKER_01: like we're in a brute force type of regime but maybe that's fine and yeah. So where's the
[00:11:13] disagreement then? I guess there's a agreement on that. Where is the average experts?
[00:11:18] I don't think that we'll get to this singularity or I don't think that we're going to get to the next
[00:11:22] SPEAKER_01: level of human civilization until we crack the true nature of intelligence.
[00:11:32] Until we understand and have algorithms that are actually not brute force.
[00:11:38] And you think those will take a long time to come?
[00:11:43] SPEAKER_00: I'm sort of agnostic on that. It just does feel like the LMs in a way are distracting from that
[00:11:51] SPEAKER_01: because all the talent is going there and therefore there's less talent that are trying to do
[00:11:57] SPEAKER_01: basic research on intelligence. Yeah, at the same time, a huge portion of talent is going into
[00:12:06] SPEAKER_00: AI research that used to previously wouldn't have gone into AI at all. And so you have this massive
[00:12:13] SPEAKER_00: industry, massive funding, you know, funding compute but also funding human employees. And that is,
[00:12:24] SPEAKER_00: I guess I, nothing seems fundamentally so hard that it couldn't be solved by the smartest
[00:12:32] SPEAKER_00: people in the world working incredibly hard for the next five years on it. But basic research
[00:12:38] SPEAKER_00: is different, right? Like trying to, like trying to get into the fundamentals and as
[00:12:46] SPEAKER_01: supposed to, like there's a lot of industry research. Like how do we make this things more useful
[00:12:51] SPEAKER_01: in order to generate profit? And I think that's different and often, I mean, Thomas Kuhn,
[00:13:00] SPEAKER_01: this philosopher of science talks a lot about how these research programs end up, you know,
[00:13:04] SPEAKER_01: becoming like a bubble and like sucking all the attention and ideas and like think about physics
[00:13:10] SPEAKER_01: and how there are like these industry of a string theory and like it pulls everything in and
[00:13:17] SPEAKER_01: they're sort of a black hole of progress. And, you know, yeah, yeah, no, and I think one of his
[00:13:24] SPEAKER_00: things was like you got to wait until the current people retire. That's right. You can have a
[00:13:29] SPEAKER_00: chance at changing the pattern. Very pessimistic about paradigms. But I guess I feel like the
[00:13:34] SPEAKER_00: current paradigm, this is maybe our district, I think the current paradigm is pretty good. And I
[00:13:38] SPEAKER_00: think we're nowhere near the sort of like diminishing returns of continuing to push on it.
[00:13:45] SPEAKER_00: And I bet, yeah, I guess I would just bet that you can keep doing different innovations within
[00:13:52] SPEAKER_00: the paradigm to get there. So let's say we continue to brute force it. We're able to automate a
[00:14:01] SPEAKER_02: bunch of labor. Do you estimate that GDP is something, you know, 4 or 5% a year or we're going up to
[00:14:08] SPEAKER_02: 10% plus? What does it do to the economy? I think it depends a lot on exactly where we get to and
[00:14:14] SPEAKER_00: what what a GI means. But so, so let's say you have, let's say you have LLMs that with,
[00:14:23] SPEAKER_00: with an amount of energy that costs $1 an hour, they could do a job of any human. Let's just,
[00:14:34] SPEAKER_00: just, just, just, just take that as a, as a theoretical point you could get to. I think you're going
[00:14:40] SPEAKER_00: to get to much more than 4 to 5% GDP growth in that world. I think the issue is you may not get
[00:14:46] SPEAKER_00: there. So you may be that LLMs that can do everything a human can do actually cost more than humans
[00:14:53] SPEAKER_00: do currently, or they can do kind of like 80% of what humans can do and then there's this other 20%.
[00:15:00] SPEAKER_00: And I think I do think at some point you get to LLMs that can do everything, every single thing
[00:15:06] SPEAKER_00: a human can do for cheaper. Like I don't see a reason why we don't eventually get there that may take
[00:15:12] SPEAKER_00: 5, 10, 15 years. But I think until you get there, we're going to get bottlenecked on the things
[00:15:19] SPEAKER_00: that the LLMs still can't do or the, you know, building enough power plants to, to supply the energy or
[00:15:27] there are other bottlenecks in the supply chain. One thing I worry about is the
[00:15:35] SPEAKER_01: deleterious effect of LLMs in the economy and that say LLMs effectively automate
[00:15:47] the entry level job, but not the experts job. So let's think QA, QQ,
[00:15:58] SPEAKER_01: insurance and it's so good, but there's still all these long till events that it doesn't handle.
[00:16:07] SPEAKER_01: And so you have a lot of really good QA people now managing hundreds of agents and you effectively
[00:16:14] SPEAKER_01: increase the productivity a lot, but they're not hiring new people because the agents are better than
[00:16:19] SPEAKER_01: new people. And that feels like a weird equilibrium to be in, right? I don't think that many people
[00:16:26] SPEAKER_01: ought to think he about it. Yeah, for sure. Yeah, no, I think that's, you know, I think it's
[00:16:31] SPEAKER_00: happening with CS majors graduating from college. There's just not as many jobs as there used to be.
[00:16:37] SPEAKER_00: And, and LLMs are a little more substitutable for what they previously would have done. And I'm
[00:16:44] SPEAKER_00: sure that's contributing to it. And then it means that you're going to have fewer people going up
[00:16:49] SPEAKER_00: that ramp that, you know, companies paid a lot of money to employ them and train them. And so
[00:16:56] SPEAKER_00: I think it's a real problem. I think it's going to, I'm guessing you'll probably see some kind of,
[00:17:03] SPEAKER_00: like that problem also creates an economic incentive to solve the problem. So it may be that there's
[00:17:10] SPEAKER_00: like more opportunities for companies that can train people or maybe use of AI to teach people
[00:17:17] SPEAKER_00: these things. But for sure, that's, that's an issue right now. Another related problem is that
[00:17:25] SPEAKER_01: since we're dependent on expert data in order to train the LLMs and the LLMs start to substitute
[00:17:35] SPEAKER_01: those workers. But, but, but, you know, at some point, there's no more experts because they're
[00:17:41] SPEAKER_01: all out of jobs and, and, and they're equivalent to that LLMs. But if the LLMs is truly dependent on
[00:17:48] on labeling data expert RL environments, then how would they improve beyond that? I think that's
[00:17:53] SPEAKER_01: something a question for an economist who really stood down and think about is like once you get the first
[00:18:01] take a automation, I mean, there are some challenges there. And so how do you go, how do you go,
[00:18:07] SPEAKER_01: how do you go to the next part? Yeah, I mean, I think it a lot of this is going to depend on how good
[00:18:13] SPEAKER_00: of our LL environments can be created. So, you know, on one extreme, you have some like
[00:18:19] SPEAKER_00: alpha-go where it's just a perfect environment and you can just blast past expert level.
[00:18:26] SPEAKER_00: But I think a lot of jobs have limited data that anyone can can train from. And so I think it'll
[00:18:35] SPEAKER_00: be interesting to see how how easy is it for research efforts to overcome that that bottleneck.
[00:18:43] If you had to make a guess on what job category is going to be introduced or explode in the future,
[00:18:51] SPEAKER_02: you know, some people say it's like the, you know, everyone's an influencer, you know, or in some
[00:18:55] SPEAKER_02: sort of caring field or, you know, everyone's employed by the government and some sort of bureaucrat
[00:19:00] SPEAKER_02: thing or, you know, with the training of the AI in some way, you know, as more and more things start
[00:19:06] SPEAKER_02: to get automated, you know, what is your, your guess as to what one more people start to do,
[00:19:12] SPEAKER_02: you know, doing art and poetry is. Yeah, I mean, at some point you have everything
[00:19:16] SPEAKER_00: automated. And then I think people will do art and poetry. And, you know, I think there's a
[00:19:21] SPEAKER_00: data point that the people playing chess is up since computers got better at human than humans
[00:19:29] SPEAKER_00: at chess. So I don't think that's a bad world if people are all just kind of free to pursue their
[00:19:36] SPEAKER_00: hobbies as long as you have some kind of, you know, way to distribute wealth so that some people can
[00:19:42] SPEAKER_00: afford to live. But I, you know, in the near, that's a while away. And in the near term,
[00:19:53] SPEAKER_00: well, like 10, 15 years out, I don't know how much. But yeah, in the, I'll put it in the at least
[00:19:59] SPEAKER_00: 10 years range. I think in the near term, the job categories that are going to explode the jobs
[00:20:07] SPEAKER_00: that can really leverage AI. And so, so people who are good at using AI to accomplish their jobs,
[00:20:15] SPEAKER_00: especially to accomplish things that the AI couldn't have done by itself, there's just,
[00:20:19] SPEAKER_00: there's a massive demand for that. I don't think we're going to get to a point where you
[00:20:25] SPEAKER_01: automate every, every job. Definitely not in the current paradigm. I would, I would doubt it
[00:20:33] happening. I, I'm not certain it would ever happen, but definitely not in the current paradigm.
[00:20:41] SPEAKER_01: Now, here's my thing, because a lot of jobs is about servicing other humans. You need to be
[00:20:46] SPEAKER_01: fundamental to human in order to, you need to be actually human in order to understand what other
[00:20:51] SPEAKER_01: people want, you know? And so you need to have the human experience. So unless we're going to
[00:20:57] SPEAKER_01: create human humans, unless the unless AI is actually embodied in human experience, then humans
[00:21:07] SPEAKER_01: will always be the generators of ideas in the economy. Adam, we respond to Andrea's point around
[00:21:13] SPEAKER_02: the human part because you created one of the most, you know, the best wisdom of the crowds,
[00:21:18] SPEAKER_02: you know, platforms in the universe. And now you've gone, you know, all in with Poe.
[00:21:24] SPEAKER_02: What are your thoughts on, you know, to what extent will we be relying on? Humans
[00:21:29] SPEAKER_02: diverse will we be trusting AI's to, you know, be our therapist, PR, you know, caretakers in other ways?
[00:21:35] Humans have a lot of knowledge collectively. And, you know, even like one individual person who's
[00:21:42] SPEAKER_00: an expert and has lived the whole life and had a whole career and seen a lot of things, they often
[00:21:48] SPEAKER_00: know a lot of things that are not written down anywhere. And you can call it test and knowledge,
[00:21:55] SPEAKER_00: but also what they're capable of writing down if you did ask them a question. I think there's
[00:22:01] SPEAKER_00: still an important role for people to play in the world by sharing their knowledge, especially
[00:22:09] SPEAKER_00: when they have knowledge that just wasn't otherwise in an LLM's training set.
[00:22:15] SPEAKER_00: You know, whether they will be able to make a full-time living doing that, I don't know.
[00:22:22] SPEAKER_00: But if that becomes a bottleneck, then for sure that's going to mean that all the sort of like
[00:22:27] SPEAKER_00: economic pressure goes to that. I don't, in terms of the like, you know, you have to be human
[00:22:35] SPEAKER_00: to know what humans want. I don't know about that. So like as an example, I think, I think
[00:22:43] SPEAKER_00: recommender systems, the system that ranks your Facebook or Instagram or Korra feed. Those
[00:22:51] recommender systems are already superhuman at predicting what you're going to be interested in
[00:22:58] SPEAKER_00: reading. Like if I give you a task that was like, make me a feed that I'm going to read, like,
[00:23:04] SPEAKER_00: there's just no way, no matter how much you do about me, there's no way you could compete with
[00:23:08] SPEAKER_00: these algorithms. There just have so much data about everything I've ever clicked on,
[00:23:12] SPEAKER_00: everything everyone else has ever clicked on, what all the similarities are between all those
[00:23:16] SPEAKER_00: different data sets. And so I don't know, you know, it's true that as a human, you can kind of like
[00:23:23] SPEAKER_00: simulate being a human and that makes it easier for you to like test out ideas. And I'm sure that
[00:23:30] composers and artists are this is an important part of their their process for doing work is
[00:23:36] SPEAKER_00: they're chefs or yeah, they produce something and you know, chef will cook something and they taste
[00:23:41] SPEAKER_00: it. And it's important that they can taste it. But I don't know, you know, they just they have
[00:23:46] SPEAKER_00: very little data compared to what AI can be trained on. So so I don't know how that's going to
[00:23:51] SPEAKER_00: shake out. As a say good point, I mean, at ultimately what recommender systems are, they're like
[00:23:58] SPEAKER_01: aggregating all the different tastes and then sort of finding where you sit in the sort of
[00:24:05] SPEAKER_01: multi-dimensional taste vector space and like getting you the best content there. So I guess
[00:24:11] SPEAKER_01: there's some of that. I think that's more narrow than we think like, yes, it's true in
[00:24:17] SPEAKER_01: recommender systems, but I'm not entirely sure it's true of of of everything.
[00:24:22] SPEAKER_01: But so I think the best prediction for where the world has had it and if this is not a
[00:24:33] endorsement or necessarily like this is where I think the world had it because I think part of it is
[00:24:38] SPEAKER_01: that will be slightly unstable on stable system, but I think the sovereign individual can
[00:24:46] SPEAKER_01: change to be I think a really good set of predictions for the future. Although it's not a scientific
[00:24:53] SPEAKER_01: book or not, it's a very polemic book. But the idea is, you know, in the late 80s, early 90s,
[00:25:05] SPEAKER_01: are they economists? I'm not sure. I think they're economists that were political science
[00:25:09] SPEAKER_01: measures to people out of the UK, wrote this book about trying to predict what happens
[00:25:18] SPEAKER_01: when computer technology matures, right? They're like, humanity went through a they got a
[00:25:23] SPEAKER_01: culture revolution and industrial revolution. We're going through another revolution. Clearly,
[00:25:29] SPEAKER_01: information revolution, now we call it intelligence revolution, whatever I think we will not be
[00:25:33] SPEAKER_01: able to call it something. It's a future people will call it something, but we are going through
[00:25:38] SPEAKER_01: something. And so they're trying to predict what happens from here and what they arrive at is that
[00:25:43] SPEAKER_01: the ultimately you're going to have large swaths of people that are potentially unemployed or
[00:25:49] SPEAKER_01: economically not contributing, but you're going to have the entrepreneur, the entrepreneur capitalists
[00:25:57] SPEAKER_01: going to be so highly leveraged because they can spin up these companies with AI agents very quickly.
[00:26:03] SPEAKER_01: Because they have this, because they're very generative, they have interesting ideas. They're
[00:26:09] SPEAKER_01: human. They have interesting ideas about what other people want. They can create these companies
[00:26:13] SPEAKER_01: very quickly in these products and services and they can organize the economy in certain ways.
[00:26:18] SPEAKER_01: And the politics will change because today's politics is based on
[00:26:25] SPEAKER_01: every human being economically productive. But when you have only,
[00:26:35] SPEAKER_01: when you have massive automation and then you have a few entrepreneurs and very intelligent
[00:26:41] SPEAKER_01: generative people are actually able to be productive, then the political structures also change.
[00:26:49] SPEAKER_01: And so they talk about how the nation states sort of subsides. And instead you go back to
[00:26:59] SPEAKER_01: to an era where states are like competing over people, over wealthy people. And like they,
[00:27:06] SPEAKER_01: you know, as a sovereign individual, you can like
[00:27:11] SPEAKER_01: negotiate or tax rate with your favorite state. And so I touch the sound like biology a little bit.
[00:27:17] SPEAKER_01: And I don't think it is far from where it might be headed. Now again, it's not a sort of a
[00:27:24] SPEAKER_01: value judgment or a desire. But I do think it's worth thinking about when people are not the
[00:27:34] SPEAKER_01: you know, unitive economic productivity, things have to change, including culture and politics.
[00:27:40] Yeah, I think there's a question with that book and some of this conversation were probably of like,
[00:27:45] SPEAKER_02: when does the technology reward the, you know, the defender versus this sort of aggregator or some
[00:27:51] SPEAKER_02: or like the when does it incentivize more decentralization versus central state like a
[00:27:57] SPEAKER_02: member of Peter Tiel had this quip decade ago of like, you know, crypto is libertarian. It is more
[00:28:02] SPEAKER_02: decentralizing AI is communist or more centralizing. And it it it's not obvious to me that that's
[00:28:09] SPEAKER_02: entirely accurate on on either side AI does seem to empower a bunch of individuals as you were
[00:28:15] SPEAKER_02: saying. And then also, you know, crypto turns out it's like fintech or science like stable, you know,
[00:28:20] SPEAKER_02: it does empower sort of, you know, in nation states we're talking about doing the sort of like, you
[00:28:25] SPEAKER_02: know, the China thing that they were going to do. So yeah, I think there's an open question as to,
[00:28:31] you know, which which technology leads to who does it empower more the edges or the center. And
[00:28:36] SPEAKER_02: I think if it empowers the edges, it seems like the sovereign individuals is and maybe there's
[00:28:41] SPEAKER_02: a barbell where it's like both basically the big the income is just get much much much much
[00:28:45] SPEAKER_02: much bigger. And there's like these edges, but it's a ton. Yeah, I'm I'm very excited for the
[00:28:53] SPEAKER_00: the number of solo entrepreneurs that this technology is going to enable. I think it's
[00:29:00] SPEAKER_00: it's just greatly it's vastly increased what what a single person can do. And there's so many ideas
[00:29:07] SPEAKER_00: that just never got explored because it's a lot of work to get a team of people together and
[00:29:14] SPEAKER_00: maybe raise the funding for it and get the right kind of people with all the different skills you
[00:29:18] SPEAKER_00: need. And now that one person can can bring these things into existence, I think I think I
[00:29:23] SPEAKER_00: think they were going to see a lot of really amazing stuff. Yeah, I get these treats all the time about
[00:29:27] SPEAKER_01: people who like with their jobs because they started me so much money you're using the tools
[00:29:32] SPEAKER_01: like like Replet and it's it's really exciting. I think for the first time,
[00:29:39] SPEAKER_01: opportunity is massively available for for everyone. And I think that that is to me the most
[00:29:45] SPEAKER_01: exciting thing about this technology other than all the other stuff that we're talking about,
[00:29:50] SPEAKER_01: just the ability for more people to be able to become entrepreneurs. Yeah, that trend is obviously
[00:29:56] SPEAKER_02: going to happen. As we look out of the next decade or two, do you think that as more likely to
[00:30:02] SPEAKER_02: be sustaining or disruptive in the Christian's sense? So that's get another way. Do you think that
[00:30:07] SPEAKER_02: most of the value capture is going to come from companies that were scaled pre open AI starting?
[00:30:15] SPEAKER_02: So it's a rep that still counts as the latter and so does court or do you think most of the
[00:30:20] SPEAKER_02: values going to be captured by companies that started after let's say 2015 2016. So there's a
[00:30:26] SPEAKER_00: related question which is how much of value is going to go to the hyper scalers versus everyone else?
[00:30:32] SPEAKER_00: And I think on that one, we are actually we're in a pretty good balance where there's enough
[00:30:41] SPEAKER_00: competition among the hyper scalers that the there's enough competition that as an application
[00:30:50] SPEAKER_00: level company, you have choice and you have alternatives and the prices are coming down incredibly
[00:30:57] SPEAKER_00: quickly. But there's also not so much competition that the hyper scalers and the labs like Anthropic
[00:31:06] SPEAKER_00: and OpenAI, there's not so much competition that they are unable to raise money and make these
[00:31:12] SPEAKER_00: long term investments. And so I actually think we're in pretty good balance and we're going to have
[00:31:18] SPEAKER_00: a lot of a lot of new companies and a lot of growth among the hyper scalers.
[00:31:25] I think that's that's about right. So the terminology of sustaining versus disrupting comes from
[00:31:33] SPEAKER_01: the innovators dilemma. And it's this idea that whenever there's a new technology trend,
[00:31:41] SPEAKER_01: it's sort of there's this idea of a power curve. It starts as a toy almost or something that doesn't
[00:31:47] SPEAKER_01: really work or captures the lower end of the market. But as it sort of evolves, it goes up the
[00:31:53] SPEAKER_01: power curve and eventually the disrupts even the incumbents. So originally the incumbents don't pay
[00:31:58] SPEAKER_01: attention to it because it looks like a toy and then eventually the disrupts everything and eats
[00:32:03] SPEAKER_01: the entire sort of market. So that was true of PCs. When PCs came along, the big made frame
[00:32:11] SPEAKER_01: manufacturers did not pay attention to it and initially it was like, yeah, it's four kids or
[00:32:18] SPEAKER_01: whatever. But we have to run these large computers or data centers or whatever. But now even data
[00:32:24] SPEAKER_01: centers are running on PCs and so on. And so PCs were this is usually disruptive force. But there
[00:32:33] SPEAKER_01: are technologies that come along and really benefit their incumbents and really don't really benefit the
[00:32:37] SPEAKER_01: the new players of startups. I think Adams, right? It's both. And maybe for the first time, it's kind
[00:32:47] SPEAKER_01: of both like a huge technology trend because the internet was hugely disruptive. But this time,
[00:32:55] SPEAKER_01: it feels like it is an obvious supercharge for the incumbents, for the hyper-skillers,
[00:33:02] SPEAKER_01: for the large internet companies. But it also enables new business models that is perhaps
[00:33:13] SPEAKER_01: counter-position against the existing ones. Although I think what happened is everyone read that
[00:33:23] SPEAKER_01: book and everyone learned how to not be disrupted. For example, chat GPT was fundamentally counter-position
[00:33:28] SPEAKER_01: against Google because Google had a business that was actually working.
[00:33:33] SPEAKER_01: Chat GPT was seen as this technology that hallucinates a lot and creates a lot of that information.
[00:33:38] SPEAKER_01: And Google wanted to be trusted. And so Google had chat GPT internally. They didn't release
[00:33:43] SPEAKER_01: Gemini until like two years after chat GPT and chat GPT had sort of already won the like at least
[00:33:48] SPEAKER_01: brand recognition. And so there was in a way, OpenAI came out as a disruptive technology. But now
[00:33:56] SPEAKER_01: Google realizes this is a disruptive technology and kind of responds to it. At the same time,
[00:34:00] SPEAKER_01: it was always obvious that AI is going to benefit Google. At minimum, it's overview,
[00:34:06] SPEAKER_01: search overview has gone a lot better. All its workspace suite is getting a lot better with Gemini.
[00:34:14] SPEAKER_01: Their mobile phones, everything gets better. So it seems like it's both.
[00:34:19] SPEAKER_01: Yeah, I really agree like everyone read the book and that changes what the theory even means.
[00:34:24] SPEAKER_00: Because you have, you've like all the public market investors have read that book and they
[00:34:30] SPEAKER_00: now are going to punish companies for not adapting and reward them for adapting even if it means
[00:34:35] SPEAKER_00: they have to make long-term investments. I think all the management leadership of the companies
[00:34:40] SPEAKER_00: have read the book and they're on top of their game. I think we also just like the people running
[00:34:46] SPEAKER_00: these companies are in, I guess I would say smarter. I think then like the companies from the
[00:34:55] SPEAKER_00: generation that that book was sort of built on and they're on at the top of their game and they
[00:35:02] SPEAKER_00: are, a lot of them are founder controlled. And so they can make it easier for them to sort of
[00:35:07] SPEAKER_00: take a hit and make these these investments. So that's, I actually, you know, I think if
[00:35:14] SPEAKER_00: if you had an environment more like we had in say like the 90s, I think this would actually be
[00:35:22] SPEAKER_00: more disruptive than the current hyper competitive world that we're into.
[00:35:30] One mistake that we as Vermeve reflected on over the past few years, although of course I've
[00:35:35] SPEAKER_02: been here for a few months, is this idea of that we've passed on companies because they weren't
[00:35:42] SPEAKER_02: going to be the market leader or the category winner. And thus we thought, oh, you know,
[00:35:47] SPEAKER_02: learning the lessons from from Web 2, you have to invest in the category winner. That's where
[00:35:52] SPEAKER_02: things are going to consolidate. Values going to crew over time. And it seemed, so why do the
[00:35:58] SPEAKER_02: next foundation model company if the first one already has a as a start? But it seems like
[00:36:03] SPEAKER_02: the market has gotten so much bigger that in foundation models, but also in applications,
[00:36:09] SPEAKER_02: there's just multiple winners and they're kind of, you know, fragmenting or, you know,
[00:36:13] SPEAKER_02: taking parts of the market that are all venture scale. I'm curious if this is
[00:36:18] SPEAKER_02: durable phenomenon or, but it seems just one difference than the Web 2 era is just more winners
[00:36:25] SPEAKER_02: across from more categories. I think network effects are playing much less of a role now than they
[00:36:30] SPEAKER_00: did in the Web 2 era also. And that that makes it easier for competitors to get started. There's
[00:36:37] SPEAKER_00: still a scale advantage because, you know, if you have more users, you can get more data. If you
[00:36:43] SPEAKER_00: have more users, you can raise more capital. But that advantage is not, it doesn't make it
[00:36:50] SPEAKER_00: absolutely impossible for a competitor of smaller scale. It makes it hard, but it's,
[00:36:57] SPEAKER_00: there's definitely like room for more winners than there was before.
[00:37:02] SPEAKER_00: And the another difference is that people are seeing the value so strongly that they're willing to
[00:37:08] SPEAKER_02: pay early on and maybe a way that they, the question with Web 2 companies was, how do they
[00:37:13] SPEAKER_02: get money? You know, Facebook super early, obviously, you know, Google, it said I was like,
[00:37:16] SPEAKER_02: oh, how are they going to monetize? And, you know, the companies here are monetizing from,
[00:37:20] SPEAKER_02: from the get go, you guys companies included. Yeah, yeah. And the, I think with the earlier generation
[00:37:26] SPEAKER_00: of companies, the monetization kind of depended on scale. Yeah. Like you couldn't build a good
[00:37:34] SPEAKER_00: ad business until you got to millions, tens of millions of users. And now with subscriptions,
[00:37:43] SPEAKER_00: you can just charge right away. I think especially thanks to things like Stripe that are
[00:37:47] SPEAKER_00: making it easier. And so that, that, that's also made it a lot more friendly to new entrants.
[00:37:52] SPEAKER_00: There's also questions of geopolitics like, you know, it seems clear that we're not
[00:37:59] SPEAKER_01: and this globalized era and perhaps it's going to get much worse. And so investing in the
[00:38:05] SPEAKER_01: foundation, in the open AI of Europe might be a good idea. And like similarly China being an
[00:38:12] SPEAKER_01: entire different, different world. And so there's sort of a geo aspect of it. Yeah, it's interesting.
[00:38:18] SPEAKER_01: All of a sudden our geopolitics, you know, nerdiness is helpful, is useful.
[00:38:25] Adam, you know, we were talking about sort of human knowledge. Did you see yourself with
[00:38:28] SPEAKER_02: Poe kind of disrupting yourself in a sense or talk about the bet that you made with Poe in
[00:38:34] SPEAKER_02: the evolution there? You know, I think we saw Poe Moore as just an additional opportunity
[00:38:40] SPEAKER_00: than as disruption to Kora. The way we got to it was we in early 2022, we started experimenting with
[00:38:50] SPEAKER_00: using GPT-3 to generate answers for Kora. And we compared them to the human answers and sort of
[00:38:59] SPEAKER_00: realized that they weren't as good. But what was really unique was that you could instantly get
[00:39:04] SPEAKER_00: an answer to anything you wanted to ask about. And we realized it didn't need to be in public.
[00:39:11] SPEAKER_00: Your preference would be to have it be in private. And so we felt like there was just a new
[00:39:17] SPEAKER_00: opportunity here to let people chat with AI in private. And it seemed that you were also making a bet
[00:39:25] SPEAKER_02: on how the different players were going to let there was going to be. Yeah, yeah. So it was also a bet
[00:39:30] SPEAKER_00: on diversity of model companies, which took a while to play out. But I think now we're getting
[00:39:36] SPEAKER_00: the point where there's a lot of models. There's a lot of companies, especially when you go across
[00:39:41] SPEAKER_00: modalities, you think about image models, video models, audio models, especially the reasoning,
[00:39:48] SPEAKER_00: research models are diverging agents or starting to be their own source of diversity. So we're lucky
[00:39:55] SPEAKER_00: to now be getting into this world where there's sort of enough diversity for a general interface
[00:40:01] SPEAKER_00: aggregator to make sense. But yeah, it was a bet early on. We kind of...
[00:40:07] SPEAKER_00: It's surprising, actually, that even not particularly technical consumers actually do use multiple
[00:40:15] SPEAKER_01: AI's. They didn't expect that. People only use Google. They never looked at Google and then Yahoo
[00:40:24] SPEAKER_01: or very few people did. But now you talk to just average people and they'll say, yeah, I used
[00:40:30] SPEAKER_01: chat a few more so at times, but Gemini is much better at these types of questions. So yeah,
[00:40:34] SPEAKER_01: interesting. The sophistication of consumers have gone on. And even people saying that they've
[00:40:38] SPEAKER_02: just personalities and they resonate with Claude more or whatever. I want to turn back to this point
[00:40:47] SPEAKER_02: we said earlier about... Kind of talking about dark matter. Yeah, we're going to brute force. There's
[00:40:52] SPEAKER_02: a lot of knowledge that people have that's not categorized yet. And it's not just testing
[00:40:58] SPEAKER_02: knowledge. It's actually knowledge that you could ask them about and they could describe it.
[00:41:03] SPEAKER_02: Because one question people have with LMS is like, we've already trained the whole internet. How
[00:41:07] SPEAKER_02: much more knowledge is there? Is it like 10X? Is it like a thousand? What is your intuitive sense of
[00:41:16] SPEAKER_02: if we do brute force it and though this whole machine that gets all the knowledge out of humans
[00:41:22] SPEAKER_02: onto a data set that we can then implement? How do we think about the upside from there?
[00:41:29] SPEAKER_00: I think it's very hard to quantify, but there's a massive industry developing around
[00:41:37] SPEAKER_00: getting human knowledge into the form where AI can use it. So this is things like
[00:41:44] SPEAKER_00: scale AI, surge, Mercore, but there's a massive long tail of other companies just getting started.
[00:41:56] As intelligence gets cheaper and cheaper and more and more powerful, the bottleneck I think
[00:42:04] SPEAKER_00: is increasingly going to be on the data and what do you need to create that intelligence?
[00:42:11] SPEAKER_00: And so that's going to cause more and more of this to happen. It might be that people can make
[00:42:19] SPEAKER_00: more and more money by training AI. It might be that more and more of these companies get started
[00:42:27] SPEAKER_00: or it might be that there's other forms of it. But I think it's going to be the sort of like
[00:42:32] SPEAKER_00: that the economy is going to naturally value whatever the AI can't do.
[00:42:37] SPEAKER_00: What is the framework for what it can't do?
[00:42:42] SPEAKER_02: I know you could ask an AI researcher, they might have a better answer, but to me,
[00:42:51] there's just information that's not in the training set. And that is something that's inherently
[00:42:59] SPEAKER_00: going to be something AI can't do. There will be the AI will get very smart. It can do a lot
[00:43:06] SPEAKER_00: of reasoning. It could prove every math theorem at some point if it starts from some axioms that
[00:43:13] SPEAKER_00: you give it. But if it doesn't know how did this particular company solve this problem 20 years
[00:43:22] SPEAKER_00: ago, if that wasn't in the training set, then only a human who knows that is going to be able to
[00:43:28] SPEAKER_00: answer that question. And so over time, how do you see Quora interfacing? How are you running
[00:43:36] SPEAKER_02: these in parallel? How do you think about this? Yeah, so I mean, Quora focuses on human knowledge
[00:43:41] SPEAKER_00: and letting people share their knowledge. And that knowledge may be helpful for, you know,
[00:43:50] SPEAKER_00: it's helpful for other humans. And it's also helpful for AI to learn from. We have relationships
[00:43:57] SPEAKER_00: with some of the AI labs. And we're going to sort of play the role. Quora will play the role
[00:44:04] SPEAKER_00: that it is meant to play in this ecosystem, which is a source of human knowledge. At the same time,
[00:44:12] SPEAKER_00: AI is making Quora a lot better. We've been able to make major improvements in moderation,
[00:44:19] SPEAKER_00: inequality, and in ranking answers and just improving the product experience. So it's gotten a lot
[00:44:30] SPEAKER_00: better by applying AI to it. Yeah. And I'm going to talk about your future as well. Obviously,
[00:44:36] SPEAKER_02: you know, you had this business for a long time. You know, focus on developers at one point,
[00:44:40] SPEAKER_02: you're targeting, you know, a non-profit is no. Exactly. The end tech market, I believe, you're
[00:44:45] SPEAKER_02: two with three million and revenue reported. And then, you know, recently, tech run, I know it's
[00:44:49] SPEAKER_02: outdated, but I think it reported to like 150 million. I know it's higher. So you've had this
[00:44:54] SPEAKER_02: incredible growth as you've shifted the business model and the customer segment. How do you think
[00:45:00] SPEAKER_02: about the future of Repplet? I think, I think, a, Karpathi recently said that it's going to be the
[00:45:07] SPEAKER_01: decade of agents. And I think that's absolutely right. It's as opposed to like a prior modalities
[00:45:15] SPEAKER_01: of AI, like when AI first came to coding, it was autocomplete with a cool pilot. Then it became sort
[00:45:25] SPEAKER_01: of chat, which had to be then I think cursor innovated on this composer modality, which is like
[00:45:33] SPEAKER_01: editing like large chunks of files, but that's it. I think Repplet, what Repplet innovated is
[00:45:39] SPEAKER_01: is the agent and the idea of like not only editing code, provisioning infrastructure,
[00:45:46] SPEAKER_01: like databases, doing migrations, connecting to the cloud, deploying, having the entire debug loop,
[00:45:54] SPEAKER_01: like executing the code, running tasks. And so just like the entire development lifecycle loop
[00:46:01] SPEAKER_01: happening inside an agent, and that's going to take a long time into a chart. So we're agent
[00:46:07] SPEAKER_01: in beta came September 2024. And it was first of its kind that did this both code and infrastructure.
[00:46:14] SPEAKER_01: But it was fairly janky, didn't work very well. And then agent V1 around December
[00:46:22] took another generation models. So you go to from claw 3.5 to 3.7. 3.7 was the first
[00:46:31] model that really knew how to use a computer, a virtual machine. So unsurprisingly, it was the first
[00:46:39] SPEAKER_01: also computer use model. And these things have been moving together. And so with the every generation
[00:46:46] SPEAKER_01: of models we see we find new capabilities. And you know, agent V2 improved on autonomy a lot.
[00:46:53] SPEAKER_01: agent V1 could run for like two minutes, agent V2 ran for 20 minutes. Agent 3 we advertise it
[00:47:01] SPEAKER_01: as running for 200 minutes. It just felt like it should be symmetrical, but like it's actually runs
[00:47:06] SPEAKER_01: kind of indefinitely. Like we've had users running it for 20 plus hours. And the main
[00:47:12] SPEAKER_01: idea there was that if we put a verify on the loop, I remember reading deep seek a paper from
[00:47:18] SPEAKER_01: Nvidia about how they used deep seek to write CUDA kernels. And they were able to run deep seek for
[00:47:27] SPEAKER_01: like 20 minutes if they put a verify on the loop, like being able to run tests or something like that.
[00:47:33] SPEAKER_01: And I thought, okay, so what kind of verify can we put on the loop? Obviously you can put unit tests,
[00:47:38] SPEAKER_01: but unit tests doesn't really capture whether the app is working or not. So we started kind of digging
[00:47:42] SPEAKER_01: into computer use and whether computer use was going to be able to test apps. Computer use is
[00:47:47] SPEAKER_01: very expensive and it's actually kind of still very buggy. And like Adam talked about that's going to be
[00:47:53] SPEAKER_01: a big area of improvement that'll unlock a lot of applications. But we ended up building our own
[00:47:57] SPEAKER_01: framework with like bunch of hacks and some some AI research and Rappless computer use I think
[00:48:04] SPEAKER_01: testing models. I think one of the best. And and once we put that into the loop, then you can
[00:48:12] SPEAKER_01: put Rapplet in high autonomy. So we have an autonomy scale. You can you can you can choose your autonomy
[00:48:19] SPEAKER_01: level. And then it just writes the code goes and tests the applications. If there's a bug, it reads the
[00:48:25] SPEAKER_01: error log and like writes the code again and it can go for for for hours. And I've seen people build
[00:48:31] SPEAKER_01: amazing things by letting it run for for a long time. Now that needs to continue to get better. That needs to
[00:48:38] SPEAKER_01: to get cheaper and faster. So it's not necessarily a point of pride to run for a lot longer. Like it should
[00:48:45] SPEAKER_01: be as fast as possible. So we're working on that. Agent for there's a bunch of ideas that are
[00:48:53] SPEAKER_01: going to be coming out agent for but one of the big things is you shouldn't be just like waiting for
[00:48:59] SPEAKER_01: that one feature that you requested. You should be able to work on a lot of different features.
[00:49:04] SPEAKER_01: So the idea of like parallel agents is very interesting to us. So you know, you ask for a login page,
[00:49:10] SPEAKER_01: but you could also ask for a stripe checkout and then you ask for an admin dashboard. The AI should
[00:49:16] SPEAKER_01: be able to figure out how to paralyze all these different tasks or sometimes they're not
[00:49:21] SPEAKER_01: paralyzeable, but should also be able to do merge across the code. So being able to do collaboration
[00:49:28] SPEAKER_01: across AI agents is very important. And that way the productivity of a single developer goes up by a lot.
[00:49:35] SPEAKER_01: Right now, even when you're using Cloud Code, of course, or others, there isn't a lot of
[00:49:39] SPEAKER_01: parallels I'm going on. But I think the next boost in productivity is going to come from
[00:49:46] SPEAKER_01: sitting in front of programming environment like Repplet and being able to manage
[00:49:51] SPEAKER_01: tens of agents. Maybe we have some point hundreds, but you know, at least, you know, five, six, seven,
[00:49:55] SPEAKER_01: eight, nine, ten agents, all different, all do you know, working in different parts of your product.
[00:50:01] SPEAKER_01: I also think that UI and UX could use a lot of work in terms of right now, you're trying to
[00:50:13] SPEAKER_01: translate your ideas into just like texture representation. I'm just like a like a PRD, right?
[00:50:21] SPEAKER_01: What product managers do, right? So product descriptions, but product descriptions that don't,
[00:50:26] SPEAKER_01: it's really hard. And you see in a lot of tech companies, it's really hard to align on the exact
[00:50:31] SPEAKER_01: features, because it's like language is fuzzy. And so I think there's a there's a world in which
[00:50:36] SPEAKER_01: you're interacting with the eye in a more multimodal fashion. So open up like a whiteboard and
[00:50:41] SPEAKER_01: being able to draw and like diagram with AI and and really work with it like you work with a human.
[00:50:49] SPEAKER_01: And then the next stage of that, having like better memory, better memory inside the project,
[00:50:57] SPEAKER_01: but also across project, and perhaps having different instantiations of replete agents that,
[00:51:03] SPEAKER_01: you know, that this this agent is really good at like Python data science because
[00:51:10] SPEAKER_01: you know, it has all the information and skills and memories of about my company,
[00:51:15] SPEAKER_01: what it's done in the past. So I'll have a data analysis like sort of replete agent and
[00:51:20] SPEAKER_01: I'll have like a front end replete agent and they have memory over multiple projects and over time
[00:51:25] SPEAKER_01: and over interactions. And maybe they sit in your slack like a like a worker and you can like talk
[00:51:30] SPEAKER_01: to them. So again, like I can I can keep going for another 15 minutes about a roadmap that could
[00:51:36] SPEAKER_01: span like three to four to five years, perhaps. And so, but this this agent, this agent fees that
[00:51:42] SPEAKER_01: we're in is just there's so much work to do and it's it's it's going to be a lot of fun. Yeah,
[00:51:49] it's I was talking to one of our mutual friends, one of the co founders of one of these big
[00:51:54] SPEAKER_02: productivity companies and he leads a lot of their R&D and he's like, man, during the week,
[00:51:59] SPEAKER_02: these days, I'm not even talking to humans anymore as much. I'm just like, it's just,
[00:52:03] SPEAKER_02: you know, using all these agents to build. So it's it's living in the future to some degrees already
[00:52:08] SPEAKER_02: in the present. There's something interesting about that and that are people talking to each other
[00:52:13] SPEAKER_01: less at companies. And is that a bad thing? So it's, you know, I think I started to think more about
[00:52:21] SPEAKER_01: the second order of facts of things like that. You know, we'll make it awkward for like again,
[00:52:29] SPEAKER_01: the new grads, I feel so bad for them. Like, you know, if if people are not sharing as much knowledge
[00:52:35] SPEAKER_01: between each other or it's like, it's not culturally easy to go ask for help because like,
[00:52:42] SPEAKER_01: you should be able to use AI agents. There's some there's some cultural forces that I think need
[00:52:47] SPEAKER_01: to be reckoned with. Yeah. I get a lot of tough cultural forces for Zoomers these days. Yes.
[00:52:54] That's getting towards closing here. Obviously, you guys are, you know, focused on running your
[00:52:58] SPEAKER_02: companies, but to stay current on the AI ecosystem, you you guys also make an angel investments as well.
[00:53:04] SPEAKER_02: Where are you guys most most excited? You know, we haven't talked about robotics. Are you guys
[00:53:10] SPEAKER_02: bullish on robotics in the near term or any emerging categories or use cases or spaces that
[00:53:15] SPEAKER_02: you're looking to make more investments in or you have made some? I think vibe coding generally
[00:53:20] SPEAKER_00: is just unbelievably like high potential. Just the idea that all this, you know, this, this
[00:53:28] SPEAKER_00: underhyped even still. I think so. I think, you know, just opening up the potential of
[00:53:35] SPEAKER_00: software to the mainstream of, you know, every everyone. I think that and yeah, and actually,
[00:53:42] SPEAKER_00: I think one reason I think it's underhyped is that the tools are still very far from what you can
[00:53:48] SPEAKER_00: do as a professional software engineer. And if you imagine that they're going to get there and I
[00:53:53] SPEAKER_00: think there's no reason why they wouldn't, it'll take a few years, but then it's like everyone
[00:54:00] SPEAKER_00: in the world is going to be able to create any things that would have taken a team of 100 professional
[00:54:08] SPEAKER_00: software engineers that's just going to massively open up opportunities for for everyone. So I think
[00:54:14] SPEAKER_00: Replay is like a great example of this, but I think it's also going to that there will be cases
[00:54:20] SPEAKER_00: other than just like building applications that this also creates. By the way, just on the note,
[00:54:26] SPEAKER_02: if you were going to Stanford or Harvard, you know, today, 2025, just enter it, would you major again
[00:54:32] SPEAKER_02: in computer science or just focus on building something? I think I would. I mean, I, I, I, I
[00:54:38] SPEAKER_00: I went to college starting in 2002 and it was right after the dot com bubble had burst and
[00:54:45] SPEAKER_00: there's a lot of pessimism and I remember my, my roommate, his parents had told him like,
[00:54:52] SPEAKER_00: don't study computer science, even though that was, that was something he really liked. And I just
[00:54:57] SPEAKER_00: kind of did it because I, I liked it. And I think that I think that it's definitely like the job
[00:55:07] SPEAKER_00: market is worse than it was a few years ago. At the same time, I think having these skills to
[00:55:14] SPEAKER_00: understand the sort of fundamentals of what's possible with algorithms and data structures,
[00:55:19] SPEAKER_00: I think that actually really helps you in, in managing agents when, when you're using them.
[00:55:26] SPEAKER_00: And I, I'm guessing that it will continue to be a valuable skill in the future. I also think
[00:55:31] SPEAKER_00: the other question is like, what else are you going to study? And every single thing you could
[00:55:35] SPEAKER_00: imagine, there's an argument for why it's going to be automated. So I think you might as well
[00:55:41] SPEAKER_00: study what you enjoy. And, and, and I think this is as good as, as anything. Yeah, I, um,
[00:55:47] SPEAKER_01: I think there's a lot to, to get excited by. One thing, I say, maybe kind of random, but like,
[00:55:53] SPEAKER_01: I could really fire it up to see like, Matt's science experiments, like the deep seek OCR that came
[00:55:58] SPEAKER_01: out of there. Did you see it? It's, it's wild where, um, correct me if I'm wrong because I only
[00:56:05] SPEAKER_01: looked at it briefly, but basically you can get a lot more economical with a context window.
[00:56:10] SPEAKER_01: If you like have a screenshot of the text, instead of a blocking text,
[00:56:16] SPEAKER_00: I'm not, I'm not the right person to be correcting you. But like, it's, there's, there's definitely
[00:56:22] SPEAKER_00: some really interesting things. Yeah, I saw another thing on Hacken is that they were,
[00:56:27] SPEAKER_01: you know, text diffusion, where someone made a text diffusion model by, instead of doing,
[00:56:34] SPEAKER_01: go saying denoising, he would take like a single birth instance and like try to, you know,
[00:56:39] SPEAKER_01: mask different words and, uh, and just predict like, the different tokens and, um,
[00:56:45] SPEAKER_01: and so we have a lot of components. And I don't think people think a lot about that, you know,
[00:56:50] SPEAKER_01: we have now the, you know, base pre-trained models. We have the, all these RL reasoning model models.
[00:56:56] SPEAKER_01: We have the, uh, you know, encoded decoder models. We have diffusion models. We have,
[00:57:02] SPEAKER_01: there's all these different things like just like, you know, you mix them in different ways.
[00:57:07] SPEAKER_01: Yeah. Uh, I feel like there isn't a lot of that. And be great. It'd be great if a, like,
[00:57:12] SPEAKER_01: a new research company just like comes out and is like not trying to, like compete with OpenEI
[00:57:17] SPEAKER_01: and things like that. But instead, uh, is just trying to like, discover how to put these
[00:57:22] SPEAKER_01: different components together in order to create a new flavor of these models. Yeah. Encryptor,
[00:57:26] SPEAKER_01: they talk about composability and like mixing primitives together. And yeah, maybe there needs to
[00:57:31] SPEAKER_02: be more expectation. There was less playing around. I found like, there is like, I remember in the,
[00:57:35] SPEAKER_01: like, web 2.0 era when we were like playing around with JavaScript, what browsers could do,
[00:57:41] SPEAKER_01: and what web workers could do, whatever. There was a lot of like really interesting weird experiments.
[00:57:45] SPEAKER_01: I mean, Repplet was born out of that. The original version of Repplet in open source pre-pre-the company,
[00:57:51] SPEAKER_01: which my interest was like, can you compile C to JavaScript? That was like one of the interesting
[00:57:57] SPEAKER_01: things that that became was and by the time it was, uh, and scripted it was like such a, such a nasty
[00:58:02] SPEAKER_01: hack. But I think there's so much, I think we're an era of Silicon Valley where it's like very,
[00:58:11] very, get rich driven. And that makes me a little sad. And that's partly why I moved the company out
[00:58:18] SPEAKER_01: of us. I feel like the culture in us has, has gone maybe to maybe I, I wasn't there, but like,
[00:58:25] SPEAKER_01: during the dot com era, a lot of people talked about how it's sort of like, get rich fast or the crypto
[00:58:30] SPEAKER_01: thing. So I feel like there needs to be a lot more tinkering and I would love to see more of that
[00:58:36] SPEAKER_01: and more companies getting funded that are trying to just do something a little more novel, even if
[00:58:42] SPEAKER_01: it doesn't mean like it fundamentally new, new model. Last question. Um, I'm glad you've, uh,
[00:58:49] SPEAKER_02: been into consciousness for a long time. Are you bullish that we will via some of this AI work,
[00:58:53] SPEAKER_02: or just some scientific progress elsewhere, make some progress and understand in, in, uh,
[00:58:59] SPEAKER_02: you know, getting across this, this hard problem or, you know, something happened recently,
[00:59:04] SPEAKER_01: which is interesting. A clot 4.5, uh, seem to have to become more aware of its context length.
[00:59:14] SPEAKER_01: So as it gets closer to the end of the context, it starts becoming becoming more economical with
[00:59:19] SPEAKER_01: tokens. It also, it looks like it's awareness when it's being read teamed or in test environment,
[00:59:26] SPEAKER_01: like jumped significantly. And so there's something happening there that's quite interesting.
[00:59:31] SPEAKER_01: Now, I think, uh, in terms of, you know, the, the question of, of consciousness,
[00:59:39] SPEAKER_01: it is still fundamentally not a scientific question. And there is a sort of, uh, we've given up
[00:59:46] SPEAKER_01: on trying to make a scientific, but I think it, uh, I think this is also, uh, the problem that I
[00:59:54] SPEAKER_01: talked about with all the energy going into LMS, um, uh, no one is trying to really think about the
[01:00:02] SPEAKER_01: true nature of intelligence, true nature of, uh, consciousness. Um, and there's a lot of,
[01:00:10] SPEAKER_01: really core, core questions. Like one of my favorite one is, uh, the, uh, Roger Penrose,
[01:00:19] SPEAKER_01: uh, Emperor's New Mind, where he wrote a book about how everyone in the sort of philosophy of mind
[01:00:28] SPEAKER_01: space, uh, and perhaps the larger scientific ecosystem started thinking about the brain in terms
[01:00:35] SPEAKER_01: of a computer. And in that book, he tried to show that it fundamentally is impossible for the brain
[01:00:40] SPEAKER_01: to be, uh, a computer because, uh, humans, uh, are able to do things that cheering machines
[01:00:50] SPEAKER_01: cannot do or cheering machines like fundamentally get, get stuck on such as, um, uh, you know, just, uh,
[01:00:59] SPEAKER_01: basic logic, um, puzzles, uh, that we're able to kind of detect, but like, there's no way to
[01:01:08] SPEAKER_01: encode that in a, in a, in a cheering machine, for example, like this statement is false, you know,
[01:01:14] SPEAKER_01: there's like old logic puzzles. Um, and, uh, anyways, it's like a complicated argument, but
[01:01:23] SPEAKER_01: if you read that book or, or many others, uh, there's like a core strain of arguments in the
[01:01:30] SPEAKER_01: theory of mind about how, uh, computers, uh, are fundamentally different from, from human intelligence.
[01:01:39] SPEAKER_01: Uh, and so, yeah, I, I mean, I haven't really, I've been very busy, so I haven't really updated my
[01:01:44] SPEAKER_01: thinking too much about that, but, but I think there's, there's a, there's a, there's a huge field of
[01:01:50] SPEAKER_01: study there that is not being studied. If you were a freshman, uh, entering college today,
[01:01:55] SPEAKER_01: would you study philosophy? I would do that. I would definitely study philosophy of mind. I would
[01:01:59] SPEAKER_01: probably go into neuroscience, uh, because I think those are the core questions that are kind of,
[01:02:03] SPEAKER_01: become very, very important as they are, I kind of continue to see more of jobs in economy and
[01:02:08] SPEAKER_01: things like that. That's a great place to wrap. I'm John. I don't think I'm gonna podcast. Thank you. Thank you.