# The 2045 Superintelligence Timeline: Epoch AI’s Data-Driven Forecast

**Podcast:** A16z Podcast
**Date:** 2025-11-24
**Video ID:** TbFSGiQdCaw
**Video URL:** https://www.youtube.com/watch?v=TbFSGiQdCaw

---

[00:00:00] people are spending a lot on these models. They're presumably doing this because they're getting
[00:00:05] SPEAKER_03: valued from them. You can maybe argue like, oh well I don't think that value is real. I think
[00:00:10] SPEAKER_03: people are just playing around with whatever they're paying for. It's a pretty solid sign.
[00:00:15] SPEAKER_03: We're almost giving you the useful answer. I don't think it's a bubble because it's not burst yet.
[00:00:20] SPEAKER_03: When it's burst yet, then you'll know it's a bubble. People often make the case, oh yeah,
[00:00:24] SPEAKER_02: it hasn't been profitable yet and they're spending more to make it profitable. The reality
[00:00:28] SPEAKER_02: will have paid off the cost of all the development they've done in the past very soon.
[00:00:33] It's just that they're doing more development for the future. Will they regret that spending?
[00:00:37] SPEAKER_03: How much are they spending? You can look at Nvidia and how much they're selling each year and you
[00:00:42] SPEAKER_03: can see whether it keeps on growing and you can see whether this fuss is kind of looking good
[00:00:46] SPEAKER_03: to continue. Math team is unusually easy for AI. I'm good to be honest. People often
[00:00:52] SPEAKER_02: think claims about it being like this, you know, intuitive, deep thing that it would mean that AI
[00:00:56] SPEAKER_02: has achieved something, some huge level of intelligence for it to solve. I think in practice,
[00:01:01] SPEAKER_02: this is just like, you know, making a piece of art. It turns out to be farther down the capability
[00:01:06] SPEAKER_02: stream than people might have guessed. We sort of had this with chess decades ago, right? Like,
[00:01:11] SPEAKER_03: computers solved chess very well and everyone was thinking of this as the pinnacle of reasoning
[00:01:17] SPEAKER_03: and everyone as there is what kind of concluded by, oh well, of course, computers can do chess.
[00:01:21] SPEAKER_02: The interesting scenario to think about, you know, 20% chance, 30% chance, something like this will
[00:01:26] SPEAKER_02: happen in the next decade is like, you know, a 5% increase in unemployment over a very short period
[00:01:32] SPEAKER_02: of time, like six months due to AI. The public's reaction to this will determine a lot. There will be
[00:01:36] SPEAKER_02: very, very strong feelings about AI once this happens. I think there will be a bunch of very strong
[00:01:41] SPEAKER_02: consensus on what to do or on things that we don't normally think of as things that people are
[00:01:46] SPEAKER_02: considering. I know when this happened with COVID, there was a several trillion dollar stimulus
[00:01:51] SPEAKER_02: package. And a matter of weeks to days, it was breakneck speed. I don't know what that will look
[00:01:56] SPEAKER_02: like for AI. But I think it's like everything else in AI. It's like exponential, which means it
[00:02:02] SPEAKER_02: will pass the point of people sort of care about it to people really care about it quite fast.
[00:02:07] SPEAKER_02: I just expect wherever we end up, there will be this certain thing which we would have considered
[00:02:12] SPEAKER_02: unimaginable a year ago. Guys, there's a lot of conversation about the macro. Are we in a bubble?
[00:02:24] SPEAKER_01: How should we even think about this question? We're going to get into forecasting later on. But
[00:02:28] SPEAKER_01: why don't you just take your first stab at how you approach such a big, general question?
[00:02:32] SPEAKER_01: Yeah, I mean, for me, at least, the way that I thought about this a little bit is I look at kind of
[00:02:39] SPEAKER_03: the big indicator being how much people are spending on stuff like compute. And I guess maybe some
[00:02:46] SPEAKER_03: sense of will they regret that spending? That's relevant. But how much are they spending thing?
[00:02:51] SPEAKER_03: Like you can see, you can look at Nvidia and how much they're selling each year and you can see
[00:02:55] SPEAKER_03: whether it keeps on growing and you can see whether stuff is kind of looking good to continue.
[00:03:00] SPEAKER_03: The will they regret it's side? I mean, that's just to the sea, right? Like we'll actually have to
[00:03:06] SPEAKER_03: see it does seem as if most compute gets spent on inference that companies don't so far regret
[00:03:12] SPEAKER_03: like using to offer their products. So I mean, on that side, I'm like thinking not to bubbly yet.
[00:03:21] SPEAKER_03: But yeah, I low confidence. So there's other stuff to think about.
[00:03:26] Right now, the amount of money companies are actually earning in profit, not including the cost
[00:03:30] SPEAKER_02: to develop the models initially, seems to be like very positive, such that if they stop developing
[00:03:35] SPEAKER_02: bigger and bigger models and just stick with the ones they've had, they'd have earned a profit
[00:03:40] SPEAKER_02: pretty quickly at the current margins. And in this sense, it doesn't seem bubbly. On the other hand,
[00:03:46] SPEAKER_02: at any given time, they're investing in building even larger and larger models. And if that goes
[00:03:53] SPEAKER_02: well, then they'll earn more money and if that doesn't go well, then no matter how profitable they
[00:03:58] SPEAKER_02: are right now, it'll be a small amount of money compared to how much they would have spent.
[00:04:04] SPEAKER_02: So it's like, I think right now there are not financial signs that things are actually
[00:04:10] SPEAKER_02: that there's a bubble. A lot of people worrying about bubbles just like aren't necessarily used to
[00:04:15] SPEAKER_02: the level of spending and just like the level of success that sort of happened and scaling.
[00:04:22] SPEAKER_02: But if there is a bubble, it could happen very suddenly and be pretty bad. So
[00:04:28] yeah, I think we're almost giving you the useful answer. I don't think it's a bubble because it's
[00:04:33] SPEAKER_03: not burst yet. When it's burst, yes, and you'll know it's a bubble. Yeah, I do think like there's
[00:04:39] you could imagine a world at which there's all the spending and the current level of success
[00:04:44] SPEAKER_02: does not like people have to make the case, oh, AI hasn't been profitable yet and they're spending
[00:04:49] SPEAKER_02: more to make it profitable. But right now it's not making anything. In reality, they're making,
[00:04:55] SPEAKER_02: you know, they'll have paid off the cost of all of the development they've done in the past very
[00:04:59] SPEAKER_02: soon. It's just that they're doing more development for the future. So I think like there is this
[00:05:05] SPEAKER_02: like underlying financial success so far that I wouldn't expect to see if there are the very
[00:05:11] SPEAKER_02: least and obvious bubble. Yeah, that does seem very relevant. People are spending a lot on these
[00:05:18] SPEAKER_03: models that presume it like, you know, uses to use them. They're presumably doing this because
[00:05:23] SPEAKER_03: they're getting value from them. You can maybe argue like, oh, well, I don't think that values
[00:05:28] SPEAKER_03: really. I think people just playing around whatever they're paying for it. That's a pretty solid
[00:05:34] SPEAKER_03: sign. I guess one quick question on related to this is like you're talking the report of the AI
[00:05:39] SPEAKER_00: in 2030. Basically, you haven't seen signs of basically these models kind of plateauing or like
[00:05:47] SPEAKER_00: the capabilities keep increasing and you have the benchmarks you have. The amount of data that is
[00:05:51] SPEAKER_00: going the amount of compute. Do you think faces or parts of the models are plateauing though?
[00:05:56] SPEAKER_00: Like for instance, pre-training. Are we seeing some sort of plateauing in that or do you think
[00:06:01] SPEAKER_00: people are still exploring some innovations in that stage and curious on what do you think about that?
[00:06:06] SPEAKER_00: Yeah, I think this gets a bit harder to look at. Like we get to an area where there isn't as much
[00:06:14] SPEAKER_03: public data to say a lot, right? It seems as if pre-training is comparatively less
[00:06:20] SPEAKER_03: of a focus than it was before, partly because you have this exciting new direction of
[00:06:26] SPEAKER_03: well, new, new-ish direction of post-training where they've done so much about reasoning, whatever.
[00:06:32] SPEAKER_03: But then I don't necessarily take those evidence of like, oh no, and that means pre-training,
[00:06:36] SPEAKER_03: you couldn't sc� further, whatever. It seems as if there is meaningfully more data out there.
[00:06:41] SPEAKER_03: It seems as if plausibly like even a load of this stuff is quite synergistic. You develop a
[00:06:47] SPEAKER_03: better model, you use post-training stuff to make it better. You get a load of data of the model
[00:06:53] SPEAKER_03: actually being used successfully or not. A load of that can probably go into pre-training next time.
[00:07:00] You aren't projecting a software only singularity where AI is able to automate AI research,
[00:07:05] SPEAKER_01: but it's an automated feedback loop. Why not?
[00:07:08] SPEAKER_01: Yeah, I mean, I guess like I might say this and I'll be at the office same
[00:07:12] SPEAKER_03: more in a sec. For me, it's like that report. It's no one person's kind of, oh this is like
[00:07:21] SPEAKER_03: the forecast, this is the prediction, right? This report very specifically looks at what are the
[00:07:26] SPEAKER_03: current trends? Are there reasons that they clearly like couldn't continue or might not?
[00:07:31] SPEAKER_03: And if they do continue, where do they lead? I think whether you see this self-improvement thing,
[00:07:38] SPEAKER_03: that's very hard to do from a sort of trend extrapolation basis, right? Like currently,
[00:07:43] SPEAKER_03: AI stuff does help AIR and do at least a little in terms of stuff like coding or selecting your data
[00:07:50] SPEAKER_03: sets and correcting those, whatever, but it's quite hard to actually measure and it's not really
[00:07:55] SPEAKER_03: helping in some big way like this kind of self-improving thing would suggest.
[00:08:00] SPEAKER_03: There are reasons that you might think it could be very hard. People have discussed before,
[00:08:06] SPEAKER_03: how possibly, you know, if stuff just just depend a lot on scaling up compute, then maybe
[00:08:13] SPEAKER_03: automating a load of the R&D isn't that helpful. I find that somewhat compelling, but I think
[00:08:19] SPEAKER_03: it's also just, it's pretty uncertain, it's hard to speculate about something that's quite
[00:08:25] SPEAKER_03: out of regime like that. One thing that needs to happen in order for a software only singularity
[00:08:32] SPEAKER_02: to occur is you need to be in this world where scaling up the amount of researcher R&D time,
[00:08:37] SPEAKER_02: basically, allows you to like improve AI enough that it makes up for the lack of being able to
[00:08:44] SPEAKER_02: scale experimental compute or pre-training. I think that something you would expect to see if
[00:08:50] SPEAKER_02: this were the case is, you know, maybe not that much experimental compute being used in practice,
[00:08:54] SPEAKER_02: and instead all of the money is going towards researchers. Now there's a very good case that there's
[00:08:58] SPEAKER_02: a very large amount of money going towards researchers, but as far as we can tell experimental compute,
[00:09:03] SPEAKER_02: which you seem to need to do research, is also is receiving a similar amount of money, and that in
[00:09:09] SPEAKER_02: fact, it's receiving many times more money than the final training runs that are actually
[00:09:13] SPEAKER_02: of the models that are actually being released. I think this is, in my mind, is a strong update
[00:09:21] SPEAKER_02: towards, oh, you actually need this, you need to do very large scale experiments to do research,
[00:09:25] SPEAKER_02: and that we don't really have good evidence that researchers and just researchers would be able
[00:09:31] SPEAKER_02: to speed things up without doing more experiments. However, the actual, they're like pretty good
[00:09:40] SPEAKER_02: arguments on either side of this. I tend to lean towards, no, you actually need to do more experiments,
[00:09:44] SPEAKER_02: and that means you can't get this software only singularity, but I don't think the people who
[00:09:49] SPEAKER_02: claim otherwise are like crazy. I think they're making some, they have very reasonable differences,
[00:09:55] SPEAKER_02: and we're both speculating on something where the data is currently pretty sparse.
[00:10:01] Actually related to that, what do you think on, so if you have some of the exploration that
[00:10:07] SPEAKER_00: researchers are trying, I mean, obviously people are exploring a lot with RL, trying to go beyond
[00:10:11] SPEAKER_00: verifiable domains, and what do you think about the argument, for instance, that grading descent
[00:10:17] SPEAKER_00: is really good on learning, and the current data that you're giving, if you keep training this over
[00:10:22] SPEAKER_00: and over, it's going to start forgetting things that it was trained before, like catastrophic forgetting,
[00:10:28] SPEAKER_00: and there is this argument, like, well, kids don't learn that way, like, maybe there's some
[00:10:33] SPEAKER_00: imitation learning that kids do, maybe there's some sort of exploration that they do, and I wonder
[00:10:38] SPEAKER_00: what you think about it, and it sounds right, like if kids really would just learn on imitation learning,
[00:10:44] SPEAKER_00: far as it would have a great time just raising kids, but it seems like the reason why they have
[00:10:48] SPEAKER_00: such a hard time raising kids is because they explore all these different things. What do you think
[00:10:52] SPEAKER_00: about it, in terms of the algorithms and the things we need to keep improving this model
[00:10:56] SPEAKER_00: server and over, beyond the data and the computer? I am cautious about comparing the, like, how
[00:11:02] SPEAKER_02: AI's learned to how humans learn, not because I don't think they are comparable, but because I
[00:11:07] SPEAKER_02: think we know a lot more about how AI's learn right now, than we know about how humans learn,
[00:11:11] SPEAKER_02: and people like making sort of assumptions about how human learning works, and saying, oh,
[00:11:15] SPEAKER_02: AI doesn't do it that way, and I don't know, maybe that's true, maybe human kids learn via RL.
[00:11:26] SPEAKER_02: I think that, yeah, I don't have strong opinions on whether or not you need to change
[00:11:30] SPEAKER_02: to a method that's more like what we think kids do right now. I suspect people will find some
[00:11:35] SPEAKER_02: method that works to use the computer available because they've been able to do this in the past.
[00:11:40] Yeah, I'm also sort of reluctant. I guess as well, it's one of those things where
[00:11:46] SPEAKER_03: when we point to particular issues, like the example of catastrophic forgetting, it's sort of,
[00:11:54] well, okay, but as we've scaled up, we have managed to do quite well at like having models that
[00:12:01] SPEAKER_03: remember more and more things. This isn't to say that hence the problem is solved, hence we're done,
[00:12:06] SPEAKER_03: hence the more I would make an aggregation necessary or anything like that, but I'm not
[00:12:11] SPEAKER_03: exactly going to write it off. Yeah, I definitely don't think we've seen any slowdown yet in
[00:12:18] SPEAKER_02: capabilities from any of these concerns people have. I think that people always have these sorts of
[00:12:25] SPEAKER_02: concerns. I'm reluctant to believe any given one of them until this actually shows up in numbers
[00:12:31] SPEAKER_02: I can see on the graph, which I just don't think has happened yet. Dario and Thropic has said,
[00:12:38] SPEAKER_01: he said in March 2025 that within six months, AL or right, 90% of code, and of course that
[00:12:44] SPEAKER_01: hasn't happened yet. He also said, we have, we could have AI systems equivalent of a country of
[00:12:49] SPEAKER_01: geniuses in a data center as soon as 2026 or 2027. How do you evaluate why and Thropic is so bullish
[00:12:56] SPEAKER_01: or what is the crux of difference between what would they believe and perhaps what would you believe?
[00:12:59] SPEAKER_01: My model at least, which I don't know of, it's right, but what it is is that they think a bit more
[00:13:09] SPEAKER_03: like the people who believe in you automate R&D and that gives you very quick takeoff. So they see
[00:13:16] SPEAKER_03: it as like, yep, we're working on these AI's that are great for kind of research engineering type
[00:13:21] SPEAKER_03: coding and at some point they're going to be useful and that's going to rapidly accelerate us to
[00:13:26] SPEAKER_03: develop the next ones and then it's going to be quick progress. Yeah, I think that it's hard to tell
[00:13:36] SPEAKER_02: the extent to which I don't think we've gotten a lot of evidence that there's sort of views of
[00:13:42] SPEAKER_02: this like software only take off are wrong. Insofar as like they will taking a little bit longer to
[00:13:47] SPEAKER_02: get to like the minimum level of competence for AI to get you there definitely seems to be the case.
[00:13:52] SPEAKER_02: But it's hard to tell the extent to which we've actually had significant updates on this. I know
[00:14:00] SPEAKER_02: of Dorio often qualifies what he says by like saying as soon as or something like this. So this is
[00:14:07] SPEAKER_02: like maybe the more more so the faster timeline he gives all the more mature. Yeah, there has also been
[00:14:13] SPEAKER_03: anything sort of you know Talmud style commentary where people are carefully looking at his exact
[00:14:19] SPEAKER_03: wording and then a wording of other people's discussion of how many lines of code that are
[00:14:25] SPEAKER_03: generated by some teams that are interrupted are generated by quad code and whether this does or
[00:14:30] SPEAKER_03: doesn't satisfy what you said. So it gets a bit tricky. Yeah, I remember there was the paper from
[00:14:37] SPEAKER_00: the uplift paper that was claiming that actually models would slow you down. But I think like in
[00:14:42] SPEAKER_00: matter of law what models they were using at the time because I think they were pretty outdated by
[00:14:46] SPEAKER_00: the time the report came out and I mean in my personal experience you definitely become way faster
[00:14:51] SPEAKER_00: and it just also much more for you like you're just having the whole context on your code base. That's
[00:14:56] SPEAKER_00: such a huge advantage that I think for human just would be really hard to do. I mean far more than 90%
[00:15:03] SPEAKER_02: of the code I write is written by AI these days. But I know I'm not like the average coder at all.
[00:15:11] SPEAKER_02: But it's definitely I don't think it's like a wild prediction at this point that 90% of code is
[00:15:17] SPEAKER_02: going to be written by AI. I mean for all I know somewhere at OpenAI there's someone just you know
[00:15:23] SPEAKER_02: or that you know with Alpha Code doing evolutionary algorithms on having tons and tons of trials
[00:15:31] SPEAKER_02: trying to you know million shots some hard problem. But it's just like it's really unclear how many
[00:15:37] SPEAKER_02: lines of code are actually being written by AI right now. I don't think it's such a wild.
[00:15:42] SPEAKER_02: It's by a lot of like people's intuitive sense in terms of like I was 90% of the job of a programmer
[00:15:47] SPEAKER_02: being done by AI's definitely not. But there's this more complicated sense of like how much is
[00:15:53] SPEAKER_02: being written by AI probably not 90% but it's it's hard to tell. Yeah I think that ends with very
[00:16:00] SPEAKER_03: meaningful distinction. Yeah like if you were to measure how many lines of code are being
[00:16:06] SPEAKER_03: written quote unquote by like tab completion then it's probably quite high. But you don't necessarily
[00:16:12] SPEAKER_03: expect that that's taking on that much of the programmers really hard work. That uplift paper
[00:16:18] SPEAKER_03: that you mentioned like I find it really interesting and really good and it's also surprisingly
[00:16:23] SPEAKER_03: recent in a way like you know you mentioned are the models are outdated. I mean this was early 2025.
[00:16:28] SPEAKER_03: So these were models that people actually did think were helping them and in the paper they even
[00:16:32] SPEAKER_03: got them to say ahead of time like how much do you think this was video up and they said yeah I think
[00:16:37] SPEAKER_03: how much they then asked them often it's how much do you think this fed you up and they're yeah
[00:16:42] SPEAKER_03: yeah it fed me up and I feel it does reveal actually like it might be hard for us to judge whether
[00:16:49] SPEAKER_03: we were sped up or not. Yeah one thing that might be happening here is that a lot of the code that's
[00:16:54] SPEAKER_02: getting written by AI is code that wouldn't have been written otherwise so it's not really
[00:16:57] SPEAKER_02: speeding up things that would normally happen but you know there's a lot of simple graphs or
[00:17:02] SPEAKER_02: simulations I run that might have not gotten written otherwise and so it's it's hard to tell
[00:17:11] SPEAKER_02: exactly what's going on here in terms of the impacts I think at the end of the day the most
[00:17:15] SPEAKER_02: reliable indicator here is going to be how much money these people are making from programmers
[00:17:20] SPEAKER_02: and from you know subscriptions in general and it's a lot of money I think there's definitely
[00:17:24] SPEAKER_02: indications that people are finding a use for them and probably a decent amount of that uses for
[00:17:28] SPEAKER_02: coding but not exactly for the metric of doing 90% of an existing code is job. Yeah.
[00:17:36] Bology is this phrase it's been being used a lot which is AI is an end to end it's it's middle to
[00:17:42] SPEAKER_01: middle and maybe we just meant to imply that you know we're going to need a lot more human
[00:17:48] SPEAKER_01: involvement than some people you know typically think what is your mental model of what is
[00:17:55] SPEAKER_01: going to do for labor markets either on the sort of lower end and on the higher end in the next
[00:18:01] SPEAKER_01: you know decade let's say. Oh in the next decade like on the higher end I'm definitely like you know
[00:18:09] probably I expect new jobs to be created everyone could still be influencers but on the higher end
[00:18:15] SPEAKER_02: it's like there are not very good individual things that you can point to where it's very obvious
[00:18:22] SPEAKER_02: that AI can't automate that job at this point. Now you could argue okay but there's some unknowns
[00:18:28] SPEAKER_02: and I think it's like pretty reasonable but those unknowns we sometimes you know we AI gets up
[00:18:35] SPEAKER_02: against its limits and we figure out what they are and then it learns surpasses that and I don't
[00:18:40] SPEAKER_02: know at the higher end it definitely seems plausible that it could just automate all the basically
[00:18:44] SPEAKER_02: all of existing jobs with the exceptions of ones that require manual labor that people actually
[00:18:49] SPEAKER_02: care about being done by a human it's just like does not seem at all implausible to me that that
[00:18:56] SPEAKER_02: can happen or that that could happen very fast with the caveat there being like there's probably some
[00:19:05] SPEAKER_02: regulatory pushback if that happens. On the lower end I don't know it could just you know it could
[00:19:11] SPEAKER_02: be a bubble and doesn't have any impact. The thing I talk about when I'm talking about like the
[00:19:16] SPEAKER_02: the like interesting scenario to think about which I'm not I don't know you know 20% chance 30%
[00:19:21] SPEAKER_02: chance something like this will happen in the next decade is like you know a 5% increase in
[00:19:25] SPEAKER_02: unemployment over over a very short period of time like six months due to AI being released to
[00:19:30] SPEAKER_02: something that I think will have a very substantial impact on the world both in terms of how people
[00:19:36] SPEAKER_02: think about AI and sort of how much attention it gets and seems plausible to me but you know far
[00:19:44] SPEAKER_02: from guaranteed. Yeah I think I strongly agree with being just highly uncertain it seems very
[00:19:54] SPEAKER_03: plausible to me that you end up more or less kind of you know this generation actually is exactly
[00:20:00] SPEAKER_03: where we run out of progress it would be kind of crazy but it could happen and then it's like oh
[00:20:06] SPEAKER_03: everything is very much just generating more jobs for technical people to try to integrate it into
[00:20:12] SPEAKER_03: doing kind of useful but janky things for all of the existing work people do. The stuff where it
[00:20:19] SPEAKER_03: kind of becomes a crazy runaway thing that you can really automate large swaves of promote work
[00:20:26] SPEAKER_03: with I mean my time lens of I guess pretty a bit longer than the others but yeah I mean it seems
[00:20:32] SPEAKER_03: hard to rule out but something really big happens in a decade. Decade it's quite a long time.
[00:20:38] SPEAKER_02: I think I would be surprised if there were not 5% of jobs that exist now which AI has automated
[00:20:45] SPEAKER_02: away over the course of the next decade. I honestly have to be surprised if it's not 10% of the jobs
[00:20:50] SPEAKER_02: that exist now I think. How fast that happens and like the extent to which those people find other
[00:20:56] SPEAKER_02: jobs is something which I don't think I have seen compelling evidence for either way and probably
[00:21:04] SPEAKER_02: depends on how fast various things go and exactly what jobs are automated. I think that 10% over
[00:21:09] SPEAKER_02: the next 10% of current jobs seems like a pretty reasonable lower it's not quite my lower bound
[00:21:16] SPEAKER_02: but you know a pretty reasonable number over the next decade but this might not show up in overall
[00:21:21] SPEAKER_02: employment numbers. This is interesting. I mean definitely like the kind of to the extent there is
[00:21:30] SPEAKER_03: a mainstream economics view of this stuff it would probably be that automation happens at the level
[00:21:35] SPEAKER_03: of tasks rather than occupations and occupations can as a result you know go down quite a bit but
[00:21:43] SPEAKER_03: a lot of the time you're automating these like similar tasks across lots of jobs. I think this
[00:21:48] SPEAKER_03: is compatible with what you're saying it's just that some jobs get really hit by it. I don't know
[00:21:53] SPEAKER_03: I find it yeah quite hard to think about. I'm not sure what that even the historic base rate
[00:21:58] SPEAKER_03: for kind of jobs ceasing to exist is I know there are problems with this like the historic
[00:22:03] SPEAKER_03: employment data series there is actually quite a high I believe base rate of just the tasks in a
[00:22:09] SPEAKER_03: job changing jobs that sells changing jobs kind of going away coming in so yeah even this 5%
[00:22:17] SPEAKER_03: thing I don't know what to think yeah that would be like a big effect or kind of yeah that's
[00:22:20] SPEAKER_03: actually roughly the size of the fact you've already seen from something like software I don't know
[00:22:26] yeah I'm probably 5% of jobs that existed before software no longer exists it seems pretty
[00:22:32] SPEAKER_02: reasonable but I'm not confident of this it's definitely something which like I don't know I expect
[00:22:40] SPEAKER_02: especially if revenue trends continue I expect to know a lot more about this in a couple in a
[00:22:45] SPEAKER_02: year or two probably within the next year because it will just be the case that okay we will have
[00:22:51] SPEAKER_02: AI is earning enough to substantiate to be like a substantial part of the economy if it's not showing
[00:22:58] SPEAKER_02: up in unemployment then we've learned something about what it's doing we've learned that like
[00:23:01] SPEAKER_02: it's able to do this without showing up in unemployment numbers or maybe it will show up in
[00:23:05] SPEAKER_02: unemployment numbers and we'll see exactly what there's been like some early work looking at like
[00:23:09] SPEAKER_02: indicators of this there's a lot of things that complicate looking into this
[00:23:17] SPEAKER_02: because interest rates also have effects on like the sort of things you might care about or just
[00:23:21] SPEAKER_02: like normal trend or also it's possible that tech companies you know maybe they'll lay off a bunch
[00:23:26] SPEAKER_02: of programmers so that they have the capital to build data centers and are those programmers being
[00:23:31] SPEAKER_02: laid off because of AI I don't know if you had a kid that was a freshman in college and they were
[00:23:40] SPEAKER_01: asking hey you know what should I major in if I want to have a great career you know what might
[00:23:44] SPEAKER_01: you tell them and if they ask you about you know computer science or math or you know what would you say
[00:23:54] I mean I'd probably say not prompt and prompt engineer I think in general people get better at
[00:23:58] SPEAKER_02: using AI is very easy to use yeah I think it's a good question I think they should probably
[00:24:07] SPEAKER_02: measure in something where if they're majoring in programming the thing that they should be or
[00:24:12] SPEAKER_02: computer science the thing that they should be looking for is not being a person who's good to like
[00:24:16] SPEAKER_02: like the skills that are going to be useful are not going to be knowing a programming language
[00:24:20] SPEAKER_02: it's going to be more general purpose skills ability to like work with other people
[00:24:26] SPEAKER_02: um a communication skills the sort of thing I don't really know entirely if this points to a
[00:24:32] SPEAKER_02: particular major most majors are probably not majors that are like actually relevant for your job
[00:24:38] SPEAKER_02: yeah I guess I'd sort of be like well there's not too much that you can do to plan around the super
[00:24:45] SPEAKER_03: crazy futures so I guess go for something but you're passionate about that's useful in the
[00:24:50] SPEAKER_03: worlds but don't go crazy in that way I actually think that yeah computer science math if you're
[00:24:56] SPEAKER_03: passionate about them they're very good can see all the interesting things that are valuable in
[00:25:01] SPEAKER_03: any worlds um but I don't know I gave advice to younger relatives recently and they chose to study
[00:25:07] SPEAKER_03: drama instead so I do think that you know one of the things that if you have a better time in
[00:25:16] SPEAKER_02: college that's like four years of your life you've had a better time during and at the end of the
[00:25:20] SPEAKER_02: day like you know if you if it's uh you have it's a crapshoot which of those things is actually
[00:25:25] SPEAKER_02: going to give you a better time in the future it's planning for the present is a lot easier
[00:25:30] SPEAKER_00: I mean you definitely become really hard to to know right I mean I remember like the
[00:25:34] SPEAKER_00: the prompugioro was obviously a joke because everyone believed two years ago that that was sort of
[00:25:39] SPEAKER_00: some sort of viable thing and obviously models are phenomenally better I'd like just being
[00:25:45] SPEAKER_00: great prompters uh so obviously that's kind of like one thing that has been happening is just
[00:25:50] SPEAKER_00: really hard to predict what's what's happening as this model keep getting better keep getting better
[00:25:54] SPEAKER_00: one one question that I have related to this is obviously code is such a big market and it has
[00:25:59] SPEAKER_00: such a big impact one that I'm very excited about but it's still much earlier I think it's computer
[00:26:05] SPEAKER_00: use right it's basically automating all the digital tasks that you're doing on your computer
[00:26:10] SPEAKER_00: and there's very few benchmarks around this like whether it's webery now or the
[00:26:14] SPEAKER_00: always world you talk a little bit on your report about benchmarks curious on like what do you
[00:26:19] SPEAKER_00: think is missing in that space like why we haven't seen yet that moment where the the moment for
[00:26:24] SPEAKER_00: example when san at 3.5 km or cloud code or codex where we saw a significant improvement on coding
[00:26:31] SPEAKER_00: in general we haven't had that moment for computer years what do you think is missing there
[00:26:36] hmm interesting I mean there have been improvements on computer use for sure I do have I mean
[00:26:44] SPEAKER_03: this maybe I'm going out on a limb here slightly but also I do think that there is a sense in which
[00:26:50] SPEAKER_03: models are a little bit artificially hobbled by um their vision capabilities like it does
[00:26:57] SPEAKER_03: seem as if a common pattern you see when you try to get models to do stuff with a gooey if they kind
[00:27:03] SPEAKER_03: of get a bit confused about manipulating it and and you know in a way where it's like okay this is
[00:27:09] SPEAKER_03: interacting with your general propensity to get infused in long as you would in like difficult
[00:27:15] SPEAKER_03: long coding problems but it's kind of exacerbated because like you're not able to just easily
[00:27:20] SPEAKER_03: look back on the thing and see kind of how I was wrong you instead go down like some awful bed end
[00:27:26] SPEAKER_03: of just I'm just going to click this again and again and again um so I think that's part of it
[00:27:32] SPEAKER_03: I think there is something here or so probably about kind of long context coherent stuff like
[00:27:39] SPEAKER_03: those tokens to represent the gooey are pretty big and then you're filling up your context window
[00:27:45] SPEAKER_03: as you go with like oh yeah well I had all of this stuff that's happened before and you seem to
[00:27:50] SPEAKER_03: just run into a kind of spiral of increasingly less sensible outputs so I feel like these are two
[00:27:56] SPEAKER_03: of the big things but I don't have that answer as a question I found computer use
[00:28:02] SPEAKER_02: I know this was the first year I found computer use actually useful I we use chat GPT agent in our
[00:28:09] SPEAKER_02: data center research because a lot of what we have to do is find permits which are all going to be
[00:28:14] SPEAKER_02: on janky county by county databases of error permits for you know the county that Abelene
[00:28:21] SPEAKER_02: Texas is in and I don't know what databases exist for every county in the US uh chat GPT does
[00:28:32] SPEAKER_02: normal chat GPT can't search them because it's these you know these actual user interfaces you
[00:28:38] SPEAKER_02: can't just search them with you know URLs because they definitely don't work that well and it's
[00:28:43] SPEAKER_02: able to navigate this such that I can just ask it to find me permits on a data center in a particular
[00:28:48] SPEAKER_02: city and it will come back with air pollution permits and like tax abatement documents and all
[00:28:53] SPEAKER_02: of this stuff that let me learn a huge amount um and this is just like because of the improvements
[00:28:59] SPEAKER_02: we've seen in computer use over the past year or so um I'm excited to yeah I think it's just
[00:29:05] SPEAKER_02: just gonna get better from there but I've definitely found it starting to get to the point where
[00:29:08] SPEAKER_02: it's actually useful. What's your mental model more broadly for what is going to happen to
[00:29:16] SPEAKER_01: productivity or or just sort of economic economy statistically in general are you some people say
[00:29:22] SPEAKER_01: GDP growth would be you know 5% I think it's a talent count of you I think some people would say no
[00:29:27] SPEAKER_01: no you should get up to 10% growth or maybe even higher if we truly have have AGI in terms of how
[00:29:33] SPEAKER_01: we understand it what's your model of what happens to the productivity. I think my kind of baseline
[00:29:39] SPEAKER_03: guessing would be you know I forecast out kind of if revenue keeps growing the way it has
[00:29:47] SPEAKER_03: in theory for it to be worth spending that much on that you know those chips to do that inference
[00:29:54] SPEAKER_03: you should be getting something kind of similar to that value after those chips by then
[00:29:58] SPEAKER_03: so then you could just draw from that kind of like oh okay so extrapolating to 2030 you need
[00:30:04] SPEAKER_03: and I think for there it was in the report I don't know I character I think it was on the order of
[00:30:10] SPEAKER_03: like a percent kind of GDP increase that's in a few years right that's not presuming AGI that's
[00:30:15] SPEAKER_03: presuming like if in video stock not revenues keep like growing as they sort of previously have and
[00:30:22] SPEAKER_03: you assume that they make roughly as much compute from it as before and so on. If you actually get
[00:30:30] SPEAKER_03: something I mean AGI is like yeah people use it to the empty different things I think if you
[00:30:35] SPEAKER_03: actually get something that can do any tasks that humans can do remotely then presumably you see a
[00:30:45] SPEAKER_03: lot of growth it feels sort of difficult to guess exactly what kind of a lag you're going to see
[00:30:51] SPEAKER_03: I think there's reasons to think oh well maybe people will be slow to adopt stuff how do they learn
[00:30:56] SPEAKER_03: to trust it whatever there's other reasons to think well they're already using these technology is
[00:31:01] SPEAKER_03: a lot of it might actually be quicker than most growth and indeed adoption has been quicker for
[00:31:05] SPEAKER_03: elements than for many previous technologies so yeah I think it sort of gets hard at that point
[00:31:13] SPEAKER_03: to model at some point on our site we had some rough numbers where it was stuff like what if you
[00:31:18] SPEAKER_03: you know doubled the virtual labor force what if you ten times bit whatever then you see these like
[00:31:23] SPEAKER_03: crazy GDP boosts I don't know whether that's the most reason of a way to think about it I sort of
[00:31:33] SPEAKER_03: I think a lot of it comes down to whether you imagine that like yeah you really get something
[00:31:37] SPEAKER_03: that can do everything versus you get something first but can do a meaningful fraction of remote
[00:31:44] SPEAKER_03: tasks but maybe can't do like an entire bucket of burn that it bottlenecks you more so I guess
[00:31:50] SPEAKER_03: it's again this thing of like my best guess on current trends is this fairly well-defined you
[00:31:57] SPEAKER_03: know few percent of GDP in 2030 thing which is already pretty crazy by economic standards but then
[00:32:05] SPEAKER_03: once you go much further it's like God you know my predictions are just going to be even
[00:32:09] SPEAKER_03: crazy or I'm reluctant to make them I am going to be slightly less reluctant
[00:32:15] SPEAKER_02: and I'm playing for your form assuming in the next ten years we get AI that is capable of doing
[00:32:21] SPEAKER_02: any remote job as well as any human I think you know 30% GDP growth seems like a lower bound
[00:32:28] SPEAKER_02: on something that's reasonable assuming you get this is a big assumption that a lot of people
[00:32:33] SPEAKER_02: are going to you know it's there's a lot going on in that assumption but assuming that happens
[00:32:38] SPEAKER_02: I think you either are going to get like 30% GDP growth or you know negative 100% GDP growth
[00:32:43] SPEAKER_02: because everyone's dead it's just like you know it's just like at the end of the day it seems like
[00:32:51] you're going to have AI that can scale that if you have AI that can scale there you can probably have
[00:32:55] SPEAKER_02: AI that scales even farther and right now I think the like economic models I have seen of what
[00:33:03] SPEAKER_02: happens if you get this sort of full replacement you can automate a job are you know either show this
[00:33:11] SPEAKER_02: sort of extremely fast wild takeoff or with a couple of it or you know you have some people
[00:33:18] SPEAKER_02: attempting to do this who then say and then you like look down through paragraphs and it's like
[00:33:23] SPEAKER_02: assuming current levels of assuming AI is as capable as GPT-3 you know I think the the smaller numbers
[00:33:30] SPEAKER_02: just like you know they're newer they're either newer term protections or predictions that aren't
[00:33:36] SPEAKER_02: looking at like the full the the more the upper end of what sort of capabilities you might see
[00:33:42] SPEAKER_02: in the next 10 years yeah I mean it does seem hard to imagine a world where you have this supply
[00:33:48] SPEAKER_03: virtual labor that literally can do any stuff that humans can do and then it doesn't need to crazy
[00:33:54] SPEAKER_03: things I definitely agree with that I guess perhaps maybe some sort of a I don't know a heavy
[00:34:00] SPEAKER_03: regulation situation but there are the doing yeah I think there exist worlds in which things don't
[00:34:07] SPEAKER_02: go crazy after that it does seem like those worlds are not in an indefinite stable state but
[00:34:15] SPEAKER_02: you know it's not impossible but it does seem like the default there is you either go crazy up or
[00:34:22] SPEAKER_02: you either go crazy down and it's probably going to be one of those two if you get to a world where
[00:34:26] SPEAKER_02: it's like genuinely AI can do any job as well as any human I think people I don't know it seems
[00:34:31] SPEAKER_02: wild to be to claim that you know given that your default case should be you know not super
[00:34:37] SPEAKER_02: ridiculous changes it's just like that's a lot of things that you're AI can do right there and
[00:34:43] SPEAKER_02: that's like yeah it just like seems like it should have fundamentally changed the economy in one
[00:34:47] SPEAKER_02: direction or another my intuition is a lot of the disagreeing then I mean probably some of it
[00:34:53] SPEAKER_03: does come down to sort of cash beliefs people already have but I do also think some of it is
[00:34:57] SPEAKER_03: that when people talk about like oh yeah AGI AI that can do a remote job whatever even though
[00:35:04] SPEAKER_03: we feel like we're talking about the same thing maybe sometimes we're not I don't know I've
[00:35:08] SPEAKER_03: certainly had examples of conversations that's like yeah I can do any remote job and then they
[00:35:13] SPEAKER_03: discuss stuff that it can't do and the stuff that it can't do it's like well no like that's
[00:35:18] SPEAKER_03: that's also a remote job like that's the kind of thing people currently do so I think there is
[00:35:22] SPEAKER_03: some of this what do you think like I mean you talk about benchmarks on your report but I wonder
[00:35:27] SPEAKER_00: like 2027 2028 what are going to be the right benchmarks the measuring the progress more than the
[00:35:35] SPEAKER_00: economic growth more the capabilities on the model like intelligence on the model like we had in
[00:35:41] SPEAKER_00: 2012 Alex net obviously that that got solved long ago but that was probably not a measure of AGI by
[00:35:47] SPEAKER_00: any means do you think the same would happen with the current benchmarks we have so so
[00:35:52] SPEAKER_00: a sweet bench m or you let's say we maxed out on those benchmarks what comes after the how would
[00:35:59] SPEAKER_00: we do we measure that is here sort of like GDP growth with these models it's sort of breakthroughs
[00:36:04] SPEAKER_00: in science how do you think is the right measure going forward yeah I mean I think most of what we have
[00:36:10] SPEAKER_03: is likely to be solved and indeed the examples you gave are like pretty close already like I know
[00:36:17] SPEAKER_03: you is basically solved we bench it's like possibly close depends a bit on how and big your
[00:36:24] SPEAKER_03: some of the questions are there some details but it's really getting there I mean I think some
[00:36:30] SPEAKER_03: directions are obvious you kind of do similar things but harder and a bit that are and try to make
[00:36:35] SPEAKER_03: them a bit more realistic and people are doing this there are harder software benchmarks that people
[00:36:41] SPEAKER_03: made more of an effort to try to curate and that cover larger tasks for example I think there's
[00:36:48] SPEAKER_03: also perhaps some question of kind of budgets involved I do think there's this kind of thing well
[00:36:53] SPEAKER_03: like obviously if you just burn money it doesn't intrinsically make the benchmark better but probably
[00:36:59] SPEAKER_03: you are going to see something where you're just going to have to devote more resources on average
[00:37:03] SPEAKER_03: to them like if you're trying to prove a sort of higher level of capabilities to a higher standard
[00:37:09] SPEAKER_03: of proof probably it's going to involve kind of more effort in developing them I do also think
[00:37:15] SPEAKER_03: though you're going to see examples of you know relatively small kind of small numbers of things
[00:37:21] SPEAKER_03: that are just very impressive and these are also valuable signal like when you see
[00:37:26] SPEAKER_03: are being able to do things like oh yeah it just refactored this entire code base and it was really
[00:37:33] SPEAKER_03: useful then this is going to be useful and even if it's not yet formalized into a benchmark if
[00:37:40] SPEAKER_03: you've seen it for yourself it's going to be kind of useful for you as evidence and then people
[00:37:44] SPEAKER_03: are probably going to make benchmarks that cover things like this to try to systematize them
[00:37:50] I want to go back to our question on timelines and I want to ask you about a few different
[00:37:55] SPEAKER_01: sort of milestones and get your perspective on timelines there so first is what is your
[00:38:00] SPEAKER_01: rough timeline for a major unsolved math problem being solved by I actually wondered yeah because
[00:38:08] SPEAKER_03: you had a few of these that you said trust the look at when you say that it solves this I mean
[00:38:14] SPEAKER_03: is this unassisted entirely it's or is it kind of a news you know reports or someone tweets that
[00:38:20] SPEAKER_03: hey like I dump this at GPT and it solved it and what counts as major something that we would all
[00:38:27] SPEAKER_01: agree like a substantive you know version of it not not a you know just a anecdotal you know
[00:38:34] SPEAKER_01: person scrubbing it that does it have to solve it on its own yeah let's go with that sure yes
[00:38:41] SPEAKER_01: honestly oh yeah because I mean there's already cases it seems of Ellen's be like people are
[00:38:47] SPEAKER_03: debating a little bit but mathematicians who seem trustworthy are saying like wow I used this and
[00:38:53] SPEAKER_03: it was really helpful during my proof yeah I would not be surprised if hey I solves like a major
[00:38:58] SPEAKER_02: unsolved math problem like the remanhypathesis or similar in the next five years I'm not going to
[00:39:03] SPEAKER_02: say that like that's my you know median case necessarily but I definitely wouldn't be that surprised
[00:39:08] SPEAKER_02: it's like right now it doesn't look like math is that hard for AI it's just like some things turn
[00:39:18] SPEAKER_02: out to be hard and some things don't and math is just like one of the debates where it's all seems
[00:39:23] SPEAKER_02: to work pretty well and where it's most other domains it's not at the point where it's like useful to
[00:39:29] SPEAKER_02: a full professor to the same extent I think it is for math all or getting very close to for math
[00:39:37] SPEAKER_02: yeah at the end and also it's like very unclear to what extent certain capabilities that it has
[00:39:42] SPEAKER_02: unusually well might actually turn out to be very very useful like maybe it'll turn out that there's
[00:39:47] SPEAKER_02: like four papers out there that it knows about that have obscure results in them that when combined
[00:39:52] SPEAKER_02: solves some big conjecture which is the sort of thing that it like might be much more feasible to
[00:39:57] SPEAKER_02: figure out with AI than for a human to figure out or something similar this a lot of uncertainty
[00:40:03] SPEAKER_02: here but just like does not currently seem like something that AI is actually going to struggle with
[00:40:10] SPEAKER_02: people often it claims about it being like this you know intuitive deep thing that it would mean
[00:40:14] SPEAKER_02: that AI has achieved something some huge level of intelligence for it to solve I think in practice
[00:40:20] SPEAKER_02: this is just like you know making a piece of art it turns out AI could just do that before it could
[00:40:25] SPEAKER_02: do a lot of other before it can you know remember things for more than a couple of days or whatever
[00:40:32] SPEAKER_02: yeah it turns out to be far farther down the capabilities tree than people might have guessed
[00:40:36] SPEAKER_02: yeah I think I'm also bullish though I do think that yeah it's one of those things where it's
[00:40:44] SPEAKER_03: tricky and you really probably do need to define it quite well to get a good forecast on it to hope
[00:40:50] SPEAKER_03: to get a good forecast on it like I don't know we've had this experience that with benchmarking
[00:40:55] SPEAKER_03: mathematics you know we got mathematicians to start with problems that I think aren't as
[00:40:59] SPEAKER_03: difficult as the kind of problems you're talking about but nevertheless they're like yeah
[00:41:04] SPEAKER_03: they I could solve this it would be like a big deal for AI progress it would mean something to me
[00:41:08] SPEAKER_03: and then AI has solved them and usually their response has been kind of like oh yeah that
[00:41:14] SPEAKER_03: updates me a bit or the man when I look at it I just realized like yeah you can kind of brute force
[00:41:18] SPEAKER_03: this you can kind of choose this you can get through and it's a bit like oh okay I mean what if
[00:41:25] SPEAKER_03: there's a problem but for humans we consider certain all this would be quite big and then yeah
[00:41:30] SPEAKER_03: AI solves it and like oh well it solved it whatever we sort of had this with chess decades ago right
[00:41:35] SPEAKER_03: like computers solved chess very well and everyone was thinking of this as the pinnacle of reasoning
[00:41:42] SPEAKER_03: and then they did and everyone is sort of just all kind of concluded by oh well of course
[00:41:47] SPEAKER_03: computers can do chess so yeah I don't know I suspect that math is quite nice for AI to do
[00:41:58] SPEAKER_03: I'm reluctant to go out and assert like oh yeah definitely AI is going to like solve some of the
[00:42:03] SPEAKER_03: millennium prize problems in the next few years but it would not at all surprise me if it solves
[00:42:10] SPEAKER_03: quite impressive seeming things in the next few years to then what about a breakthrough in biology
[00:42:16] SPEAKER_01: or medicine and we've already seen some of that with the what's they called alpha fold it
[00:42:26] SPEAKER_02: a math team is unusually easy for AI I'm good to be honest so to the extent where I'm like I
[00:42:32] SPEAKER_02: as I could to do the same exact level of like oh it on its own did this huge thing that seems to
[00:42:36] SPEAKER_02: be a much bigger stretch to me it definitely seems plausible but there's a lot of other concerns
[00:42:43] SPEAKER_02: there where it needs to it needs to be able to like actually do experiments and get data and
[00:42:52] interact with the real world for a lot of these in a way that does not need to happen at all for math
[00:42:59] SPEAKER_02: in particular for certain yeah it's just they in fact seem farther off what is what seems
[00:43:05] SPEAKER_02: more plausible to me is that we see like you know it become ubiquitous that sums tools like of
[00:43:12] SPEAKER_02: using AI in some sort of aspect of like biology or chemistry or something useful like that that
[00:43:18] SPEAKER_02: like certain aspects of it are enhanced it also is possible that AI will you know make incredible
[00:43:25] SPEAKER_02: strides without yeah I think without humans but it's harder yeah I think again it's a bit tricky
[00:43:31] SPEAKER_03: for where you draw the line I mean I think you're not counting tools like alpha fold because if you
[00:43:37] SPEAKER_03: were then probably you'd argue for that right the inventors co won the shed and I'm surprised um but
[00:43:45] SPEAKER_03: yeah I mean I guess there's kind of different directions in biology you could have AI being
[00:43:50] SPEAKER_03: able to predict quite you know specific things like that or you could have something that's more
[00:43:55] SPEAKER_03: general purpose this so-called like co scientist or whatever they want to call it approach which
[00:44:00] SPEAKER_03: more about like oh it was able to look through the literature and have good ideas and there's
[00:44:05] SPEAKER_03: different extents of human involvement there already seem to be some results when impressive stuff
[00:44:11] SPEAKER_03: is happening I've not vetted them enough to really have a sense of like would this already count
[00:44:16] SPEAKER_03: as having satisfied yeah the sort of level of impressiveness you're looking for I sort of assume
[00:44:25] SPEAKER_03: that finding things that end up being meaningful will happen pretty soon if it hasn't already happened
[00:44:33] SPEAKER_03: but then maybe there's a question of kind of okay but is it doing as well and human researchers
[00:44:41] SPEAKER_03: actually like prioritizing the best few ones to work on I think most of these co scientist results
[00:44:47] SPEAKER_03: have probably had pretty involved humans prioritizing but again I've not looked enough to say
[00:44:53] lastly um how about for real super intelligence for your definition of super intelligence
[00:45:00] I have I have I think I am I am on the record is saying that the the median timeline I discussed
[00:45:08] SPEAKER_02: or the modal timeline sorry I think it's modal yeah which might be on the early side compared to where
[00:45:16] SPEAKER_02: my median is is you know 2045 was where when I did the podcast with Jaime we discussed like our
[00:45:23] SPEAKER_02: forecasting breaking down and everything going bananas is the terminology I have used and that
[00:45:31] SPEAKER_02: like looks like super intelligence um I you know um I think that it's like the case that if we get AI
[00:45:42] SPEAKER_02: that can do every single job uh that a human can do as well as any human can do that job
[00:45:48] in the near future then this is you know means that scaling just works to get things much much
[00:45:54] SPEAKER_02: better and probably means that you are not that many steps so that you are just a bit more scaling
[00:46:00] SPEAKER_02: away from getting AI that could do anything uh that humans uh so two things vastly better than humans
[00:46:10] SPEAKER_02: yeah it gets hard to predict and I think as well it gets to be one of these things where the
[00:46:15] SPEAKER_03: predictions get a bit unmoored from the the stuff that you can like properly model like my my
[00:46:21] SPEAKER_03: sort of you know guesses my like judgmental forecasts to use the fancy term for just kind of
[00:46:28] SPEAKER_03: can do any remote work tasks probably have a median of about like 20 25 years um I kind of struggle
[00:46:38] SPEAKER_03: to imagine a world where that happens and people are like deploying it and doing research and yet
[00:46:45] SPEAKER_03: they're not making further progress to being able to do stuff much better so I guess they have to
[00:46:51] SPEAKER_03: be like not too much longer after that for some definition of super intelligence but yeah all very
[00:46:57] SPEAKER_03: uncertain and yeah it seems to break down a bit you talk a lot about the progress in data center
[00:47:04] SPEAKER_00: as benchmarks a biology and there was one interesting part that I noticed it doesn't the field that
[00:47:10] SPEAKER_00: is robotics is making a lot of progress with let's say world models and like the physical space a
[00:47:15] SPEAKER_00: little bit curious on like um what does your take here like what do you think it's uh it seems like
[00:47:20] SPEAKER_00: a lot of the problems in robotics can be solved purely with imitation learning you might not need
[00:47:23] SPEAKER_00: a lot of sort of like breakthroughs in math or whatever like you can just basically learn it from
[00:47:28] SPEAKER_00: a lot of data and I think in the last couple of years has been remarkable using in robotics and
[00:47:34] SPEAKER_00: world models overall curious on your take alert on these and if you did some kind of research in
[00:47:38] SPEAKER_00: space so we've looked into what sort of uh anonymous compute is actually being used to like do these
[00:47:46] SPEAKER_02: training runs um and what we found is that like compute it the training runs that are being used for
[00:47:53] SPEAKER_02: robotics are like a hundred times smaller than the training runs that are being used for uh
[00:47:59] SPEAKER_02: than the training runs that are being used for like frontier models and so there's a lot of skill
[00:48:03] SPEAKER_02: you can do there I don't think that until plausibly until very very recently there have been serious
[00:48:09] SPEAKER_02: attempts to gather data for robotics at a massive scale it's just the case that you can hire a
[00:48:13] SPEAKER_02: bunch of people to move around in motion capture suits if you need to and there haven't been a lot
[00:48:18] SPEAKER_02: of attempts to do that although I think this might be changing um I think of robotics as mostly a
[00:48:23] SPEAKER_02: hardware problem um a hardware and like economics problem of yeah if you if it costs a hundred
[00:48:29] SPEAKER_02: thousand dollars to build a robot then you know it's not necessarily better than a human who could
[00:48:34] SPEAKER_02: work for twenty thousand dollars a year uh or a very cheap human um in certain countries uh or
[00:48:40] SPEAKER_02: something uh that's like a that like sort of minimum wage in some countries uh they might be able to
[00:48:47] SPEAKER_02: afford labor for um it's just not obvious to me that there is a software problem here um the hardware
[00:48:56] SPEAKER_02: it does seem like unclear it's it's very unclear to me how much of a hardware problem is left in
[00:49:03] SPEAKER_02: particularly there's certain tasks with robots might be able to do but are they actually the tasks
[00:49:08] SPEAKER_02: that you care about a robot being able to do if you want your robot to be able to like nimbley walk
[00:49:12] SPEAKER_02: around while lifting up heavy things and moving fast and react then that's that's hard that's a
[00:49:17] SPEAKER_02: hardware problem that I don't think they've seen solutions for yet yeah I think my impression roughly
[00:49:23] SPEAKER_03: matches this it's sort of I don't know people people fairly often talk about this distinction between
[00:49:30] SPEAKER_03: remote work and physical work I think because there's this perception of robotics progress lagging
[00:49:37] SPEAKER_03: behind a bit and there even is some intuition that maybe maybe this physical manipulation stuff
[00:49:45] SPEAKER_03: is actually just harder but I wouldn't conclude that with much certainty like you have for said it
[00:49:52] SPEAKER_03: feels like you'd kind of also want to see well okay what what happens if it gets scaled up in a
[00:49:57] SPEAKER_03: similar way to even get a sense of like oh okay was it actually harder versus wasn't just deprioritized
[00:50:05] is there is there anything we didn't get to that you feel is important that we leave our audience with
[00:50:10] SPEAKER_01: we did discuss the data standards released we suggested I'm not sure if there's a good way to leave
[00:50:14] SPEAKER_02: the audience with that yeah let's get into it okay so you guys just did a you know release
[00:50:18] SPEAKER_01: it didn't isn't a project what one you talk a little bit about what you were trying to achieve
[00:50:21] SPEAKER_01: there and what you hope people take from it yeah so we took uh 13 of the largest data centers we
[00:50:28] SPEAKER_02: can find um these includes a few from each of the major labs in the US and we found permits
[00:50:35] SPEAKER_02: we took satellite images including new satellite images of all these data centers we figured out how
[00:50:40] SPEAKER_02: to determine how much compute is in them based off the cooling infrastructure out their building
[00:50:45] SPEAKER_02: as well as when they're coming online and their future timelines so we understand this like real
[00:50:49] SPEAKER_02: world data and it's all available online on our website for free um this like to give insight into
[00:50:58] SPEAKER_02: giant infrastructure build up that's happening and the pace of it um there's some things about it
[00:51:02] SPEAKER_02: that surprised me a lot for instance we learned that the most likely candidate to have the first
[00:51:08] SPEAKER_02: gigawatt skill data center is Anthropic which would not have been my pick um but Anthropic
[00:51:13] SPEAKER_02: Amazon's new Carlisle a project reindeer development seems on track to come online in January um
[00:51:20] SPEAKER_02: followed shortly thereafter by Colossus 2 um we also learned a lot about what the largest
[00:51:26] SPEAKER_02: concrete plans are rather than just like marketing plans some people will throw around numbers
[00:51:31] SPEAKER_02: but the one we found that's actually seriously underway and has permits and is you know setting
[00:51:38] SPEAKER_02: up the electrical infrastructure for is one by Microsoft which is going to be used by OpenAI at
[00:51:42] SPEAKER_02: least in part um in Mount Pleasant um they're calling it Microsoft Fairwater um and that one's
[00:51:49] SPEAKER_02: going to be uh use a size use not quite as much power as New York City but I think more than half
[00:51:56] SPEAKER_02: the what's stopping us from significantly increasing the the the cluster saw is it the um is it
[00:52:04] SPEAKER_01: is it cost is it supply leetimes is there any other engineering breakthroughs required power I think
[00:52:09] SPEAKER_00: that people are approximately uh wrong that there's something stopping us and we are scaling up
[00:52:15] SPEAKER_02: as fast as there is money to scale up approximately uh I suppose they could want there to be all of the
[00:52:22] SPEAKER_02: clusters literally today but they're scaling up really quite fast you're seeing these data centers
[00:52:28] SPEAKER_02: which are using uh I think the one I mentioned for Anthropic Amazon is eating about as much power
[00:52:33] SPEAKER_02: nearly as much power as the state capital of indeed of Indiana which is where it's located um and
[00:52:40] the timelines on some of these uh like the classes to uh are you know two years or less
[00:52:46] SPEAKER_02: which is just an insane thing to build this thing that's using as much power as a city um I think
[00:52:52] SPEAKER_02: that plausibly you know you don't want to buy chips now you want to wait for there to be better chips
[00:52:57] SPEAKER_02: uh I I think that people think of there's a lot of noise about things being difficult in scaling up
[00:53:06] SPEAKER_02: and I think this is because people are having to spend a little bit more than they would ordinarily
[00:53:10] SPEAKER_02: have to spend you can't use the ordinary sort of power pipeline which is designed to deliver
[00:53:15] SPEAKER_02: the supportable infrastructure on at a slow pace you have to you know buy things that you wouldn't
[00:53:20] SPEAKER_02: ordinarily have to buy and spend more than you would ordinarily have to spend but not buy enough to
[00:53:25] SPEAKER_02: slow it down all of these things paling comparison to the cost of your GPUs uh so my actual take away
[00:53:34] SPEAKER_02: from a lot of this has been oh we're not having too much trouble scaling up but just like these
[00:53:41] SPEAKER_02: plans are going really quite fast and it's not obvious that people would actually have the finances
[00:53:47] SPEAKER_02: and desire to do them faster when when people are talking about energy as uh as a as a as a
[00:53:53] SPEAKER_01: a major potential bottleneck or I was having to you know increase our capabilities significantly
[00:53:57] SPEAKER_01: you're you're not worried that that's going to be a sort of durable a sustainable bottleneck
[00:54:01] SPEAKER_01: that that's not I think people like complaining because they can't just use the traditional
[00:54:06] SPEAKER_02: plug into the grid for cheap affordable power um four years down the line pipeline at the end of
[00:54:12] SPEAKER_02: the day the day there are expensive uh technologies that exist right now you could pay for solar
[00:54:20] SPEAKER_02: power plus batteries this is fairly small lead times it might cost twice as much as normal power
[00:54:26] SPEAKER_02: but that's still way less than your GPUs so you're good to do it if you have to and you see people
[00:54:30] doing these sort of emergency things that cost them a bit more you know starting up their data
[00:54:35] SPEAKER_02: centers a common thing we see is people starting their data centers before their data centers are
[00:54:39] SPEAKER_02: connected to the grid um I think Abelene was an example xai classus one is a prominent example
[00:54:45] SPEAKER_02: of just finding ways around this that are expensive and you could play in about it because you know
[00:54:50] SPEAKER_02: it'd be nice if you could do the cheaper way and no one's used to having to do it this expensive way
[00:54:55] SPEAKER_02: at the end of the day though it's just like does not there seem to be enough solutions
[00:55:01] SPEAKER_02: especially if you are as willing to pay as you as people are in AI that I don't really expect
[00:55:06] SPEAKER_02: it to be a significant bottleneck the immediate maybe it was close to this if if these systems get
[00:55:12] SPEAKER_01: as powerful as we're as we're disgusting as we're discussing i'm curious to how the sort of
[00:55:17] SPEAKER_01: political system is going to respond i'm curious if you're sympathetic to the ash and breiner view
[00:55:22] SPEAKER_01: that that there's some potential nationalization that that occurs but how do you expect governments to
[00:55:29] SPEAKER_01: to respond it's kind of remarkable of how not in the political discourse it is given how powerful it
[00:55:37] SPEAKER_01: is already i'm curious how do you think about that i expect so the thing i calling back to what i
[00:55:42] SPEAKER_02: mentioned earlier this concept of you know the potential for five percent unemployment increase
[00:55:46] SPEAKER_02: in like six months i think that the public's reaction to this will determine a lot there will be
[00:55:52] SPEAKER_02: very very strong feelings about i i once this happens i think there will be a bunch of you know
[00:55:56] SPEAKER_02: very strong consensus on what to do i on things that we don't normally think of as things that
[00:56:02] SPEAKER_02: people are considering i know when this happened with covid there was a several trillion dollar
[00:56:07] SPEAKER_02: stimulus package passed at like you know in a matter of weeks to days it was break next speed
[00:56:15] SPEAKER_02: i don't know what that will look like for a i but i think it's
[00:56:19] SPEAKER_02: like everything else in a i it's like you know exponential which means it will pass the point of
[00:56:25] SPEAKER_02: you know people sort of care about it to people really care about it quite fast if things keep going
[00:56:30] SPEAKER_02: um i i just don't know where we're going to end up i just expect you know wherever we end up there will be
[00:56:37] it will look like oh everyone suddenly agrees that why that's that's to do this certain thing
[00:56:42] SPEAKER_02: which we would have considered unimaginable a year ago and i don't know what that will look like it
[00:56:46] SPEAKER_02: might look like nationalization it might look like pausing um it might look like i don't know
[00:56:52] going faster uh guaranteeing better unemployment benefits who knows uh i i i i just think there's
[00:56:58] SPEAKER_02: going to be some sort of like strong response of some sort and it's going to happen very fast
[00:57:04] SPEAKER_02: yeah i mean you know you make the point that government so maybe less interest is the new to
[00:57:10] SPEAKER_03: expect now but i mean the current impacts i think aren't really that large i feel like the
[00:57:16] SPEAKER_03: attention is getting larger but it's not the day a as of right now is that powerful and yet
[00:57:23] SPEAKER_03: governments are already talking about it a lot right and you have people meeting with heads of state
[00:57:29] SPEAKER_03: from various hardware manufacturers and AI companies and like countries talking about the AI
[00:57:34] SPEAKER_03: strategies stuff like this so i feel clearly country national governments are going to be quite
[00:57:41] SPEAKER_03: in awe that's just a question at how and yeah i also have a bit unaware of that i think that
[00:57:46] right now we've seen this thing in revenue and finances where it's been doubling or tripling
[00:57:51] SPEAKER_02: every year and my default assumption is that attention that AI gets from policymakers and
[00:57:58] SPEAKER_02: governments is going to follow a similar trend where it will double and triple every year um this
[00:58:03] SPEAKER_02: means that in the future the the credit if trends continue there will be a huge amount of attention
[00:58:07] SPEAKER_02: and it means that right now there's a lot more attention in the last year but you don't suddenly skip
[00:58:11] SPEAKER_02: from very little attention to all of the attention uh although you do move quite we are moving
[00:58:18] SPEAKER_02: i think quite fast i i think we made enough predictions that we'll have to have you back next year
[00:58:24] SPEAKER_01: and uh you know the year check in and see where we're at and then they make make up next year um
[00:58:29] SPEAKER_01: yeah but david thank you so much for coming up i guess thank you thank you thanks so much for having us