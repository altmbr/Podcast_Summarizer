[00:00:00] Sometimes founders ask me, what's the biggest way to create a good culture?
[00:00:04] Welcome to Facebook.
[00:00:04] I mean, Esther is winning.
[00:00:06] I remember when people said that SaaS was stupid and cloud was stupid because
[00:00:10] why would an enterprise ever move their data to a third party cloud that wasn't secure?
[00:00:13] I helped get this other company up and running called Branco.
[00:00:16] We were just calling it Branco.
[00:00:17] It was an internal placeholder and then we're going to come up with something better
[00:00:20] and like Apple and like Stripe and a few other companies,
[00:00:22] we just could never come up with anything better.
[00:00:24] We should talk about the $30 million series A.
[00:00:26] I'm really curious how you shift from investing directly into companies to incubating them.
[00:00:30] How did you work through Ivanka's husband?
[00:00:33] Ivanka's husband.
[00:00:36] Which Ivanka?
[00:00:38] Jared came out to kind of talk to different people about AI and what was happening.
[00:00:41] We started just kind of comparing notes on what he'd been seeing from the corporate and government world
[00:00:45] in terms of people trying to adopt AI and not really knowing what to do.
[00:00:47] And I'd been talking to a lot of Fortune 100 CEOs and execs about sort of a similar thread
[00:00:52] and so we kind of realized that the world's biggest institutions need to be able
[00:00:55] to have an easy way to adopt AI.
[00:00:56] When I met Jared Kushner, I think the media that portrayed him in a way that was very different from what they're like in person
[00:01:01] in terms of being very smart driven, wanting to do the right thing for the world.
[00:01:04] One thing I've always wanted to do is like imagine that I...
[00:01:07] Well, I actually don't want to talk about this.
[00:01:10] I can tell you after I just don't want to.
[00:01:11] Okay.
[00:01:12] Off the record, we have an exclusive.
[00:01:14] Yeah, exactly.
[00:01:15] Print it.
[00:01:16] With Eric Wu, are you guys going to do anything with Open Door?
[00:01:20] Do you mean like a take private or something?
[00:01:21] No, but that would be interesting.
[00:01:25] One of the things that when I was doing research, I was listening to previous podcasts you were on
[00:01:37] and there was a really good one with Patrick O'Shaughnessy.
[00:01:40] And you were talking about markets and how they collapse usually to two to three winners.
[00:01:45] So can you explain how that works and like what the framework is around that?
[00:01:49] Oh, I think there's lots of different market structures.
[00:01:52] So there's some things that form natural monopolies, right?
[00:01:55] And so that for a long period of time was like the Microsoft OS or other things like that.
[00:02:00] And then the internet displaced that and a lot of new entrants in the mobile created another entry point.
[00:02:06] So some things actually naturally are just one player really dominates.
[00:02:10] It's kind of like Uber in the US or whatever now.
[00:02:12] There's many markets and this was something I had to learn because I didn't invest in things.
[00:02:17] So like it's not a monopoly that turned out multiple players could win.
[00:02:20] That are actually allegopoly market structures.
[00:02:22] We have a handful of very large players.
[00:02:24] Now sometimes you have these large players and then you have a lot of fragmentation.
[00:02:27] You know, the three big players on 50% of the market and everything's fragmented.
[00:02:29] And that tradition has been payroll, ADP paychecks and then a bunch of stuff.
[00:02:34] And then hopefully now rippling and other sort of gusto and related companies.
[00:02:38] And then I guess deal is another one.
[00:02:41] And then there's
[00:02:44] markets where things are just default fragmented.
[00:02:46] It's like the restaurant business, right?
[00:02:48] There's thousands of restaurants in San Francisco.
[00:02:52] And so depending on different aspects of the market structure,
[00:02:58] what sort of customers you have,
[00:03:00] how dependent are they on your product or their network of facts or their scale effects, etc.
[00:03:04] That drives which market structure you end up with.
[00:03:08] So I think there's lots of different ones in tech and consumer tech,
[00:03:12] the monopoly markets were more common.
[00:03:16] That was Google to some extent and search.
[00:03:18] That was Microsoft with the SoS, etc.
[00:03:20] And then in many, many other markets,
[00:03:22] it's more a non-aligopoly structure.
[00:03:24] Payments is a good example.
[00:03:26] There's a ad gen and there's Stripe and there's PayPal.
[00:03:28] There's a variety of players.
[00:03:30] Do you think moats change over time?
[00:03:32] I think that for some companies,
[00:03:34] they build new moats over time for sure.
[00:03:36] I think there's a handful of ways to have them out.
[00:03:38] And I think there are things,
[00:03:40] things just tend to collapse and that he says the things usually I find.
[00:03:42] It's kind of the opposite of there's no good generic startup advice,
[00:03:46] kind of thing, but the reality is there are patterns too.
[00:03:48] And so one mode is a scale effect.
[00:03:52] So for example,
[00:03:54] if you're a payments company,
[00:03:56] the more scale you have,
[00:03:58] the cheaper your interchange fee is on the back end,
[00:04:00] which means you can charge less,
[00:04:02] which means you can get more scale.
[00:04:04] And so you have the cycle.
[00:04:06] That'd be one example of a scale effect.
[00:04:08] For example,
[00:04:10] everybody's built an app on top of Salesforce.
[00:04:12] Everybody selling those apps are integrated in a deep way.
[00:04:14] That helps create defensibility
[00:04:16] because if you're trying to build a Salesforce competitor,
[00:04:18] you may also have to build all these apps at once.
[00:04:20] So you have more to build against and it's tougher.
[00:04:22] So there's these ecosystem or platform effects.
[00:04:26] Some businesses have long-term contracts.
[00:04:30] So for example,
[00:04:32] in the medical distribution world,
[00:04:34] McKesson and that sort of world,
[00:04:36] in the medical distribution,
[00:04:38] people end up in these like three to seven year contracts.
[00:04:40] So the entire industry is effectively locked up
[00:04:42] between a handful of players
[00:04:44] because they each own a chunk of it.
[00:04:46] So there's a lot of different types of,
[00:04:48] I mean, I'm not going to keep going because
[00:04:50] there's like listing all my companies alphabetically, right?
[00:04:52] But fundamentally, there's only a handful of ways to do this
[00:04:54] and they tend to be very consistent,
[00:04:56] but they tend to be very strong network effects as another one.
[00:04:58] Shifting into one of your other strategies,
[00:05:00] we covered investing macro and everything like that.
[00:05:04] But I'm really curious how you
[00:05:06] shift from investing directly into companies
[00:05:08] to incubating them.
[00:05:10] There's a couple companies that you started
[00:05:12] that start with Brain.
[00:05:14] So what's the deal with these Brain companies?
[00:05:16] I mean, so Anker came up,
[00:05:18] Anker Goyle, who's the CEO and founder
[00:05:20] of Brain Trust,
[00:05:22] came up with Brain Trust,
[00:05:24] which I thought was a great name.
[00:05:26] And I helped him really early get that up and running
[00:05:28] and did a lot of really customer calls.
[00:05:30] And initially we talked about just doing that as like an open source project
[00:05:32] and all the stuff and then it kind of converted into a company.
[00:05:34] So we were just doing it for fun.
[00:05:36] It's like a kind of a side project.
[00:05:40] And then when I helped get this other company up and running called Brain Co,
[00:05:44] we were just calling it Brain Co as a placeholder.
[00:05:46] Yeah, it wasn't meant to be the long-term name.
[00:05:48] And hopefully Anker isn't upset.
[00:05:50] You know that we have another brain thing in the family.
[00:05:52] But it was meant to be like kind of funny and quirky.
[00:05:56] And it was an internal placeholder.
[00:05:58] And then we're going to come up with something better.
[00:06:00] And like Stripe.
[00:06:01] And if you're other companies, we just could never come up with anything better
[00:06:03] and the people who are working on it liked it.
[00:06:04] So it kind of stuck.
[00:06:05] So it was an inadvertent.
[00:06:06] How did you recruit Ivanka's husband?
[00:06:10] Ivanka's husband.
[00:06:12] Which Ivanka?
[00:06:14] Ivanka truly?
[00:06:16] Oh yeah.
[00:06:17] So I met Jared when he was...
[00:06:22] So Jared came out to kind of talk to different people about AI and what was happening.
[00:06:26] And we started just kind of comparing notes on what he'd been seeing from this sort of corporate
[00:06:33] and government world in terms of people trying to adopt AI and not really knowing what to do.
[00:06:36] And I'd been talking to a lot of Fortune 100 CEOs and execs about sort of a similar thread.
[00:06:45] And there was Luis who works with Jared, who was similarly was having this sort of conversations.
[00:06:48] And so we kind of realized that there was a very clear need and pain point around very large scale enterprise.
[00:06:56] Government, like the world's biggest institutions need to be able to have a easy way to adopt AI for various workflows and purposes.
[00:07:02] And so we thought it would make a lot of sense to kind of build out a company that could have a core platform
[00:07:10] that you could then build different applications on the top of that would serve those needs.
[00:07:13] And so Eric Wu came in as sort of a founder and chairman.
[00:07:16] And then Dan Ashton who you know and Mersha and others came on as sort of the initial founding team.
[00:07:22] And we kind of just were off into the races from then and Clemens recently joined the CEO of the company.
[00:07:27] So how do you think about I think this company is really interesting because you're going after one end of the market that has been underserved so far.
[00:07:36] Like we're seeing a lot of value accretion in the hardware layer and then now in the LLM.
[00:07:42] But like the services really has not been tapped into yet because it's just a downstream effect, I think.
[00:07:48] If downstream is the right word, but I'm curious from your standpoint, like how large is this opportunity?
[00:07:53] You talked about Tams before, but like how large is this and who are they going to be like.
[00:07:59] Yeah, I mean, I think this is a truly massive, massive town.
[00:08:03] And so, you know, it really is, if you look at a startup's life cycle normally that's doing B2B.
[00:08:10] You tend to start off with smaller businesses you're selling to and then you realize that's a tough market and you go mid market and you spend a couple years in mid market.
[00:08:16] And then eventually do big enterprise and you land your first multi-million dollar deal in your ecstatic or you have a $10 million deal.
[00:08:22] It takes you like three to seven years to get there.
[00:08:26] Is there a thing you let's just jump straight to those customers.
[00:08:29] We have access to them.
[00:08:30] We know their needs.
[00:08:32] We can build really aggressively against it.
[00:08:35] But we can also attract a caliber of engineer to work with them that they just won't necessarily have access to in any other way.
[00:08:41] And that's because we have created a team or brought on a team or hired a team that are the types of people that normally be working at the foundation labs, right.
[00:08:51] They'd be working at OpenAI or they'd be working at Google or they'd be working at some of these great companies.
[00:08:55] And we've really taken the approach of saying we're both going to build out this platform.
[00:09:00] So it's a common piece of infrastructure that everybody can use.
[00:09:03] But then on top of that, we can build the spoke apps and then resell those apps to other people in the same vertical.
[00:09:08] And so if you're dealing with one of the world's biggest healthcare chains, you can repeatedly provide that to the world's biggest healthcare organizations because they all have some similar needs.
[00:09:16] And so we think that strategy has actually worked really well on this enormous pent up demand because every CEO is asking, what is my AI approach with my AI strategy.
[00:09:24] I know it can impact my margin or my productivity or my sales output, you know, maybe I can double sales through it.
[00:09:30] But they may not necessarily have the resources to go right at it immediately or they'll have a research team internally.
[00:09:36] This working on it, but that team can use extra resources or they can use some of the product work that we provide.
[00:09:42] Sorcery is brought to you by Brex, the financial stack trusted by more than 30,000 companies, including one in three venture back startups in the US.
[00:09:51] Nearly 40% of startups fail because they run out of cash.
[00:09:55] Brex is literally built to help founders avoid that.
[00:09:58] Unlike traditional banks that let your money sit idle, shipping away out it with fees, Brex's designs help you spend smarter and move faster.
[00:10:06] They're all in one solution, combines checking, treasury, and FDIC protection into one powerful account.
[00:10:13] You can send and receive money globally at lightning speeds, get 20 times the standard FDIC coverage through their partner banks and even high yield from day one.
[00:10:22] With same day and even same hour liquidity, access your funds anytime.
[00:10:27] Companies like Scale AI, DoorDash, Service Titan, HIMS, Anthropic, Flexport, Robinhood, and Plod trust and use Brex.
[00:10:36] Start today at Brex.com slash Sorcery. That's B-R-E-X.com slash Sorcery.
[00:10:44] Do you think that the MIT study was correct?
[00:10:50] I think it had aspects that were correct.
[00:10:55] So basically the study you're referring to is the one that says that AI doesn't really help anything or whatever.
[00:10:59] Yeah, it said 95% of AI pilots are garbage.
[00:11:03] But if you read it, it says 63% of ones that were internally created were actually successful.
[00:11:11] Yeah. I don't know how much I believe that kind of data.
[00:11:16] I think it depends on what they mean by pilots and garbage and what does it mean?
[00:11:21] And a lot of people mess around with things and try it the first time.
[00:11:25] And so often the AI adoptions that go to big enterprises, you have a small team is doing almost like skunk works or research.
[00:11:30] Some may become the AI team.
[00:11:32] And they go and they try some stuff and they prototype it and they mess around with it.
[00:11:35] And they're just learning how to use it.
[00:11:36] It's a new technology and it takes time to learn how to use it.
[00:11:39] And then usually there's three places you can implement it as an enterprise.
[00:11:43] You can buy something from a vendor.
[00:11:45] So you're like, I'm going to buy a decagon for customer support or I'm going to buy a bridge for medical scrubbing or whatever it may be.
[00:11:52] And so then there's your vendor selection process and you work with and all this stuff.
[00:11:55] Harvey for legal would be an example of that.
[00:11:58] There's a second set of things that you do, which is internal tooling.
[00:12:03] How do I make my internal teams dramatically more effective?
[00:12:06] How do I build apps for them internally to do things?
[00:12:09] My ops team is doing this repetitive work and use AI for that workflow.
[00:12:13] And then there's stuff that gets it into your own product that you're offering externally to your customers.
[00:12:17] This is sort of the three levels of AI for an enterprise.
[00:12:21] And so when I see a study like that, I'm like, okay, which of these things are they doing?
[00:12:24] And did they try and who is actually working on it?
[00:12:26] And is it the right talent and all the stuff?
[00:12:28] And the reality is if you look at mobile as an example, when mobile first came out,
[00:12:33] everybody said the exact same thing or the internet, right?
[00:12:35] The internet was this giant transformative wave.
[00:12:38] People forget that some companies literally spun out.
[00:12:41] Their internet division is a tracking stock because it would trade so highly
[00:12:45] they could pull in a billion dollars through an IPO of some random piece of whatever business they had.
[00:12:50] And then when those stocks collapsed a few years later as a dot com bubble collapse,
[00:12:53] they rolled them back in super cheap.
[00:12:55] And so it's just a way to are getting some money by branding something as an internet company.
[00:13:02] Again, I think the 90s is a very interesting lesson for today in terms of what we're becoming.
[00:13:06] So if you look at the early mobile wave as an example,
[00:13:10] the first BFA like mobile website was really bad, right?
[00:13:14] You go to this jinky kind of HTML site that was on your phone on your browser
[00:13:18] and you couldn't really do anything and it would crash half the time.
[00:13:21] And then 10 years later you can do these amazing things in the app, right?
[00:13:24] You can scan checks in OCR them.
[00:13:26] You can take out money by tapping it against the ETM in case anybody ever uses cash
[00:13:32] for whatever in affairs things people do.
[00:13:34] Or if you just came up that or you know,
[00:13:37] you can send money really easily with Zell or Venmo or other things.
[00:13:40] And so something that be available up is really useful, right?
[00:13:45] But it took a decade.
[00:13:46] And it just takes time to adopt these things to learn new patterns of usage
[00:13:50] to understand how to use it properly for users to adapt themselves to it.
[00:13:54] So I just think it's going to be one of these long arcs
[00:13:56] and to say that things should immediately be working.
[00:13:58] It's not reflective of any technology wave has ever happened.
[00:14:01] And in the internet people said the internet doesn't matter.
[00:14:03] And in the early crypto days people said crypto doesn't matter.
[00:14:05] And people always say these things don't matter.
[00:14:07] Oh, I remember when people said that SaaS was stupid and cloud was stupid
[00:14:11] because why would an enterprise ever move their data to a third party cloud
[00:14:14] that wasn't secure and you know, it's always the same thing.
[00:14:17] So I just view it as like there's that old saying of old wine and new bottles.
[00:14:22] And I think that's what this is.
[00:14:24] Old wine and new bottles.
[00:14:26] How do you think about, and I'm sure you've talked to like many Fortune 500 CEOs teams about this,
[00:14:33] how do you think about how different companies are approaching AI
[00:14:36] and which ones are doing it right?
[00:14:38] Like what are they looking to do?
[00:14:40] What are the key components of that?
[00:14:42] And then how do you decipher, how do you know like which teams are just not going to make it
[00:14:47] because they're just not thinking about it correctly?
[00:14:49] Yeah, I mean, I think these things are tenure journeys, right?
[00:14:52] So the migration of the cloud has taken 15 years for many companies.
[00:14:57] Some companies are still using cobalt and very old programming languages for the services they run, right?
[00:15:02] You'll literally find a cobalt installation running some core server for a company
[00:15:05] doing payment processing or whatever and it hasn't been touched in 40 years, right?
[00:15:10] So I think people misunderstand the state of software and sophistication
[00:15:16] and they're maybe very sophisticated. They miss how these old legacy things.
[00:15:19] And so it's kind of hard to say, hey, we're just going to grade somebody on something, right?
[00:15:23] There's all these other things moving pieces, how they deal with data, you know,
[00:15:27] the whole migration to a data bricks would be an example of something that some companies are still doing, right?
[00:15:30] To get to data lakes and modern data infrastructure.
[00:15:34] So it's a very uneven world around these things.
[00:15:38] And so often what you need to look for is early adopters.
[00:15:41] And then you can work with them to really help implement something that's very useful for them.
[00:15:45] Or to build on top of this platform that is an example.
[00:15:48] Brinko has the thing I found striking, having worked in different businesses for a long time,
[00:15:52] is in every industry, there's a set of early adopters.
[00:15:56] And they're trying to be the key influencers or decision leaders or opinion leaders in that area.
[00:16:02] So for example, if you're selling HR software, I think it's Costco and Home Depot.
[00:16:06] And if you others are graded adopting new benefits, new HR software, et cetera, which you wouldn't expect, right?
[00:16:12] These are big, you know, impressive enterprises.
[00:16:15] But they often adopt things before younger companies, well, or smaller companies, well.
[00:16:19] And so often what you ask yourself for any new product is who are the taste makers,
[00:16:23] or who are the people who are in general tend to adopt things more.
[00:16:26] And can I work with them first because they'll be fastest, they'll be easiest, they'll be with the most thoughtful,
[00:16:30] they'll give good feedback.
[00:16:31] But they'll also spread it to other people because other HR departments call them for advice and view them as sort of a leader.
[00:16:39] We should talk about the $30 million series A. How did that come together?
[00:16:43] Yeah, I think what we decided to do was there's almost two ways you see people incubate things.
[00:16:49] One is they take a lot of common stock and they try to control the company and they try to...
[00:16:54] And we did the opposite where we said, well, just put money into buyer ownership stakes.
[00:16:58] And you know, the equity should really go to the employees and the founders and the people running it day to day.
[00:17:03] So we kind of approached it as a more traditional financing structure.
[00:17:06] And who was involved?
[00:17:08] Yeah, I mean, we had a great group.
[00:17:10] So I, my fund and Jerry's, which is Affinity, Coletta, so we just put in half.
[00:17:19] And then we had a great sort of bevy of angels across AI, you know...
[00:17:25] Very reasonable.
[00:17:26] I have them.
[00:17:27] Yeah, that would be amazing.
[00:17:28] It's a better clip from you.
[00:17:29] I was trying to tee you up for this.
[00:17:31] Yeah, please.
[00:17:32] Where?
[00:17:33] Oh, here it is.
[00:17:34] I'm memorizing alphabetical order.
[00:17:36] This is going to take a while.
[00:17:38] Yeah.
[00:17:39] It's going to be hard for me to pronounce all their names.
[00:17:41] We have the CEO of Databricks.
[00:17:43] We have Andre Carpathi.
[00:17:44] We have former chairman and CEO of Dow Chemical.
[00:17:47] We have the CEO of Proplexity, CEO of Coinbase, CEO of Applications at OpenAI,
[00:17:52] Chief Product Officer at OpenAI, former chairman and CEO of EY.
[00:17:56] Global co-head of Blackstone Real Estate, founder of Angelus.
[00:18:01] That's an evolved.
[00:18:02] Yeah, evolved great.
[00:18:03] You didn't know.
[00:18:04] Yeah, evolved.
[00:18:05] It's so good.
[00:18:06] Nome Brown, AI Researcher at OpenAI.
[00:18:09] We have Patrick Callison, CEO of Stripe.
[00:18:11] Reid Hoffman.
[00:18:13] We have Sarah Gua, is that how you pronounce it?
[00:18:15] I think so.
[00:18:16] I think it's Gua.
[00:18:17] Well, I've been listening to like a lot of different things,
[00:18:20] pronunciation, pronunciations.
[00:18:21] We should ask her.
[00:18:22] She's a comedian.
[00:18:23] Yeah, she's a caller.
[00:18:24] Sarah Gua.
[00:18:25] Yeah.
[00:18:26] And then we also have the CEO of Together AI.
[00:18:30] How do you get all of these people on one cap table?
[00:18:33] Well, I mean, I think a number of people helped really pull this round together.
[00:18:36] Eric was very involved.
[00:18:37] Jared was involved.
[00:18:38] Dan, the president of the company, you know, really drove the fundraise day to day.
[00:18:43] So I think it's one of those things where people were just very excited about what we were
[00:18:47] doing.
[00:18:48] It was one of those moments where everybody talked to us like,
[00:18:50] of course, this is needed.
[00:18:51] Of course, I've seen use cases.
[00:18:52] Of course, I've seen people ask me about this.
[00:18:54] So I just think it's one of those things where we thought it was a clear indicator
[00:18:58] of just like how interesting and exciting what we're doing is.
[00:19:01] And then as people met, Dan and Clemens and the team, I would get texts where they're
[00:19:06] like, oh, my God, these are really impressive people, right?
[00:19:09] Like, I want to, I want to back whatever these people do.
[00:19:12] So I think it's also the caliber of the people involved operating the company really matters.
[00:19:17] And with Eric Wu, are you guys going to do anything with Open Door?
[00:19:22] Oh, you mean like a take private or something?
[00:19:25] I mean, no, but that was interesting.
[00:19:28] I know that question was leading.
[00:19:30] Maybe they'll be a customer.
[00:19:31] Yeah, they're going to be open door and help fill in that market cap that they just
[00:19:37] got.
[00:19:38] Eric is awesome.
[00:19:39] He's so good.
[00:19:40] It's one of those things where he's so impressive in terms of how good he is at operating
[00:19:44] things and getting things done.
[00:19:46] And thinking about things strategically, like, you know, I backed his very first company
[00:19:50] Movedie like years ago.
[00:19:52] And then I backed Open Door.
[00:19:54] And I've worked with him over the years.
[00:19:56] And then I started working with him on on Branco.
[00:19:59] And I was just so impressed.
[00:20:00] I already knew him and I already knew he was very good, but he's really taking things
[00:20:04] at the next level.
[00:20:05] In today's high speed business world, staying ahead means using the smartest tools possible,
[00:20:10] including the powerful capabilities of artificial intelligence, meet Turing intelligence.
[00:20:14] Turing builds customizable AI systems designed to solve your mission critical challenges,
[00:20:19] no matter your industry.
[00:20:20] From expert guidance to tailored projects, Turing helps top companies realize AI that's
[00:20:25] capable, more adaptable, and more effective.
[00:20:28] With Turing, discover how AI can accelerate your business growth.
[00:20:32] To learn more, visit Turing.com slash sorcery spelled S-O-U-R-C-E-R-Y.
[00:20:39] That's Turing.com slash sorcery.
[00:20:41] Between all of your investments and the companies that you've funded,
[00:20:45] what is the best redemption story that you've seen?
[00:20:47] A redemption story.
[00:20:48] How do you define redemption?
[00:20:50] Coming back from the ashes.
[00:20:51] Oh, I mean, I think there's a couple examples of that.
[00:20:54] What's meant by the ashes, right?
[00:20:56] There's a few founders that I've backed where there are some bumps along the way
[00:21:05] with their first company in one form or another, even if the company was successful.
[00:21:08] An example would be Parker Conrad from Rippling.
[00:21:12] I backed him at Zenefitz.
[00:21:13] I was an angel in that company, and then I invested in the first round of Rippling.
[00:21:16] That was a good example where there was obviously controversy around the company.
[00:21:22] I always thought he was amazing.
[00:21:23] I always thought he would have some amazing redemption arc,
[00:21:26] and so I got involved with Rippling in the very first round
[00:21:28] as sort of a vote of confidence behind him in what he was doing.
[00:21:31] Palmer Lucky is another one where I backed Andrew in the very first round,
[00:21:35] and he was controversial given what happened at Metta early on with him.
[00:21:39] I think in both cases they basically got thrown into the bus in one form or another.
[00:21:43] So I think they deserved that arc.
[00:21:47] So I think they've done amazing things.
[00:21:49] I mean, when I met Jared Kushner, I think similarly,
[00:21:52] the media had portrayed him in a way that was him and Ivanka,
[00:21:55] both actually in a way that was very different from what they're like in person
[00:21:58] in terms of being very smart driven,
[00:22:00] wanting to do the right thing for the world.
[00:22:03] So at this point, I think I've worked with lots of people
[00:22:05] who in one form or another at one time or another had gone a little bit through some firestorm
[00:22:11] and came out the other side stronger and more motivated and crisp on what they care about
[00:22:18] and what's important in life.
[00:22:20] You know, because I think experience is like that for many people.
[00:22:23] And I'm not saying anything specific to any of these individuals.
[00:22:26] I've just observed in general that sometimes a controversy also just makes you crisper about what's important to you,
[00:22:33] like as a person.
[00:22:34] Most of those do run through the media cycles
[00:22:37] and the harsh reality of what can happen to you in the news.
[00:22:42] I'm curious from your standpoint,
[00:22:44] you have podcasts, you put out a book, you're like close to all these worlds,
[00:22:48] these personal stories.
[00:22:50] What do you think people most get wrong about headlines versus reality?
[00:22:54] Oh, I mean, for certain media, the headline is literally the opposite of reality.
[00:22:59] And we've seen that a lot throughout COVID and some of the claims that were made
[00:23:03] and then reversed a year or two later.
[00:23:05] I mean, literally reversed.
[00:23:06] It wasn't like, oh, we were slightly wrong.
[00:23:08] It was we were completely wrong, right on so many topics.
[00:23:12] And so I think it's very hard to trust reasonably large swaths of the media.
[00:23:16] And you've probably heard or talked about like the Marie-Gelle Manifact,
[00:23:19] or Jelman, I never know his name, his name.
[00:23:22] Do you know this whole story?
[00:23:23] Okay, so Michael Crichton, the author who wrote Jurassic Park and all these things,
[00:23:28] was trying to coin a phrase that would reflect a situation
[00:23:32] where say you're reading the New York Times
[00:23:35] and you read an article about something that you're an expert in.
[00:23:39] You're like, oh, my God, they got all this wrong.
[00:23:41] It's complete bullshit.
[00:23:42] And then you flip the page and you read an article about something
[00:23:45] that you don't know anything about and you believe it, right?
[00:23:48] But you just read something that they wrote that was completely false.
[00:23:50] So he called this the Marie-Gelle Manifact because Marie-Gelle Man was a two-time noble physicist
[00:23:55] and so he's trying to choose the name of somebody really smart and attributed to them
[00:23:59] to make the effects seem more wady or important.
[00:24:01] So it was kind of like a branding exercise, the name and effort of this physicist.
[00:24:04] But I think everybody has that, right?
[00:24:07] You'll read something and be like, oh, I know this and this is obviously false
[00:24:10] and then I'll read the next one and be like, oh, of course this must be true.
[00:24:13] And I think one of the big lessons for me was a lot of the stuff is just false
[00:24:18] and a lot of it is manufactured and there's agendas behind these things.
[00:24:21] I don't think it's an accident over and over and over again.
[00:24:23] I think it's purposeful.
[00:24:25] I think it's really bad for society that people act this way.
[00:24:30] But also, I think it just reinforces and it's interesting.
[00:24:34] A lot of the outcry in either traditional media or online is, oh, well, don't trust that person.
[00:24:40] They're not an expert. They haven't, you know, they're looking at the data directly.
[00:24:43] But what did they know? And you're like, well, actually, that's the best way to actually understand things.
[00:24:46] And so I remember early on in COVID, in late January, early February of 2020,
[00:24:53] I actually sent out an email to founder saying, hey, I think this COVID thing is real
[00:24:56] and it's going to be really bad and they may shut down cities and all the stuff, right?
[00:25:00] Because you saw them weld people into their apartments in Wuhan, right?
[00:25:03] Yeah, which doesn't happen.
[00:25:05] It was kind of an out of thing every day.
[00:25:07] Yeah, you kind of notice it if you're paying attention.
[00:25:10] And then a few months later, my chief of staff pulled all the data off of the government websites
[00:25:14] and it was very clear the demographics that were actually impacted by COVID
[00:25:18] and that had very deep policy implications in terms of what you should be doing societally.
[00:25:22] Should you be shutting down schools or not? Probably not actually.
[00:25:25] And so we wrote this up and it got circulated a bunch of governments
[00:25:29] and we got calls from the White House. We got calls from the UK government.
[00:25:32] We actually got a number of phone calls on what we wrote up because it was very data driven.
[00:25:35] It was just like, here's the data.
[00:25:37] And here's some basic implications.
[00:25:39] And then of course policy went in the opposite direction, right?
[00:25:42] But I think it was clear.
[00:25:44] Like what was real, wasn't real quite early.
[00:25:47] So I think you kind of ran into that over and over again.
[00:25:50] And to some extent, if to tie that back to startup investing,
[00:25:53] I think people tend to project a lot of things under the world.
[00:25:58] And there's lots of forms of that.
[00:26:00] As a founder, for example, you project the way that you act on to employees
[00:26:05] if you haven't managed before.
[00:26:07] And founders are perfectly fine with chaos and uncertainty and risk.
[00:26:10] And most people aren't. Most of your employees want a stable direction.
[00:26:14] They want to feel like the thing is working and they want to know where to go.
[00:26:17] But as a founder often early on in your career, you don't provide that
[00:26:19] because you don't realize you're projecting on to people your own viewpoint.
[00:26:22] That happened societally or how do you interpret certain information
[00:26:25] or how do you really see the world in a clear and crisp way?
[00:26:28] And so one of the things I try to do as an investor is ask,
[00:26:30] what is the reality of this thing?
[00:26:31] Not what is the thing?
[00:26:32] I hope it is.
[00:26:33] The thing the founder is telling me that, you know,
[00:26:35] what do I, what is really going to happen here?
[00:26:38] What is the physics of the situation?
[00:26:40] A friend of mine used to work with Steve Jobs.
[00:26:43] And he said that the thing that he felt that Steve Jobs had
[00:26:48] wasn't a reality distortion field.
[00:26:50] You don't change reality.
[00:26:51] Reality is what it is.
[00:26:53] He just was able to see things more crisply
[00:26:56] and articulate them with the fewest number of words in a way
[00:26:59] that would motivate the person to act against that reality.
[00:27:02] So it wasn't reality distortion.
[00:27:04] It was clarity of seeing and clarity of communication.
[00:27:08] And one of the things I found that tends to correlate
[00:27:11] with very good founders is that clarity of thought
[00:27:14] and it's often reflected in crisp communication.
[00:27:18] What's the worst advice you've ever received?
[00:27:20] The worst advice I've ever received?
[00:27:22] I mean, I think there's a lot of advice out there
[00:27:25] that I just don't agree with, like, follow what you're passionate about.
[00:27:28] Really?
[00:27:29] Yeah.
[00:27:30] Why?
[00:27:31] Because most people's passions are really bad dead end things
[00:27:34] to follow, like, realistically, right?
[00:27:36] Do you want to have a good job or not?
[00:27:37] Do you want to have a family?
[00:27:39] Do you want to, you know, et cetera?
[00:27:41] I think, societally, we've been giving really bad advice
[00:27:43] around very basic aspects like that.
[00:27:48] So, you know, one thing I've always wanted to do is,
[00:27:52] like, imagine that I, well, I actually don't want to talk about this.
[00:27:57] I can tell you after I still want to get on there.
[00:28:00] Off the record.
[00:28:01] We have an exclusive.
[00:28:02] Yeah, exactly.
[00:28:03] Print it.
[00:28:04] Yeah, I think that's one piece of advice that usually isn't good.
[00:28:09] Everyone's while your passion lines up with something really important
[00:28:11] for the world or really important for a field or discipline
[00:28:14] or industry or society and great follow your passion.
[00:28:16] But most of the time, it's really bad advice
[00:28:18] and it actually leads people to a suboptimal state in life.
[00:28:22] I've also find that people, you know, sometimes founders ask me,
[00:28:25] what's the biggest way to create a good culture?
[00:28:28] And the answer is winning.
[00:28:30] That's the best way to create a good culture.
[00:28:31] It's not the motivational speeches and the kombucha or what.
[00:28:34] It's like, when you're winning, everybody's excited
[00:28:36] and they want to show up and they want to do good work.
[00:28:39] And that's true in many aspects of life.
[00:28:41] Okay, so sorcery is sponsored by Brex.
[00:28:44] One of your really investments, love Brex.
[00:28:47] And they're all about spending smarter moving faster.
[00:28:51] They are a performance modern intelligence finance platform.
[00:28:55] And I'm really curious from your standpoint on how you manage performance
[00:28:59] between all of your projects.
[00:29:00] You are constantly context switching.
[00:29:03] How do you manage that?
[00:29:04] You know, I'd like to get to, well, I think there's lots of different approaches
[00:29:08] that people take to sort of manage context switching.
[00:29:10] Sometimes people block out hours of the day to do certain things.
[00:29:13] You know, Jack Dorsey, when he was running Twitter and Square famously,
[00:29:17] would have chunks of the day for Square and chunks of the day for Twitter.
[00:29:20] Or so he could just show up and be focused.
[00:29:22] So some people take that approach.
[00:29:24] Obviously, if you have a team, there's things you can delegate specifically
[00:29:27] that allow you to sort of multitask things
[00:29:29] or create a distributed environment to getting things done.
[00:29:31] So I think there's lots of things like that.
[00:29:34] What do you use?
[00:29:35] It's a mixture of some team leverage.
[00:29:37] And then, you know, I think it's just trying to emphasize
[00:29:45] what are the most important things to get done in a given day or week.
[00:29:50] And so sometimes I'll sit down in the morning and say,
[00:29:52] what do I actually have to do today?
[00:29:53] There's all these things I could do today or I'll get sucked into today.
[00:29:55] But what are the two or three things that if I get them done are actually important?
[00:29:59] And then what's that for the week?
[00:30:00] And I think that's really useful.
[00:30:02] One exercise that I'm about to go through is I'm going to try and think 10 years ahead,
[00:30:07] which is of course silly and stupid and it never actually works.
[00:30:10] But I basically want to think in terms of one, three and 10 years
[00:30:14] and think across force fears and kind of plan against that.
[00:30:18] And so I don't want to wake up 10 years from now and say,
[00:30:20] where did the 10 years go?
[00:30:21] John Lennon has this quote that life is what's happening when you're making other plans.
[00:30:25] Right.
[00:30:26] And so this fears I want to start thinking about are obviously there's personal life
[00:30:31] and kids and family and how do you want to think about that?
[00:30:33] There's society and societal impact.
[00:30:35] That's things like the monuments projects or other things like that.
[00:30:38] Like how do you want to actually make the world or your neighborhood or your society better?
[00:30:42] There's the work side of it.
[00:30:44] You know, like what do you want to impact?
[00:30:46] What do you want to build?
[00:30:47] What sort of institution do you want to leave behind?
[00:30:48] Or what do you want to accomplish?
[00:30:50] And that could be impact goals.
[00:30:54] It could be financial goals.
[00:30:55] It could be right different goals.
[00:30:57] And then the last piece is more like how do you think about relevance in the world
[00:31:01] and society over a longer arc?
[00:31:03] And so I'm kind of thinking across those those four things.
[00:31:06] It's a perfect answer.
[00:31:08] Thank you, Brex.
[00:31:09] Sorcery is proudly sponsored by Carta.
[00:31:11] Carta is transforming the private marketplace, connecting founders, investors,
[00:31:16] and limited partners through software purpose built for private capital.
[00:31:20] Trusted by more than 65,000 companies in over 160 countries.
[00:31:24] Carta's platform of software and services lays the groundwork so you can build, invest, and scale with confidence.
[00:31:31] Carta's Fund Administration platform supports over 9,000 funds and SPVs,
[00:31:36] representing nearly $185 billion in assets under management,
[00:31:41] with tools designed to enhance the strategic impact of fund CFOs.
[00:31:45] For more information visit carda.com slash sorcery.
[00:31:49] That's C-A-R-T-A dot com slash S-O-U-R-C-E-R-Y.
[00:31:54] And Rick actually called me and was feeding me that information.
[00:31:58] Really?
[00:31:59] That's great.
[00:32:00] Is he in the room with us right now?
[00:32:01] Yeah, Pedro is in spirit.
[00:32:02] He's with us today.
[00:32:03] Okay, so as we close out, I want to go through some quick future predictions.
[00:32:08] Okay.
[00:32:09] Okay, first we're going to do some from Calche.
[00:32:11] Are you ready for this?
[00:32:12] Yeah.
[00:32:13] It'll be fast.
[00:32:14] Okay.
[00:32:15] When will OpenAI achieve AGI?
[00:32:16] I have no idea.
[00:32:17] Because people always say what's the definition of AGI and what is AGI?
[00:32:20] You know, people always dodge the question that way.
[00:32:22] So it's going to dodge the question.
[00:32:23] Thank you.
[00:32:24] I know what it means.
[00:32:25] Before 2030.
[00:32:26] Before 2020.
[00:32:27] I don't want to buy his Calche.
[00:32:28] I don't want to destroy their marketplace.
[00:32:32] Look, the markets.
[00:32:34] It's up to the markets, free markets.
[00:32:35] Yeah.
[00:32:36] Free markets.
[00:32:37] Yeah.
[00:32:38] Okay.
[00:32:39] This one's a little bit more fun.
[00:32:40] Will a humanoid robot walk on Mars before a human does?
[00:32:43] What do you think the odds are?
[00:32:45] Probably quite high, like 80%.
[00:32:47] Really?
[00:32:48] Why?
[00:32:49] You can send them any time of year.
[00:32:50] The length of the journey doesn't matter.
[00:32:53] You don't need to worry about life support and other systems being built in.
[00:32:56] That are self-sustainable.
[00:32:57] You don't have to worry about food.
[00:32:58] There's a lot of things you don't have to worry about.
[00:33:01] I mean, we've already sent a robot to Mars.
[00:33:03] Right?
[00:33:04] We have Mars Rovers.
[00:33:05] So we've already accomplished that part.
[00:33:06] So a humanoid version of that seems fine.
[00:33:08] I don't know why we care if it's humanoid.
[00:33:10] But let's do it.
[00:33:12] I think they're thinking of Optimus in particular.
[00:33:16] Yeah.
[00:33:17] That probably makes some sense.
[00:33:18] Yeah.
[00:33:19] Somebody's brain uploaded into it.
[00:33:20] I wonder who's brain is going to be?
[00:33:21] Oh my gosh.
[00:33:22] Yeah.
[00:33:23] It's going to be very exciting.
[00:33:24] That's really interesting.
[00:33:25] Well, it's probably...
[00:33:26] Who do you send?
[00:33:28] X-A-I's brain.
[00:33:29] You probably send X-A-I.
[00:33:30] Yeah.
[00:33:31] So it's going to be...
[00:33:32] Everyone's...
[00:33:33] Yeah, it's going to be making memes from Mars.
[00:33:34] That'll be amazing.
[00:33:35] I would be down for that.
[00:33:36] I would love memes from Mars.
[00:33:37] I would follow that.
[00:33:38] On the X.
[00:33:39] Yeah.
[00:33:40] How do they make memes from Mars?
[00:33:42] They would just tweet them.
[00:33:43] They're going to post them.
[00:33:44] I'm sorry.
[00:33:45] They're going to say tweets anywhere.
[00:33:46] I used to work at Twitter or so.
[00:33:47] I think I'm allowed to still use OG terms.
[00:33:49] But most people can't.
[00:33:50] I don't know.
[00:33:51] I'm not the...
[00:33:52] You get banned.
[00:33:53] You get thrown off.
[00:33:54] Yeah.
[00:33:55] Well, right now, the odds for this are at 32%.
[00:33:57] Oh, really?
[00:33:58] I think there's tremendous upside in this one.
[00:34:01] Yeah, I should actually invest in that one.
[00:34:03] That's good.
[00:34:04] On the theme of Outer Space, I really want to get your opinion on this.
[00:34:08] First, on what the odds are for this, and then also your opinion on the topic in general.
[00:34:14] Are you ready?
[00:34:15] Yeah.
[00:34:16] Will the USA that aliens exist this year?
[00:34:18] I think the odds are that are low.
[00:34:20] Just given historical precedent.
[00:34:22] Why?
[00:34:23] Well, just given historical precedent.
[00:34:25] There's three scenarios.
[00:34:27] One is aliens exist, and the US government knows about it, and they won't tell us.
[00:34:32] Why would they tell us specifically this year if they've known for a while?
[00:34:36] There's they don't exist.
[00:34:38] In which case, they could tell us, but then they're lying.
[00:34:41] There's a reason to do that.
[00:34:43] Or they don't exist, and they don't tell us.
[00:34:45] And the last one is that they exist, and they don't know.
[00:34:47] And so if they don't know, why would they sell me discover it this year?
[00:34:50] Do you think they exist?
[00:34:51] I'm sure there's alien intelligence somewhere in the universe.
[00:34:54] It's a big universe.
[00:34:55] I don't know what do you think.
[00:34:56] Definitely.
[00:34:57] Yeah.
[00:34:58] Definitely.
[00:34:59] Do you think you've met alien life?
[00:35:00] Probably.
[00:35:01] Yeah.
[00:35:02] I think this goes kind of weird sometimes.
[00:35:03] Yeah.
[00:35:04] I think I like definitely walked across the street with a few this morning.
[00:35:08] Mm-hmm.
[00:35:09] Yeah.
[00:35:10] It gets a little sketchy, you never know.
[00:35:11] Yeah.
[00:35:12] It's kind of rough.
[00:35:13] Yeah.
[00:35:14] That's why I don't walk around us up anymore.
[00:35:16] The alien life.
[00:35:17] You don't?
[00:35:18] How do you get around?
[00:35:19] Waymo?
[00:35:20] I don't.
[00:35:21] I don't really.
[00:35:22] Yeah.
[00:35:23] I'm not going to do that.
[00:35:24] But thank you.
[00:35:25] The biking or the waymo?
[00:35:26] I'm not going to think.
[00:35:27] Yeah.
[00:35:28] Smart.
[00:35:29] It affects my podcast outfits.
[00:35:30] It's a good optimization function.
[00:35:32] Okay.
[00:35:33] Well, elad, elad.
[00:35:34] It's a pleasure to have you on.
[00:35:36] Molly Malaya.
[00:35:37] Thank you.
[00:35:38] Appreciate it.
[00:35:39] Hey, it's Molly.
[00:35:40] If you enjoyed our interviews, check out our newsletter, sorcery.bc, where we deliver a once-a-week
[00:35:46] top deals and tech headlines email and also go deeper on our podcast interviews.
[00:35:51] Subscribe to sorcery today.
[00:35:53] And don't forget to subscribe to our podcast on YouTube, Spotify, Apple, or wherever you listen.
[00:35:58] Link in description to sign up.