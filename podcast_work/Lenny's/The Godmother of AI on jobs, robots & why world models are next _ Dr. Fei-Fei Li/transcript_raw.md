# The Godmother of AI on jobs, robots & why world models are next | Dr. Fei-Fei Li

**Podcast:** Lenny's
**Date:** 2025-11-16
**Video ID:** Ctjiatnd6Xk
**Video URL:** https://www.youtube.com/watch?v=Ctjiatnd6Xk

---

[00:00:00] A lot of people call you the godmother of AI.
[00:00:02] SPEAKER_00: The work you did actually was the spark
[00:00:04] SPEAKER_00: that brought us out of AI winter.
[00:00:05] SPEAKER_00: In the middle of 2015, middle of 2016,
[00:00:09] SPEAKER_01: some tech companies avoid using the word AI
[00:00:12] SPEAKER_01: because they were not sure if AI was a dirty word.
[00:00:16] SPEAKER_01: 2017-ish was the beginning of companies
[00:00:20] SPEAKER_01: calling themselves AI companies.
[00:00:22] SPEAKER_01: There's this line, I think this was when you're
[00:00:24] SPEAKER_00: presenting to Congress.
[00:00:25] SPEAKER_00: There's nothing artificial about AI.
[00:00:26] SPEAKER_00: It's inspired by people, it's created by people
[00:00:28] SPEAKER_00: and most importantly, it impacts people.
[00:00:30] SPEAKER_00: It's not like I think AI will have no impact on jobs
[00:00:33] SPEAKER_01: or people.
[00:00:34] SPEAKER_01: In fact, I believe that whatever AI does,
[00:00:38] SPEAKER_01: currently or in the future, is up to us.
[00:00:41] SPEAKER_01: It's up to the people.
[00:00:42] SPEAKER_01: I do believe technology is a net positive for humanity,
[00:00:46] SPEAKER_01: but I think every technology is a double-edged sword.
[00:00:49] SPEAKER_01: If we're not doing the right thing
[00:00:52] SPEAKER_01: as a society, as individuals, we can screw this up as well.
[00:00:56] SPEAKER_01: You had this breakthrough inside of just,
[00:00:57] SPEAKER_00: OK, we can train machines to think like humans,
[00:01:00] SPEAKER_00: but it's just missing the data that humans have
[00:01:02] SPEAKER_00: to learn as a child.
[00:01:03] SPEAKER_00: I chose to look at artificial intelligence
[00:01:05] SPEAKER_01: through the lens of visual intelligence
[00:01:08] SPEAKER_01: because humans are deeply visual animals.
[00:01:11] SPEAKER_01: We need to train machines with as much information
[00:01:14] SPEAKER_01: as possible on images of objects.
[00:01:16] SPEAKER_01: But objects are very, very difficult to learn.
[00:01:20] SPEAKER_01: A single object can have infinite possibilities
[00:01:24] SPEAKER_01: that is shown on an image, in order
[00:01:25] SPEAKER_01: to train computers with tens and thousands of object concepts.
[00:01:30] SPEAKER_01: You really need to show it millions of examples.
[00:01:36] Today, my guest is Dr. Fei-Fei Li,
[00:01:38] SPEAKER_00: who's known as the godmother of AI.
[00:01:41] SPEAKER_00: Fei-Fei has been responsible for and at the center
[00:01:43] SPEAKER_00: of many of the biggest breakthroughs
[00:01:45] SPEAKER_00: that sparked the AI revolution they were currently living through.
[00:01:48] SPEAKER_00: She spearheaded the creation of ImageNet, which was basically
[00:01:51] SPEAKER_00: her realizing that AI needed a ton of clean label data
[00:01:55] SPEAKER_00: to get smarter.
[00:01:56] SPEAKER_00: And that data said became deep breakthrough
[00:01:58] SPEAKER_00: that led to the current approach to building and scaling AI models.
[00:02:01] SPEAKER_00: She was chief AI scientist at Google Cloud,
[00:02:04] SPEAKER_00: which is where some of the biggest early technology
[00:02:06] SPEAKER_00: breakthroughs emerged from.
[00:02:07] SPEAKER_00: She was director at SAIL, Stanford's artificial intelligence
[00:02:10] SPEAKER_00: lab, where many of the biggest AI minds came out of.
[00:02:13] SPEAKER_00: She's also a curator of Stanford Human-centered AI
[00:02:16] SPEAKER_00: Institute, which is playing a vital role in a direction
[00:02:19] SPEAKER_00: that AI is taking.
[00:02:20] SPEAKER_00: She's also been on the board of Twitter.
[00:02:22] SPEAKER_00: She was named one of times 100 most influential people in AI.
[00:02:26] SPEAKER_00: She's also the United Nations Advisory Board I could go on.
[00:02:29] SPEAKER_00: In her conversation, Fei-Fei shares a brief history
[00:02:32] SPEAKER_00: of how we got to today in the world of AI,
[00:02:35] SPEAKER_00: including this mind-blowing reminder
[00:02:37] SPEAKER_00: that nine to 10 years ago, calling yourself an AI company
[00:02:40] SPEAKER_00: was basically a death knell for your brand.
[00:02:43] SPEAKER_00: Because no one believed that AI was actually going to work.
[00:02:45] SPEAKER_00: Today, it's completely different.
[00:02:47] SPEAKER_00: Every company is an AI company.
[00:02:49] SPEAKER_00: We also chat about her take on how she sees
[00:02:52] SPEAKER_00: AI impacting humanity in the future.
[00:02:54] SPEAKER_00: How far current technologies will take us?
[00:02:56] SPEAKER_00: Why is she so passionate about building a world model?
[00:02:59] SPEAKER_00: And what exactly world models are?
[00:03:01] SPEAKER_00: And most exciting of all, the launch of the world's first
[00:03:04] SPEAKER_00: large world model, Marble, which just came out
[00:03:07] SPEAKER_00: as this podcast comes out.
[00:03:08] SPEAKER_00: Anyone can go play with this at marble.worldlabs.ai.
[00:03:12] SPEAKER_00: It's insane.
[00:03:13] SPEAKER_00: Definitely check it out.
[00:03:14] SPEAKER_00: Fei-Fei is incredible and way to enter the radar
[00:03:16] SPEAKER_00: for the impact that she's had on the world.
[00:03:18] SPEAKER_00: So I am really excited to have her on
[00:03:20] SPEAKER_00: and to spread her wisdom with more people.
[00:03:22] SPEAKER_00: A huge thank you to Ben Horowitz and Condoleezza Rice
[00:03:25] SPEAKER_00: for suggesting topics for this conversation.
[00:03:27] SPEAKER_00: If you enjoyed this podcast, don't forget
[00:03:29] SPEAKER_00: to subscribe and follow it in your favorite
[00:03:30] SPEAKER_00: podcasting app or YouTube.
[00:03:32] SPEAKER_00: With that, I bring you Dr. Fei-Fei Lee
[00:03:34] SPEAKER_00: after a short work from our sponsors.
[00:03:37] This episode is brought to you by Figma,
[00:03:39] SPEAKER_00: makers of Figma Make.
[00:03:41] SPEAKER_00: When I was a PM at Airbnb, I still remember
[00:03:43] SPEAKER_00: when Figma came out and how much it improved
[00:03:45] SPEAKER_00: how we operated as a team.
[00:03:47] SPEAKER_00: Suddenly, I could involve my whole team
[00:03:49] SPEAKER_00: in the design process, dip feedback on design concepts
[00:03:52] SPEAKER_00: really quickly, and it just made
[00:03:53] SPEAKER_00: the whole product development process so much more fun.
[00:03:56] SPEAKER_00: But Figma never felt like it was for me.
[00:03:58] SPEAKER_00: It was great for giving feedback and designs,
[00:04:01] SPEAKER_00: but as a builder, I wanted to make stuff.
[00:04:03] SPEAKER_00: That's why Figma built Figma Make.
[00:04:06] SPEAKER_00: With just a few prompts, you can make any idea or design
[00:04:09] SPEAKER_00: into a fully functional prototype or app
[00:04:12] SPEAKER_00: that anyone can iterate on and validate with customers.
[00:04:15] SPEAKER_00: Figma Make is a different kind of vibe coding tool.
[00:04:17] SPEAKER_00: Because it's all in Figma, you can use your team's
[00:04:20] SPEAKER_00: existing design building blocks, making it easy to create
[00:04:23] SPEAKER_00: outputs that look good and feel real and are connected
[00:04:26] SPEAKER_00: to how your team builds.
[00:04:28] SPEAKER_00: Stop spending so much time telling people about your
[00:04:30] SPEAKER_00: product vision and instead show it to them.
[00:04:33] SPEAKER_00: Make code back prototypes and apps fast with Figma Make.
[00:04:37] SPEAKER_00: Check it out at figma.com slash running.
[00:04:40] SPEAKER_00: Did you know that I have a whole team that helps me with
[00:04:42] SPEAKER_00: my podcast and with my newsletter?
[00:04:44] SPEAKER_00: I want everyone on my team to be super happy and thrive
[00:04:47] SPEAKER_00: in their roles.
[00:04:48] SPEAKER_00: JustWorks knows that your employees are more than
[00:04:50] SPEAKER_00: just your employees.
[00:04:51] SPEAKER_00: They're your people.
[00:04:53] SPEAKER_00: My team is spread out across Colorado, Australia,
[00:04:55] SPEAKER_00: and Nepal, West Africa, and San Francisco.
[00:04:58] SPEAKER_00: My life would be so incredibly complicated to hire people
[00:05:01] SPEAKER_00: internationally to pay people on time and in their
[00:05:03] SPEAKER_00: local currencies and to answer their HR questions 24-7.
[00:05:07] SPEAKER_00: But with justworks, it's super easy.
[00:05:10] SPEAKER_00: Whether you're setting up your own automated payroll,
[00:05:12] SPEAKER_00: offering premium benefits, or hiring internationally,
[00:05:15] SPEAKER_00: justworks offer simple software and 24-7 human support
[00:05:19] SPEAKER_00: from small business experts for you and your people.
[00:05:21] SPEAKER_00: They do your human resources right so that you can do
[00:05:24] SPEAKER_00: right by your people.
[00:05:25] SPEAKER_00: Justworks for your people.
[00:05:31] Hey, hey, thank you so much for being here and welcome
[00:05:33] SPEAKER_00: to the podcast.
[00:05:34] SPEAKER_00: I'm excited to be here, Lenny.
[00:05:36] SPEAKER_01: I'm even more excited to have you here.
[00:05:38] SPEAKER_00: It is such a treat to get to chat with you.
[00:05:40] SPEAKER_00: There's so much that I want to talk about.
[00:05:42] SPEAKER_00: You've been at the center of this AI explosion that we're
[00:05:45] SPEAKER_00: seeing right now for so long.
[00:05:47] SPEAKER_00: We're going to talk about a bunch of the history that I think
[00:05:49] SPEAKER_00: a lot of people don't even know about how this whole thing
[00:05:52] SPEAKER_00: started.
[00:05:52] SPEAKER_00: But let me first read a quote from Wired
[00:05:54] SPEAKER_00: about you, just so people get a sense.
[00:05:56] SPEAKER_00: And in the intro, I'll share all of the other epic things
[00:05:58] SPEAKER_00: you've done.
[00:05:58] SPEAKER_00: But I think this is a good way to just set context.
[00:06:01] SPEAKER_00: Fei-Fei is one of a tiny group of scientists, a group
[00:06:03] SPEAKER_00: perhaps small enough to fit around a kitchen table who
[00:06:06] SPEAKER_00: are responsible for AI's recent remarkable advances.
[00:06:10] SPEAKER_00: A lot of people call you the godmother of AI.
[00:06:13] SPEAKER_00: And unlike a lot of AI leaders, you're an AI optimist.
[00:06:17] SPEAKER_00: You don't think AI is going to replace us.
[00:06:20] SPEAKER_00: You don't think it's going to take all our jobs.
[00:06:21] SPEAKER_00: You don't think it's going to kill us.
[00:06:22] SPEAKER_00: So I thought it'd be fun to start there.
[00:06:24] SPEAKER_00: Just what's your perspective on how AI is going
[00:06:27] SPEAKER_00: to impact humanity over time?
[00:06:29] SPEAKER_00: Yeah.
[00:06:30] SPEAKER_01: OK.
[00:06:30] SPEAKER_01: So Lenny, let me be very clear.
[00:06:32] SPEAKER_01: I'm not a utopian.
[00:06:34] SPEAKER_01: So it's not like I think AI will have no impact on jobs
[00:06:38] SPEAKER_01: or people.
[00:06:39] SPEAKER_01: In fact, I'm a humanist.
[00:06:41] SPEAKER_01: I believe that whatever AI does, currently
[00:06:47] SPEAKER_01: or in the future, is up to us.
[00:06:49] SPEAKER_01: It's up to the people.
[00:06:50] SPEAKER_01: So I do believe technology is a net positive for humanity.
[00:06:55] SPEAKER_01: If you look at the long course of civilization,
[00:06:58] SPEAKER_01: I think we are an fundamentally
[00:07:02] SPEAKER_01: we're an innovative species that we,
[00:07:06] SPEAKER_01: if you look at from written records thousands of years ago
[00:07:11] SPEAKER_01: to now, humans just kept innovating ourselves
[00:07:15] SPEAKER_01: and innovating our tools.
[00:07:17] SPEAKER_01: And with that, we make lives better.
[00:07:20] SPEAKER_01: We make work better.
[00:07:21] SPEAKER_01: We build civilization.
[00:07:23] SPEAKER_01: And I do believe AI is part of that.
[00:07:26] SPEAKER_01: So that's where the optimism comes from.
[00:07:29] SPEAKER_01: But I think every technology is a double-edged sword.
[00:07:34] SPEAKER_01: And if we're not doing the right thing
[00:07:38] SPEAKER_01: as a species, as a society, as communities, as individuals,
[00:07:44] SPEAKER_01: we can screw this up as well.
[00:07:47] SPEAKER_00: There's this line.
[00:07:47] SPEAKER_00: I think this was when you were presenting to Congress.
[00:07:50] SPEAKER_00: There's nothing artificial about AI.
[00:07:51] SPEAKER_00: It's inspired by people.
[00:07:52] SPEAKER_00: It's created by people and most importantly, it impacts people.
[00:07:56] I don't have a question there, but what are great lines?
[00:07:59] SPEAKER_00: Yeah.
[00:08:00] SPEAKER_01: I feel pretty deeply.
[00:08:02] SPEAKER_01: I started working AI two and a half decades ago,
[00:08:07] SPEAKER_01: and I've been having students for the past two decades.
[00:08:11] SPEAKER_01: And almost every student who graduates,
[00:08:14] SPEAKER_01: I remind them when they graduate from my lab
[00:08:17] SPEAKER_01: that your field is called artificial intelligence,
[00:08:21] SPEAKER_01: but there's nothing artificial about it.
[00:08:23] Coming back to the point, just made about how it's kind
[00:08:25] SPEAKER_00: of up to us, about where this all goes.
[00:08:27] SPEAKER_00: What is it you think we need to get right?
[00:08:28] SPEAKER_00: How do we set things on a path?
[00:08:30] SPEAKER_00: I know this is a very difficult question to answer,
[00:08:33] SPEAKER_00: but just what's your advice?
[00:08:35] SPEAKER_00: What do you think we should be in mind?
[00:08:36] SPEAKER_00: Yeah, like how many hours do we have?
[00:08:38] SPEAKER_01: How do we align AI?
[00:08:40] SPEAKER_00: There we go, let's solve it.
[00:08:41] SPEAKER_00: Yeah, so I think people should be responsible individuals,
[00:08:45] SPEAKER_01: no matter what we do.
[00:08:47] SPEAKER_01: This is what we teach our children,
[00:08:49] SPEAKER_01: and this is what we need to do as grownups as well,
[00:08:52] SPEAKER_01: no matter which part of the AI development or AI deployment
[00:08:59] SPEAKER_01: or AI application you are participating in.
[00:09:03] SPEAKER_01: And most likely many of us, especially as technologists,
[00:09:07] SPEAKER_01: were in multiple points,
[00:09:09] SPEAKER_01: we should act like responsible individuals
[00:09:12] SPEAKER_01: and care about us, actually care a lot about us.
[00:09:16] SPEAKER_01: I think everybody today should care about AI
[00:09:19] SPEAKER_01: because it is going to impact your individual life,
[00:09:23] it is going to impact your community,
[00:09:25] SPEAKER_01: it's going to impact the society and the future generation,
[00:09:29] SPEAKER_01: and caring about it as a responsible person
[00:09:33] SPEAKER_01: is the first but also the most important step.
[00:09:37] Okay, so let me actually take a step back
[00:09:39] SPEAKER_00: and kind of go to the beginning of AI.
[00:09:42] Most people started hearing and caring about AI
[00:09:45] SPEAKER_00: is what it's called today, just like, I don't know,
[00:09:48] SPEAKER_00: a few years ago when Chatshey PT came out,
[00:09:49] SPEAKER_00: maybe it was like three years ago.
[00:09:51] SPEAKER_01: Three years ago, almost one more month, three years ago.
[00:09:54] SPEAKER_01: Wow, okay, that was Chatshey PT coming out,
[00:09:56] SPEAKER_00: is that the milestone?
[00:09:57] SPEAKER_00: Yeah, mine, okay, cool.
[00:09:58] SPEAKER_00: That's exactly how I saw it.
[00:10:00] SPEAKER_00: But very few people know there was a long, long history
[00:10:02] SPEAKER_00: of people working on, it was called machine learning back then
[00:10:05] SPEAKER_00: and there's other terms and now it's just everything's AI.
[00:10:07] SPEAKER_00: And there was kind of like a long period
[00:10:09] SPEAKER_00: of just a lot of people working on it
[00:10:11] SPEAKER_00: and then there's what people were first used to the AI winter
[00:10:13] SPEAKER_00: where people just gave up, almost most people did
[00:10:15] SPEAKER_00: and just, okay, this idea isn't going anywhere.
[00:10:19] SPEAKER_00: And then the work you did actually was essentially the spark
[00:10:21] SPEAKER_00: that brought us out of AI winter
[00:10:23] SPEAKER_00: and is directly responsible for the world
[00:10:26] SPEAKER_00: where now just AI is all we talk about as you just said,
[00:10:28] SPEAKER_00: it's gonna impact everything we do.
[00:10:31] SPEAKER_00: So that would be really interesting to hear from you,
[00:10:32] SPEAKER_00: just kind of like the brief history
[00:10:34] SPEAKER_00: of what the world was like before ImageNet,
[00:10:38] SPEAKER_00: then just the work you did to create ImageNet,
[00:10:41] SPEAKER_00: why that was so important
[00:10:42] SPEAKER_00: and then just what happened after?
[00:10:44] It is for me hard to keep in mind that AI is so new
[00:10:49] SPEAKER_01: for everybody.
[00:10:50] SPEAKER_01: When I lived my entire professional life in AI,
[00:10:55] SPEAKER_01: it's there's a part of me that it's just,
[00:10:58] SPEAKER_01: it's so satisfying to see a personal curiosity
[00:11:02] SPEAKER_01: that I started barely out of teenage hood
[00:11:06] SPEAKER_01: and now has become a transformative force
[00:11:11] of our civilization.
[00:11:13] SPEAKER_01: It generally is a civilization level technology.
[00:11:17] SPEAKER_01: So that journey is about about 30 years
[00:11:21] SPEAKER_01: or 20 something, 20 plus years
[00:11:24] SPEAKER_01: and it's just very satisfying.
[00:11:27] SPEAKER_01: So where did I all start?
[00:11:29] SPEAKER_01: Well, I'm not even the first generation AI researcher.
[00:11:32] SPEAKER_01: The first generation really date back to the 50s and 60s
[00:11:37] SPEAKER_01: and Alan Turing was ahead of his time by in the 40s
[00:11:42] SPEAKER_01: by asking daring humanity with the question,
[00:11:45] SPEAKER_01: can we is there thinking machines?
[00:11:48] SPEAKER_01: And of course, he has a specific way
[00:11:51] SPEAKER_01: of testing this concept of thinking machine
[00:11:55] SPEAKER_01: which is a conversational chapot,
[00:11:58] SPEAKER_01: which to his standard, we now have a thinking machine
[00:12:02] SPEAKER_01: but that was just a more anecdotal inspiration.
[00:12:08] SPEAKER_01: The field really began in the 50s
[00:12:11] SPEAKER_01: when computer scientists came together
[00:12:13] SPEAKER_01: and look at how we can use computer programs
[00:12:17] SPEAKER_01: and algorithms to build these programs
[00:12:22] that can do things that have been only capable
[00:12:27] SPEAKER_01: by human cognition.
[00:12:29] SPEAKER_01: So and that was the beginning and the founding fathers,
[00:12:33] SPEAKER_01: the Dartmouth, the workshop in the 1956.
[00:12:37] SPEAKER_01: You know, we have Professor John McCarthy
[00:12:39] SPEAKER_01: who later came to Stanford
[00:12:41] SPEAKER_01: who coined the term artificial intelligence.
[00:12:45] SPEAKER_01: And between the 50s, 60s, 70s and 80s,
[00:12:49] SPEAKER_01: it was the early days of AI exploration
[00:12:53] SPEAKER_01: and we had logic systems, we had expert systems,
[00:12:58] SPEAKER_01: we also had early exploration of neural network.
[00:13:02] SPEAKER_01: And then it came to around the late 80s, the 90s
[00:13:07] SPEAKER_01: and the very beginning of the 21st century.
[00:13:12] SPEAKER_01: That stretch about 20 years
[00:13:15] SPEAKER_01: is actually the beginning of machine learning.
[00:13:17] SPEAKER_01: It's the marriage between computer programming
[00:13:20] SPEAKER_01: and statistical learning.
[00:13:23] SPEAKER_01: And that marriage brought a very, very critical concept
[00:13:28] SPEAKER_01: into AI, which is that purely rule-based program
[00:13:34] SPEAKER_01: is not gonna account for the vast amount
[00:13:40] SPEAKER_01: of cognitive capabilities that we imagine computers can do.
[00:13:46] So we have to use machines to learn the patterns.
[00:13:51] SPEAKER_01: Once the machines can learn the patterns,
[00:13:53] SPEAKER_01: it has the hope to do more things.
[00:13:56] SPEAKER_01: For example, if you give it three cats,
[00:13:59] SPEAKER_01: the hope is not just for the machines
[00:14:01] SPEAKER_01: to recognize these three cats,
[00:14:03] SPEAKER_01: the hope is the machines can recognize the fourth cat,
[00:14:07] SPEAKER_01: the fifth cat, the sixth cat and all the other cats.
[00:14:10] SPEAKER_01: And that's a learning ability
[00:14:12] SPEAKER_01: that is fundamental to humans and the many animals.
[00:14:16] SPEAKER_01: And we as a field realize we need machine learning.
[00:14:21] SPEAKER_01: So that was up till the beginning of the 21st century.
[00:14:26] I enter the field of AI literally in the year of 2000.
[00:14:30] SPEAKER_01: That's when my PhD began at Caltech.
[00:14:33] SPEAKER_01: And so I was one of the first generation
[00:14:36] SPEAKER_01: machine learning researchers.
[00:14:37] SPEAKER_01: And we were already studying this concept of machine learning
[00:14:41] SPEAKER_01: especially in your network.
[00:14:43] SPEAKER_01: I remember that was one of my first courses
[00:14:46] SPEAKER_01: in the at Caltech is called your network.
[00:14:49] But it was very painful.
[00:14:50] SPEAKER_01: It was still smack in the middle of the so-called AI winter,
[00:14:54] SPEAKER_01: meaning the public didn't look at this too much.
[00:14:57] SPEAKER_01: There wasn't that much funding.
[00:14:59] SPEAKER_01: But there was also a lot of ideas flowing around.
[00:15:03] SPEAKER_01: And I think two things happened to myself
[00:15:07] SPEAKER_01: that brought my own career so close to the birth of modern AI
[00:15:12] SPEAKER_01: is that I chose to look at artificial intelligence
[00:15:17] SPEAKER_01: through the lens of visual intelligence.
[00:15:19] SPEAKER_01: Because humans are deeply visual animals.
[00:15:24] SPEAKER_01: We can talk a little more later,
[00:15:26] SPEAKER_01: but so much of our intelligence is built upon visual,
[00:15:31] SPEAKER_01: perceptual, spatial understanding,
[00:15:33] SPEAKER_01: not just language per se.
[00:15:35] SPEAKER_01: I think they're complementary.
[00:15:37] SPEAKER_01: So I chose to look at visual intelligence.
[00:15:39] SPEAKER_01: And my PhD and my early professor years,
[00:15:44] SPEAKER_01: I, my students and I are very committed to a North Star
[00:15:48] SPEAKER_01: problem, which is solving the problem of object recognition.
[00:15:52] SPEAKER_01: Because it's a building block for the perceptual world,
[00:15:55] SPEAKER_01: right? We go around the world,
[00:15:57] SPEAKER_01: interpreting, reasoning, and interacting with it,
[00:16:01] SPEAKER_01: more or less at the object level.
[00:16:03] SPEAKER_01: We don't interact with the world at the molecular level.
[00:16:07] SPEAKER_01: We don't interact with the world as we sometimes do,
[00:16:11] SPEAKER_01: but we rarely, for example, if you wanna lift a teapot,
[00:16:15] SPEAKER_01: you don't say, okay, the teapot is made of 100 pieces of porcelain.
[00:16:19] SPEAKER_01: And let me work on these 100 pieces.
[00:16:22] SPEAKER_01: You look at this as one object and interact with it.
[00:16:25] SPEAKER_01: So object is really important.
[00:16:27] SPEAKER_01: So I was among the first researchers to identify this
[00:16:33] SPEAKER_01: as a North Star problem.
[00:16:35] But I think what happened is that as a student of AI,
[00:16:40] SPEAKER_01: and then a researcher of AI, I was working on all kinds
[00:16:45] SPEAKER_01: of mathematical models, including your network,
[00:16:48] SPEAKER_01: including Bayesian network, including many models,
[00:16:53] SPEAKER_01: and there was one singular pain point,
[00:16:56] SPEAKER_01: is that these models don't have data to be trained up.
[00:16:59] And as a field, we were so focusing on these models,
[00:17:04] SPEAKER_01: but it don't down me that human learning,
[00:17:09] as well as evolution, is actually a big data learning process.
[00:17:14] SPEAKER_01: Humans learn with so much experience constantly
[00:17:19] SPEAKER_01: and evolution, if you look at time,
[00:17:21] SPEAKER_01: animals evolved with just experiencing the world.
[00:17:25] SPEAKER_01: So I think my student and I conjectured
[00:17:29] SPEAKER_01: that very critically overlooked ingredient
[00:17:34] SPEAKER_01: of bringing AI to life is big data.
[00:17:37] SPEAKER_01: And then we began this image data project in 2006, 2007.
[00:17:42] SPEAKER_01: We were very ambitious.
[00:17:44] SPEAKER_01: We wanna get the entire internet's image data on objects.
[00:17:49] SPEAKER_01: Now granted, internet was a lot smaller than today.
[00:17:52] SPEAKER_01: So I feel like that emission was at least not too crazy.
[00:17:57] SPEAKER_01: Now it's totally delusional to think
[00:18:02] SPEAKER_01: a couple of grander students and the professor can do this.
[00:18:05] SPEAKER_01: But and that's what we did.
[00:18:07] SPEAKER_01: We curated very carefully 15 million images
[00:18:11] SPEAKER_01: on the internet, created a taxonomy of 22,000 concepts,
[00:18:16] SPEAKER_01: borrowing other researchers work like linguists work on wordnet.
[00:18:20] SPEAKER_01: And it's a particular way of dictionary words.
[00:18:28] SPEAKER_01: And we combine that into image data.
[00:18:31] SPEAKER_01: And we open source that to the research community,
[00:18:34] SPEAKER_01: we held an annual image that challenged to encourage
[00:18:39] SPEAKER_01: everybody to participate in this.
[00:18:42] SPEAKER_01: We continue to do our own research.
[00:18:44] SPEAKER_01: But 2012 was the moment that many people think
[00:18:48] SPEAKER_01: was the beginning of the deep learning
[00:18:50] SPEAKER_01: or birth of modern AI because a group of Toronto researchers
[00:18:54] SPEAKER_01: led by Professor Jeff Hinton participated in image
[00:18:58] SPEAKER_01: that challenge, used the image that big data
[00:19:02] SPEAKER_01: and two GPUs from Nvidia and created successfully
[00:19:06] SPEAKER_01: the first neural network algorithm that can,
[00:19:11] it didn't totally solve a major huge progress
[00:19:16] SPEAKER_01: towards solving the problem of object recognition.
[00:19:20] And that combination of the TREAL technology,
[00:19:24] SPEAKER_01: big data neural network and GPU was kind of the golden recipe
[00:19:31] SPEAKER_01: for modern AI.
[00:19:32] SPEAKER_01: And then fast forward the public moment of AI,
[00:19:38] SPEAKER_01: which is the chat GPD moment,
[00:19:41] SPEAKER_01: if you look at the ingredients of what brought chat GPD
[00:19:46] SPEAKER_01: to the world, technically is still use these three ingredients.
[00:19:53] SPEAKER_01: Now it's internet scale data, mostly texts,
[00:19:57] SPEAKER_01: is a much more complex neural network architecture than 2012
[00:20:03] SPEAKER_01: but it's still neural network.
[00:20:05] SPEAKER_01: And a lot more GPUs but it's still GPUs.
[00:20:09] SPEAKER_01: So these three ingredients are still at the core of modern AI.
[00:20:16] Incredible.
[00:20:17] SPEAKER_00: I have never heard that full story before.
[00:20:19] SPEAKER_00: I love that it was two GPUs was the first,
[00:20:23] I love that, just kidding.
[00:20:25] And now it's like I don't know, hundreds of thousands, right?
[00:20:27] SPEAKER_00: That are orders of magnitudes more powerful.
[00:20:31] SPEAKER_00: And those two GPUs where they were like gaming GPUs,
[00:20:34] SPEAKER_00: they just went to the like the game star, right?
[00:20:35] SPEAKER_00: They were people used for playing games.
[00:20:37] SPEAKER_00: As you said, this continues to be in a large way
[00:20:39] SPEAKER_00: the way models get smarter.
[00:20:41] SPEAKER_00: Some of the fastest growing companies in the world right now
[00:20:43] SPEAKER_00: I've had them all mostly on the podcast,
[00:20:45] SPEAKER_00: Merchord, Surgeon, Scale.
[00:20:46] SPEAKER_00: Like they do this, they continue to do this for labs,
[00:20:49] SPEAKER_00: just give them more and more label data
[00:20:51] SPEAKER_00: of the things they're most excited about.
[00:20:52] SPEAKER_00: Oh yeah, I remember Alex Wang from Scale very early days,
[00:20:57] SPEAKER_01: I probably still has his emails when he was starting scale.
[00:21:00] SPEAKER_01: He was very kind.
[00:21:02] SPEAKER_01: He keeps sending me emails about how you match that inspired scale.
[00:21:07] SPEAKER_01: I was very pleased to see that.
[00:21:09] One of my other favorite takeaways from what you just shared
[00:21:11] SPEAKER_00: is just such an example of high agency
[00:21:13] SPEAKER_00: and just doing things.
[00:21:15] SPEAKER_00: That's kind of a me-month Twitter.
[00:21:16] SPEAKER_00: Just you can just do things.
[00:21:17] SPEAKER_00: You're just like, okay, this is probably necessary to move AI.
[00:21:21] SPEAKER_00: And it's called machine learning back then, right?
[00:21:23] SPEAKER_00: Was that the term most people used?
[00:21:25] I think it was interchangeably.
[00:21:27] SPEAKER_01: It's true.
[00:21:28] SPEAKER_01: Like I do remember the companies, the tech companies,
[00:21:31] SPEAKER_01: I'm not going to name names,
[00:21:33] SPEAKER_01: but I was in a conversation in one of the early days.
[00:21:38] SPEAKER_01: I think it is in the middle of 2015, middle of 2016.
[00:21:43] SPEAKER_01: Some tech companies avoid using the word AI
[00:21:47] SPEAKER_01: because they were not sure if AI was a dirty word.
[00:21:51] SPEAKER_01: And I remember I was actually encouraging everybody
[00:21:55] SPEAKER_01: to use the word AI because to me,
[00:21:58] SPEAKER_01: that is one of the most audacious question humanity
[00:22:02] SPEAKER_01: has ever asked in our quest for science and technology.
[00:22:06] SPEAKER_01: And I feel very proud of this term.
[00:22:08] SPEAKER_01: But yes, at the beginning,
[00:22:10] SPEAKER_01: some people were not sure.
[00:22:12] SPEAKER_01: What year was that roughly when AI was already working?
[00:22:14] SPEAKER_00: 2016.
[00:22:15] SPEAKER_00: I think it was less than 10 years ago.
[00:22:17] SPEAKER_01: That was the changing.
[00:22:19] SPEAKER_01: Like some people start calling it AI.
[00:22:23] But I think if you look at the Silicon Valley tech company,
[00:22:28] SPEAKER_01: if you trace their marketing term,
[00:22:31] SPEAKER_01: I think 2017-ish was the beginning of companies
[00:22:37] SPEAKER_01: calling themselves AI companies.
[00:22:40] That's incredible.
[00:22:41] SPEAKER_00: Just how the world has changed.
[00:22:43] SPEAKER_00: Now you can't not call yourself an AI company.
[00:22:46] SPEAKER_00: I know.
[00:22:47] SPEAKER_00: Just nine-ish years later.
[00:22:48] SPEAKER_00: Yeah.
[00:22:49] SPEAKER_00: Oh, man.
[00:22:50] SPEAKER_00: Okay.
[00:22:51] SPEAKER_00: Is there anything else around the history,
[00:22:52] SPEAKER_00: that early history that you think people don't know?
[00:22:54] SPEAKER_00: They think it's important before we chat about
[00:22:57] SPEAKER_00: where things are going and the work that you're doing.
[00:23:01] SPEAKER_01: I think as all histories, I'm keenly aware
[00:23:05] SPEAKER_01: that I am recognized for being part of the history,
[00:23:09] SPEAKER_01: but there are so many heroes and so many researchers.
[00:23:12] SPEAKER_01: We're talking about generations of researchers.
[00:23:15] SPEAKER_01: They're in my own world.
[00:23:18] SPEAKER_01: There are so many people who have inspired me,
[00:23:21] SPEAKER_01: which I talked about in my book.
[00:23:24] SPEAKER_01: But I do feel our culture,
[00:23:27] SPEAKER_01: especially the Silicon Valley,
[00:23:29] SPEAKER_01: tends to assign achievements to a single person.
[00:23:35] SPEAKER_01: While I think it has value,
[00:23:38] SPEAKER_01: but it's just to be remembered,
[00:23:41] SPEAKER_01: AI is a field of at this point, 70 years old,
[00:23:44] SPEAKER_01: and we have gone through many generations.
[00:23:48] SPEAKER_01: Nobody, no one,
[00:23:51] SPEAKER_01: could have gotten here by themselves.
[00:23:53] SPEAKER_01: Okay.
[00:23:54] SPEAKER_00: Let me ask you this question.
[00:23:56] SPEAKER_00: It feels like we're always on this precipice of AI,
[00:23:58] SPEAKER_00: this kind of vague term, people throw around,
[00:24:00] SPEAKER_00: AI is coming, it's gonna take over everything.
[00:24:03] SPEAKER_00: How, what's your take on?
[00:24:05] SPEAKER_00: How far you think we might be from AI?
[00:24:06] SPEAKER_00: Do you think we're gonna get there on the current trajectory?
[00:24:09] SPEAKER_00: Or on do you think we need more break views?
[00:24:10] SPEAKER_00: Do you think the current approach will get us there?
[00:24:13] Yeah, this is a very interesting term, Lenny.
[00:24:17] I don't know if anyone has ever defined AI.
[00:24:22] You know, there are many different definitions,
[00:24:26] SPEAKER_01: including some kind of superpower for machines,
[00:24:30] SPEAKER_01: all the way to can,
[00:24:33] SPEAKER_01: machines can become economically viable agents
[00:24:37] SPEAKER_01: in the society.
[00:24:40] SPEAKER_01: In other words, making salaries to live.
[00:24:43] SPEAKER_01: Is that a definition of AI?
[00:24:45] SPEAKER_01: As a scientist, I take science very seriously,
[00:24:49] SPEAKER_01: and I enter the field because I was inspired
[00:24:53] SPEAKER_01: by this audacious question of chemistings,
[00:24:57] SPEAKER_01: think and do things in the way that human can do.
[00:25:02] SPEAKER_01: For me, that's always the North start of AI.
[00:25:05] SPEAKER_01: And from that point of view,
[00:25:07] SPEAKER_01: I don't know what's the difference between AI and AI.
[00:25:10] SPEAKER_01: I think we've done very well in achieving parts of the goal,
[00:25:15] SPEAKER_01: including conversational AI,
[00:25:18] SPEAKER_01: but I don't think we have completely conquered all the goals of AI.
[00:25:23] SPEAKER_01: And I think our founding fathers, the Alan Turing,
[00:25:27] I wonder if Alan Turing is around today,
[00:25:30] SPEAKER_01: and you ask him to contrast the AI versus AI.
[00:25:34] SPEAKER_01: Team I just shrugged and said,
[00:25:36] SPEAKER_01: well, I asked the same question back in 1940s.
[00:25:40] SPEAKER_01: So I don't want to get on to a rabbit hole
[00:25:44] SPEAKER_01: of defining AI versus AI.
[00:25:47] SPEAKER_01: I feel AI is more a marketing term than a scientific term.
[00:25:52] SPEAKER_01: As a scientist and technologist,
[00:25:55] SPEAKER_01: AI is my North star, is my field's North star,
[00:25:59] SPEAKER_01: and I'm happy people call it whatever name they want to call it.
[00:26:05] So let me ask you, maybe this way,
[00:26:07] SPEAKER_00: like you described, there's kind of these components
[00:26:09] SPEAKER_00: that from ImageNet and AlexNet kind of took us to where we're today,
[00:26:13] SPEAKER_00: GPUs, essentially data, label data,
[00:26:17] SPEAKER_00: just like the algorithm of the model.
[00:26:19] SPEAKER_00: There is also just a transformer,
[00:26:21] SPEAKER_00: feels like an important step in that trajectory.
[00:26:24] SPEAKER_00: Do you feel like those are the same components that'll get us to,
[00:26:27] SPEAKER_00: I don't know, 10 times smarter model,
[00:26:29] SPEAKER_00: something that's like life changing for the entire world?
[00:26:32] SPEAKER_00: Or do you think we need more breakthroughs?
[00:26:34] SPEAKER_00: I know we're going to talk about world models,
[00:26:35] SPEAKER_00: which I think is a component of this,
[00:26:37] SPEAKER_00: but is there anything else that you think is like,
[00:26:39] SPEAKER_00: oh, this is a plateau, or okay, this will take us,
[00:26:42] SPEAKER_00: just need more data, more compute, more GPUs.
[00:26:44] Oh no, I definitely think we need more innovations.
[00:26:47] SPEAKER_01: I think scaling loss of more data, more GPUs,
[00:26:51] SPEAKER_01: and bigger current model architecture,
[00:26:54] SPEAKER_01: is there's still a lot to be done there,
[00:26:58] SPEAKER_01: but I absolutely think we need to innovate more.
[00:27:01] SPEAKER_01: There's not a single deeply scientific discipline
[00:27:06] SPEAKER_01: in human history that has arrived at a place that says,
[00:27:11] SPEAKER_01: we're done, we're done innovating.
[00:27:13] SPEAKER_01: And AI is one of the,
[00:27:16] SPEAKER_01: if not the youngest discipline in human civilization
[00:27:20] SPEAKER_01: in terms of science and technology,
[00:27:22] SPEAKER_01: we're still scratching the surface.
[00:27:25] SPEAKER_01: For example, like I said, we're going to segue into world models.
[00:27:29] SPEAKER_01: Today you take a model and run it through a video
[00:27:35] SPEAKER_01: of a couple of office rooms
[00:27:38] SPEAKER_01: and ask the model to count the number of chairs.
[00:27:41] SPEAKER_01: And this is something a toddler could do,
[00:27:43] SPEAKER_01: or maybe an elementary school kid could do,
[00:27:48] and AI could not do that, right?
[00:27:50] SPEAKER_01: So there's just so much AI today could not do.
[00:27:53] SPEAKER_01: Then let alone thinking about how did you know,
[00:27:59] someone like Isaac Newton look at the movements
[00:28:02] SPEAKER_01: of the celestial bodies and derive an equation
[00:28:08] SPEAKER_01: or a set of equations that governs the movement
[00:28:12] SPEAKER_01: of all bodies, that level of creativity, extrapolation,
[00:28:16] SPEAKER_01: abstraction, we have no way of enabling AI to do that today.
[00:28:23] SPEAKER_01: And then let's look at emotional intelligence.
[00:28:25] SPEAKER_01: If you look at a student coming to a teacher's office
[00:28:30] SPEAKER_01: and have a conversation about motivation, passion,
[00:28:34] SPEAKER_01: what to learn, what's the problem that's really bothering you,
[00:28:41] SPEAKER_01: that conversation as powerful as today's conversational bots
[00:28:46] SPEAKER_01: are you don't get that level of emotional cognitive intelligence
[00:28:52] SPEAKER_01: from today's AI.
[00:28:53] SPEAKER_01: So there's a lot we can do better.
[00:28:57] And I do not believe we're done innovating.
[00:29:00] SPEAKER_01: Demis had this really interesting interview recently
[00:29:02] SPEAKER_00: from DeepMind and Sasha Google,
[00:29:03] SPEAKER_00: where someone asked him just like,
[00:29:04] SPEAKER_00: what do you think, how far away from AGI,
[00:29:07] SPEAKER_00: what does it look like, we're through there.
[00:29:08] SPEAKER_00: He had a really interesting way of approaching it
[00:29:10] SPEAKER_00: is if we were to give them the most cutting edge model,
[00:29:13] SPEAKER_00: all the information until the end of the 20th century,
[00:29:17] SPEAKER_00: see if it could come up with all the breakthroughs Einstein had,
[00:29:20] SPEAKER_00: and so far we're never near that.
[00:29:21] SPEAKER_00: But they can see.
[00:29:22] SPEAKER_00: No, we're not.
[00:29:23] SPEAKER_01: In fact, it's even worse.
[00:29:25] SPEAKER_01: Let's give AI all the data,
[00:29:29] SPEAKER_01: including modern instruments data of celestial bodies,
[00:29:33] SPEAKER_01: which Newton did not have, and give it to that,
[00:29:36] SPEAKER_01: and just ask AI to create the 17th century set of equations
[00:29:42] SPEAKER_01: on the laws of bodily movements.
[00:29:46] SPEAKER_01: Today's AI can all do that.
[00:29:49] SPEAKER_00: All right, we're away the way.
[00:29:50] SPEAKER_00: So what I mean here.
[00:29:51] Okay, so let's talk about world models.
[00:29:52] SPEAKER_00: This is, to me, this is just another really amazing example
[00:29:56] SPEAKER_00: of you being ahead of where people end up.
[00:30:00] SPEAKER_00: So you were way ahead on, okay,
[00:30:02] SPEAKER_00: we just need a lot of clean data for AI
[00:30:05] SPEAKER_00: and neural networks to learn.
[00:30:07] SPEAKER_00: You've been talking about this idea of world models
[00:30:08] SPEAKER_00: for a long time, you started a company to build.
[00:30:11] SPEAKER_00: Essentially, there's language models.
[00:30:12] SPEAKER_00: This is a different thing.
[00:30:13] SPEAKER_00: This is a world model.
[00:30:14] SPEAKER_00: We'll talk about that is.
[00:30:15] SPEAKER_00: And now, as I was preparing for this,
[00:30:17] SPEAKER_00: Elon's like talking about world models,
[00:30:19] SPEAKER_00: Jensen's talking about world models.
[00:30:21] SPEAKER_00: I know Google's working on this stuff.
[00:30:22] SPEAKER_00: You've been at this for a long time,
[00:30:24] SPEAKER_00: and you're actually just launching something that's gonna,
[00:30:26] SPEAKER_00: we're gonna talk about right before the spot cast errors.
[00:30:31] SPEAKER_00: Talk about what is a world model?
[00:30:32] SPEAKER_00: Why is it so important?
[00:30:33] SPEAKER_00: I'm very excited to see that more and more people
[00:30:36] SPEAKER_01: are talking about world models like Elon, like Jensen.
[00:30:43] I have been thinking about really how to push AI forward
[00:30:48] SPEAKER_01: all my life, right?
[00:30:51] SPEAKER_01: And the large language models that came out
[00:30:55] SPEAKER_01: of the research world and then open AI and all this.
[00:31:00] SPEAKER_01: For the past few years,
[00:31:02] were extremely inspiring,
[00:31:04] SPEAKER_01: even for a researcher like me.
[00:31:07] SPEAKER_01: I remembered when GPT2 came out,
[00:31:11] SPEAKER_01: and that was in, I think late 2020,
[00:31:15] SPEAKER_01: I was co-director, I still am,
[00:31:19] SPEAKER_01: but I was at that time full-time co-director
[00:31:22] SPEAKER_01: of Stanford's Human Center AI Institute.
[00:31:25] SPEAKER_01: And I remember it was,
[00:31:28] SPEAKER_01: the public was not aware of the power
[00:31:30] SPEAKER_01: of the large language model yet,
[00:31:32] SPEAKER_01: but as researchers, we were seeing it,
[00:31:35] SPEAKER_01: we're seeing the future.
[00:31:36] SPEAKER_01: And I had pretty long conversations
[00:31:38] SPEAKER_01: with my natural language processing colleagues,
[00:31:43] SPEAKER_01: like Percy Liang and Chris Madding,
[00:31:45] SPEAKER_01: we were talking about how critical this technology
[00:31:48] SPEAKER_01: is gonna be,
[00:31:50] SPEAKER_01: and Stanford AI Institute,
[00:31:52] SPEAKER_01: Human Center AI Institute,
[00:31:53] SPEAKER_01: HAI was the first one to establish a full research center
[00:31:59] SPEAKER_01: on foundation model.
[00:31:59] SPEAKER_01: We were Percy Liang and many researchers
[00:32:02] SPEAKER_01: led the first academic paper foundation model.
[00:32:06] SPEAKER_01: So it was just very inspiring for me.
[00:32:10] SPEAKER_01: So of course, I come from the world of visual intelligence,
[00:32:14] SPEAKER_01: and I was just thinking there's so much we can push forward
[00:32:19] SPEAKER_01: on beyond language, because humans have,
[00:32:27] SPEAKER_01: use our sense of spatial intelligence,
[00:32:30] SPEAKER_01: a world understanding to do so many things,
[00:32:33] SPEAKER_01: and they are beyond language.
[00:32:36] SPEAKER_01: Think about a very chaotic first responder scene,
[00:32:41] SPEAKER_01: whether it's fire or some traffic accident
[00:32:44] SPEAKER_01: or some natural disaster.
[00:32:47] And if you immerse yourself in a scene
[00:32:52] SPEAKER_01: and think about how people organize themselves
[00:32:55] SPEAKER_01: to rescue people, to stop further disasters,
[00:32:59] SPEAKER_01: to put down fires,
[00:33:01] SPEAKER_01: to a lot of that is movements,
[00:33:05] SPEAKER_01: is spontaneous understanding of objects worlds,
[00:33:10] SPEAKER_01: human situation awareness, language is part of that,
[00:33:16] SPEAKER_01: but a lot of those situations,
[00:33:18] SPEAKER_01: language cannot get you to put down the fire.
[00:33:21] SPEAKER_01: So that is what is that?
[00:33:24] SPEAKER_01: I was thinking a lot,
[00:33:25] SPEAKER_01: and in the meantime, I was doing a lot of robotics research,
[00:33:29] SPEAKER_01: and it dawned on me that the linchpin of connecting
[00:33:37] the additional intelligence,
[00:33:39] SPEAKER_01: in addition to language,
[00:33:41] SPEAKER_01: and connecting embodied AI, which are robotics,
[00:33:46] SPEAKER_01: connecting visual intelligence,
[00:33:48] SPEAKER_01: is the sense of spatial intelligence
[00:33:51] SPEAKER_01: about understanding the world.
[00:33:53] SPEAKER_01: And that's when, I think I, it was 2024,
[00:33:58] SPEAKER_01: I gave a TED Talk about spatial intelligence
[00:34:01] SPEAKER_01: at world models,
[00:34:03] SPEAKER_01: and I start formulating this idea back in 2022,
[00:34:08] SPEAKER_01: based on my robotics and computer vision research.
[00:34:14] And then one thing that was really clear to me,
[00:34:17] SPEAKER_01: is that I really wanna work with the brightest technologist
[00:34:23] SPEAKER_01: and move as fast as possible to bring this technology to life,
[00:34:28] SPEAKER_01: and that's when we found it,
[00:34:30] SPEAKER_01: this company called World Labs.
[00:34:32] SPEAKER_01: And you can see the world is in the title of our company,
[00:34:36] SPEAKER_01: because we believe so much in world modeling
[00:34:39] SPEAKER_01: and spatial intelligence.
[00:34:41] SPEAKER_01: People are so used to just chat bots,
[00:34:43] SPEAKER_00: and that's a large language model.
[00:34:44] SPEAKER_00: The simple way to understand a world model is you,
[00:34:46] SPEAKER_00: basically describe a scene,
[00:34:48] SPEAKER_00: and it generates an infinitely,
[00:34:50] SPEAKER_00: a explorer world.
[00:34:52] SPEAKER_00: We'll link to the thing you'll launch,
[00:34:54] SPEAKER_00: which we'll talk about,
[00:34:54] SPEAKER_00: but just as that is simple way to understand it.
[00:34:56] SPEAKER_00: That's part of it, Lenny.
[00:34:57] SPEAKER_01: I think a simple way to understand a world model,
[00:35:01] SPEAKER_01: is that this model can allow anyone to create
[00:35:07] any world in their mind's eye,
[00:35:10] SPEAKER_01: by prompting whether it's an image or sentence,
[00:35:14] SPEAKER_01: and also be able to interact in this world,
[00:35:18] SPEAKER_01: whether you're browsing and walking
[00:35:21] SPEAKER_01: or picking objects up or changing things,
[00:35:27] SPEAKER_01: as well as to reason within this world.
[00:35:30] SPEAKER_01: For example, if the person consuming,
[00:35:34] SPEAKER_01: if the agent consuming this output of the world model
[00:35:38] SPEAKER_01: is a robot, it should be able to plan its path
[00:35:41] SPEAKER_01: and help to tidy the kitchen, for example.
[00:35:47] SPEAKER_01: So world model is a foundation
[00:35:53] SPEAKER_01: that you can use to reason, to interact,
[00:35:57] SPEAKER_01: and to create worlds.
[00:35:59] SPEAKER_01: Great, yeah.
[00:36:00] SPEAKER_00: So robots feels like that's potentially
[00:36:04] SPEAKER_00: the next big focus for AI researchers
[00:36:07] SPEAKER_00: and just like the impact on the world,
[00:36:08] SPEAKER_00: and what you're saying here is,
[00:36:11] SPEAKER_00: this is a key missing piece of making robots
[00:36:14] SPEAKER_00: actually work in the real world,
[00:36:16] SPEAKER_00: understanding how the world works.
[00:36:17] SPEAKER_00: Yeah, well, first of all,
[00:36:18] SPEAKER_01: I do think there's more than robots that's exciting.
[00:36:23] SPEAKER_01: But I agree with everything you just said.
[00:36:25] SPEAKER_01: I think world modeling and spatial intelligence
[00:36:28] SPEAKER_01: is a key missing piece of body AI.
[00:36:33] SPEAKER_01: I also think let's not underestimate
[00:36:35] SPEAKER_01: that humans are embodied agents,
[00:36:38] SPEAKER_01: and humans can be augmented by AI's intelligence.
[00:36:43] SPEAKER_01: Just like today, humans are language animals,
[00:36:46] SPEAKER_01: but we're very much augmented by AI
[00:36:49] SPEAKER_01: when helping us to do language tasks,
[00:36:53] SPEAKER_01: including software engineering.
[00:36:55] SPEAKER_01: I think that we shouldn't underestimate,
[00:36:58] SPEAKER_01: or maybe it's, we tend not to talk about
[00:37:03] SPEAKER_01: how humans as an embodied agents
[00:37:06] SPEAKER_01: can actually benefit so much from world models
[00:37:10] SPEAKER_01: and spatial intelligent models,
[00:37:12] SPEAKER_01: as well as robots can.
[00:37:15] So the big onlocks here are robots,
[00:37:17] SPEAKER_00: which a huge deal.
[00:37:19] SPEAKER_00: If this works out, imagine each of us has robots
[00:37:21] SPEAKER_00: doing a bunch of stuff for us,
[00:37:22] SPEAKER_00: goes into, you know,
[00:37:23] SPEAKER_00: they help us with disasters, things like games.
[00:37:26] SPEAKER_00: Obviously is a really cool example,
[00:37:27] SPEAKER_00: just like infinitely playable games
[00:37:30] SPEAKER_00: that you just invent at your head.
[00:37:31] SPEAKER_00: And then creativity feels like just like being fun,
[00:37:34] SPEAKER_00: having fun, being creative, thinking of,
[00:37:35] SPEAKER_00: imagine, wild new world and environments.
[00:37:39] And also design, humans design from machines
[00:37:42] SPEAKER_01: to buildings to homes,
[00:37:45] SPEAKER_01: and also scientific discovery, right?
[00:37:47] SPEAKER_01: There is so much, I like to use the example
[00:37:51] SPEAKER_01: of the discovery of the structure of DNA.
[00:37:55] If you look at one of the most important
[00:37:58] SPEAKER_01: piece in DNA's discovery history
[00:38:01] SPEAKER_01: is the X-ray diffraction photo
[00:38:05] SPEAKER_01: that was captured by Rosalind Franklin.
[00:38:07] SPEAKER_01: And it was a flat 2D photo of a structure
[00:38:11] SPEAKER_01: that looks like, it looks like a cross with diffractions.
[00:38:15] SPEAKER_01: You can Google those photos.
[00:38:18] SPEAKER_01: But with that, 2D-flat photo,
[00:38:23] humans, especially two important humans,
[00:38:26] SPEAKER_01: James Watson and Francis Crick,
[00:38:29] in addition to their other information,
[00:38:32] SPEAKER_01: was able to reason in 3D space and deduce
[00:38:38] SPEAKER_01: a highly three-dimensional double helix structure
[00:38:42] SPEAKER_01: of the DNA.
[00:38:43] SPEAKER_01: And that structure cannot possibly be 2D.
[00:38:47] SPEAKER_01: You cannot think in 2D and deduce that structure.
[00:38:52] SPEAKER_01: You have to think in 3D spatial,
[00:38:56] SPEAKER_01: use the human spatial intelligence.
[00:38:59] SPEAKER_01: So I think even the scientific discovery,
[00:39:02] SPEAKER_01: spatial intelligence or AI assisted spatial intelligence
[00:39:06] SPEAKER_01: is critical.
[00:39:07] SPEAKER_01: This is such an example of, I think it was critics
[00:39:10] SPEAKER_00: in the head of this line that the next big thing
[00:39:12] SPEAKER_00: is gonna start off feeling like a toy.
[00:39:15] SPEAKER_00: When Chad G.P.C. just came out,
[00:39:17] SPEAKER_00: if like, I remember Sam Wampin just tweeted,
[00:39:18] SPEAKER_00: like, here's a cool thing we're playing with,
[00:39:20] SPEAKER_00: check it out.
[00:39:21] SPEAKER_00: Now it's the fastest growing product
[00:39:22] SPEAKER_00: in all of history, change the world.
[00:39:24] SPEAKER_00: And it's oftentimes the things that just look like,
[00:39:27] SPEAKER_00: okay, this is cool, that it's a fun to play with
[00:39:30] SPEAKER_00: and end up changing the world most.
[00:39:32] Yeah.
[00:39:33] SPEAKER_00: This episode is brought to you by SINCH,
[00:39:35] SPEAKER_00: the customer communications cloud.
[00:39:37] SPEAKER_00: Here's the thing about digital customer communications,
[00:39:40] SPEAKER_00: whether you're sending marketing campaigns,
[00:39:42] SPEAKER_00: verification codes or account alerts,
[00:39:44] SPEAKER_00: you need them to reach users reliably.
[00:39:46] SPEAKER_00: That's where SINCH comes in.
[00:39:48] SPEAKER_00: Over 150,000 businesses,
[00:39:51] SPEAKER_00: including eight of the top 10 largest tech companies
[00:39:53] SPEAKER_00: globally, use SINCH's API to build messaging, email,
[00:39:57] SPEAKER_00: and calling into their products.
[00:39:58] SPEAKER_00: And there's something big happening in messaging
[00:40:00] SPEAKER_00: that product teams need to know about,
[00:40:02] SPEAKER_00: rich communication services or RCS.
[00:40:06] SPEAKER_00: Think of RCS as SMS 2.0.
[00:40:08] SPEAKER_00: Instead of getting text from a random number,
[00:40:11] SPEAKER_00: your users will see your verified company name and logo
[00:40:13] SPEAKER_00: without needing to download anything new.
[00:40:16] SPEAKER_00: It's a more secure and branded experience.
[00:40:18] SPEAKER_00: Plus you get features like interactive carousels
[00:40:21] SPEAKER_00: and suggested replies.
[00:40:22] SPEAKER_00: And here's why this matters.
[00:40:24] SPEAKER_00: US carriers are starting to adopt RCS.
[00:40:27] SPEAKER_00: SINCH is already helping major brands
[00:40:29] SPEAKER_00: send RCS messages around the world.
[00:40:31] SPEAKER_00: And they're helping Lenny's podcast listeners
[00:40:33] SPEAKER_00: get registered first before the rush hits the US market.
[00:40:36] SPEAKER_00: Learn more at get started at cinch.com slash Lenny.
[00:40:40] SPEAKER_00: That's s-i-n-c-h.com slash Lenny.
[00:40:45] I reached out to Ben Horowitz, who loves what you're doing,
[00:40:47] SPEAKER_00: a big fan of yours, their investors, I believe in.
[00:40:50] SPEAKER_00: Yeah.
[00:40:51] SPEAKER_01: We've known each other for many years.
[00:40:54] SPEAKER_01: But yes, right now they are investors of War Labs.
[00:40:57] SPEAKER_01: Amazing.
[00:40:58] SPEAKER_00: OK.
[00:40:58] SPEAKER_00: So I asked him what I should ask you about.
[00:41:00] SPEAKER_00: And he suggested ask you, why is the bitter lessen alone,
[00:41:04] SPEAKER_00: not likely to work for robots?
[00:41:08] SPEAKER_00: So first of all, just explain what the bitter lesson was
[00:41:11] SPEAKER_00: in the history of AI.
[00:41:12] SPEAKER_00: And then just why that won't get us to where
[00:41:14] SPEAKER_00: we want to be with robots.
[00:41:16] So first of all, there are many bitter lessons.
[00:41:19] SPEAKER_01: But the bitter lessons everybody refers to is a paper written
[00:41:25] SPEAKER_01: by Richard Sutton, who won the Turing Award recently.
[00:41:29] SPEAKER_01: And he does a lot of reinforcement learning.
[00:41:31] SPEAKER_01: And Richard has said, if you look at the history,
[00:41:35] SPEAKER_01: especially the algorithmic development of AI,
[00:41:39] SPEAKER_01: it turns out simpler model with a ton of data always
[00:41:44] SPEAKER_01: win at the end of the day, instead of the more complex model
[00:41:51] SPEAKER_01: with less data.
[00:41:52] SPEAKER_01: I mean, that was actually, this paper came years
[00:41:56] SPEAKER_01: after ImageNet.
[00:41:57] SPEAKER_01: That, to me, was not bitter.
[00:42:00] SPEAKER_01: It was a sweet lesson.
[00:42:01] SPEAKER_01: That's why I built ImageNet because I believe
[00:42:05] SPEAKER_01: that big data plays that role.
[00:42:07] SPEAKER_01: So why can bitter lesson work in robotics alone?
[00:42:12] SPEAKER_01: Well, first of all, I think we need to give credit
[00:42:16] SPEAKER_01: to where we are today.
[00:42:18] SPEAKER_01: Robotics is very much in the early days of experimentation.
[00:42:24] SPEAKER_01: It's not the research is not nearly as mature as, say,
[00:42:29] SPEAKER_01: language models.
[00:42:30] SPEAKER_01: So many people are still experimenting
[00:42:35] SPEAKER_01: with different algorithms.
[00:42:36] SPEAKER_01: And some of those algorithms are driven by big data.
[00:42:40] SPEAKER_01: So I do think big data will continue to play a role
[00:42:45] SPEAKER_01: in robotics.
[00:42:47] SPEAKER_01: And, but what is hard for robotics,
[00:42:51] SPEAKER_01: there are a couple of things.
[00:42:53] SPEAKER_01: One is that it's harder to get data.
[00:42:56] SPEAKER_01: It's a lot harder to get data.
[00:42:58] SPEAKER_01: You can say, well, there is web data.
[00:43:00] SPEAKER_01: This is where the latest robotics research
[00:43:03] SPEAKER_01: is using web videos.
[00:43:05] SPEAKER_01: And I think web videos do play a role.
[00:43:09] SPEAKER_01: But if you think about what made language model worth
[00:43:12] SPEAKER_01: a very, as someone who does computer vision
[00:43:16] SPEAKER_01: and spatial intelligence and robotics,
[00:43:19] SPEAKER_01: I'm very jealous of my colleagues in language
[00:43:22] SPEAKER_01: because they had this perfect setup
[00:43:26] SPEAKER_01: where their training data are in words, eventually tokens.
[00:43:31] SPEAKER_01: And then the producer model that outputs words.
[00:43:36] SPEAKER_01: So you have this perfect alignment between what you hope
[00:43:41] SPEAKER_01: to get, which we call objective function
[00:43:43] SPEAKER_01: and what your training data looks like.
[00:43:47] But robotics is different.
[00:43:48] SPEAKER_01: Even spatial intelligence is different.
[00:43:51] SPEAKER_01: You hope to get actions out of robots.
[00:43:56] But your training data lacks actions
[00:44:00] SPEAKER_01: in 3D worlds.
[00:44:02] SPEAKER_01: And that's what robots have to do, right?
[00:44:04] SPEAKER_01: Actions in 3D worlds.
[00:44:06] SPEAKER_01: So you have to find different ways to fit a,
[00:44:13] SPEAKER_01: what do they call a square in a round hole.
[00:44:17] SPEAKER_01: That what we have is tons of web videos.
[00:44:23] So then we have to start talking about adding,
[00:44:27] SPEAKER_01: supplementing data such as teleoperation data
[00:44:32] SPEAKER_01: or synthetic data so that the robots are trained
[00:44:37] SPEAKER_01: with this hypothesis of bitter lesson,
[00:44:39] SPEAKER_01: which is large amount of data.
[00:44:41] SPEAKER_01: I think there's still hope
[00:44:44] because even what we are doing in world modeling
[00:44:48] SPEAKER_01: will really unlock a lot of this information for robots.
[00:44:53] SPEAKER_01: But I think we have to be careful
[00:44:54] SPEAKER_01: because we're at the early days of this.
[00:44:57] SPEAKER_01: And bitter lesson is still to be tested
[00:45:01] SPEAKER_01: because we haven't fully figured out the data for.
[00:45:06] SPEAKER_01: Another part of the bitter lesson of robotics,
[00:45:09] SPEAKER_01: I think we should be so realistic about is,
[00:45:15] SPEAKER_01: again, compared to language models or even spatial models,
[00:45:19] robots are physical systems.
[00:45:22] So robots are closer to self-driving cars
[00:45:26] SPEAKER_01: than a large language model.
[00:45:28] SPEAKER_01: And that's very important to recognize.
[00:45:30] SPEAKER_01: That means that in order for robots to work,
[00:45:35] SPEAKER_01: we not only need brains,
[00:45:38] SPEAKER_01: we also need the physical body,
[00:45:40] SPEAKER_01: we also need applications and scenarios.
[00:45:44] SPEAKER_01: If you look at the history of self-driving car,
[00:45:49] SPEAKER_01: my colleague Sebastian Thrum took Stanford's car
[00:45:55] SPEAKER_01: to win the first DARPA challenge in 2006 or 2005.
[00:46:00] SPEAKER_01: It's 20 years since that prototype of a self-driving car,
[00:46:07] SPEAKER_01: being able to drive 130 miles in the Nevada desert
[00:46:11] SPEAKER_01: to today's Weymill and on the street of San Francisco.
[00:46:17] And we're not even done yet, there's still a lot.
[00:46:20] SPEAKER_01: So that's a 20 year journey.
[00:46:22] SPEAKER_01: And self-driving cars are much simpler robots.
[00:46:25] SPEAKER_01: They're just metal boxes running on 2D surfaces,
[00:46:29] SPEAKER_01: and the goal is not to touch anything.
[00:46:32] Robot is 3D things running in 3D world
[00:46:37] SPEAKER_01: and the goal is to touch things.
[00:46:39] SPEAKER_01: So the journey is gonna be,
[00:46:42] SPEAKER_01: you know, there's many aspects, elements.
[00:46:45] SPEAKER_01: And of course one could say,
[00:46:47] SPEAKER_01: well, the self-driving car early algorithm
[00:46:51] SPEAKER_01: were pre-deplurning era.
[00:46:53] SPEAKER_01: So deplurning is accelerating the brains.
[00:46:56] SPEAKER_01: And I think that's true.
[00:46:57] SPEAKER_01: That's why I'm in robotics,
[00:46:59] SPEAKER_01: that's why I'm in spatial intelligence
[00:47:01] SPEAKER_01: and I'm excited by it.
[00:47:03] SPEAKER_01: But in the meantime, the car industry is very mature.
[00:47:07] SPEAKER_01: And productizing also involves the mature use cases,
[00:47:12] use cases, supply chains, the hardware.
[00:47:16] SPEAKER_01: So I think it's a very interesting time
[00:47:18] SPEAKER_01: to work in these problems,
[00:47:20] SPEAKER_01: but it's true, but it's right.
[00:47:22] SPEAKER_01: We might still be subject to a number of better lessons.
[00:47:28] SPEAKER_01: Doing this work, do you ever just feel off
[00:47:31] SPEAKER_00: for the way the brain works
[00:47:32] SPEAKER_00: and is able to do all of this for us?
[00:47:35] SPEAKER_00: Just the complexity, just to get a machine
[00:47:38] SPEAKER_00: to just walk around and not hit things and fall.
[00:47:41] SPEAKER_00: Does it just give you more respect
[00:47:42] SPEAKER_00: for what we've already got?
[00:47:44] SPEAKER_00: Totally.
[00:47:44] SPEAKER_00: We operate on about 20 watts.
[00:47:49] SPEAKER_01: It's dimmer than any light bulb in the room I'm in right now.
[00:47:53] SPEAKER_01: And yet we can do so much.
[00:47:57] SPEAKER_01: So I think actually the more I work in AI,
[00:48:00] SPEAKER_01: the more I respect humans.
[00:48:03] Let's talk about this product you just launched
[00:48:05] SPEAKER_00: called Marble, a very cute name.
[00:48:08] SPEAKER_00: Talk about what this is, why this important,
[00:48:09] SPEAKER_00: I've been playing with it, it's incredible.
[00:48:10] SPEAKER_00: I'll link to it for folks to check it out.
[00:48:13] SPEAKER_00: What is Marble?
[00:48:14] Yeah, I'm very excited.
[00:48:15] SPEAKER_01: So first of all, Marble is one of the first product
[00:48:19] SPEAKER_01: that World Labs has rolled out.
[00:48:22] SPEAKER_01: World Labs is a foundation frontier model company.
[00:48:25] SPEAKER_01: We are funded by four co-founders
[00:48:28] SPEAKER_01: who have deep technical history.
[00:48:31] SPEAKER_01: My co-founders Justin Johnson, Christoph Lassner
[00:48:36] SPEAKER_01: and Ben Mildenhall, we all come from the research field
[00:48:39] SPEAKER_01: of AI, computer graphics, computer vision.
[00:48:43] SPEAKER_01: And we believe that spatial intelligence
[00:48:45] SPEAKER_01: and world modeling is as important,
[00:48:49] SPEAKER_01: if not more, to language models and complementary
[00:48:53] SPEAKER_01: to language models.
[00:48:55] SPEAKER_01: So we wanted to seize this opportunity
[00:48:58] SPEAKER_01: to create deep tech research lab
[00:49:02] SPEAKER_01: that can connect the dots between frontier models with products.
[00:49:08] SPEAKER_01: So Marble is an app that's built upon our frontier models.
[00:49:15] SPEAKER_01: We've spent a year and plus building
[00:49:18] SPEAKER_01: the world's first generative model that can output
[00:49:24] SPEAKER_01: genuinely 3D worlds.
[00:49:26] SPEAKER_01: That's a very, very hard problem.
[00:49:29] And it was a very hard process.
[00:49:34] SPEAKER_01: We have a team of incredible,
[00:49:37] SPEAKER_01: founding team of incredible technologists
[00:49:40] SPEAKER_01: from incredible teams.
[00:49:45] SPEAKER_01: And then around a month or two ago,
[00:49:50] SPEAKER_01: we saw the first time that we can just prompt
[00:49:54] SPEAKER_01: with a sentence and an image and multiple images
[00:49:58] SPEAKER_01: and create worlds that we can just navigate in.
[00:50:03] SPEAKER_01: If you put it on cargo, which we have an option
[00:50:05] SPEAKER_01: to let you do that,
[00:50:07] SPEAKER_01: you can even walk around it, right?
[00:50:09] SPEAKER_01: So it was, even though we've been building this for quite a while,
[00:50:13] SPEAKER_01: it was still just awe inspiring.
[00:50:16] SPEAKER_01: And we wanted to get into the hands of people who needed.
[00:50:20] SPEAKER_01: And then we know that so many creators, designers,
[00:50:25] SPEAKER_01: people who are thinking about robotic simulation,
[00:50:29] SPEAKER_01: people who are thinking about different use cases
[00:50:33] SPEAKER_01: of navigable, interactable, immersive worlds,
[00:50:38] SPEAKER_01: game developers will find this useful.
[00:50:41] SPEAKER_01: So we developed Marble as a first step.
[00:50:45] SPEAKER_01: It's again, still very early,
[00:50:49] SPEAKER_01: but it's the world's first model doing this
[00:50:52] SPEAKER_01: and it's the world's first product
[00:50:55] SPEAKER_01: that allows people to just prompt, we call it prompt to worlds.
[00:51:00] SPEAKER_01: Well, I've been playing around it.
[00:51:02] SPEAKER_00: It is insane.
[00:51:02] SPEAKER_00: You could just have a little shire world
[00:51:04] SPEAKER_00: where you just infinitely walk around middle earth,
[00:51:07] SPEAKER_00: basically, and there's no one there yet.
[00:51:09] SPEAKER_00: But it's insane.
[00:51:10] SPEAKER_00: You just go anywhere.
[00:51:11] SPEAKER_00: There's dystopian world.
[00:51:12] SPEAKER_00: I'm just looking at all these examples.
[00:51:14] SPEAKER_01: Yes.
[00:51:14] SPEAKER_01: And my favorite part actually, I don't know.
[00:51:16] SPEAKER_00: I don't know if there's a feature bug.
[00:51:17] SPEAKER_00: You can see the dots of the world
[00:51:20] SPEAKER_00: before it actually renders with all the textures.
[00:51:22] SPEAKER_00: And I just love to, like, you get a glimpse
[00:51:24] SPEAKER_00: into what is going on with this model.
[00:51:26] SPEAKER_00: Basically great.
[00:51:27] SPEAKER_00: That is so cool to hear.
[00:51:28] SPEAKER_01: Because this is where, as a researcher, I'm learning
[00:51:33] SPEAKER_01: because the dots that lead you into the world
[00:51:38] SPEAKER_01: was an intentional feature visualization.
[00:51:44] SPEAKER_01: It is not part of the model.
[00:51:46] SPEAKER_01: It's the model actually just generates the world.
[00:51:50] SPEAKER_00: But we were trying to find a way
[00:51:52] SPEAKER_01: to guide people into the world
[00:51:54] SPEAKER_01: and a number of engineers work on different versions.
[00:51:58] SPEAKER_01: But we converge to the DAW.
[00:51:59] SPEAKER_01: And so many people, you're the only one
[00:52:03] SPEAKER_01: told us how delightful that experience is.
[00:52:06] SPEAKER_01: And it was really satisfying for us
[00:52:09] SPEAKER_01: to hear that this intentional visualization feature,
[00:52:13] SPEAKER_01: that's not just a big hardcore model, actually,
[00:52:16] SPEAKER_01: has delighted our users.
[00:52:19] Wow.
[00:52:19] So you add that to make it more like to have humans understand
[00:52:24] SPEAKER_00: what's going on more.
[00:52:24] SPEAKER_00: It's more delightful.
[00:52:25] SPEAKER_00: Wow.
[00:52:26] SPEAKER_00: That is hilarious.
[00:52:27] SPEAKER_00: It makes me think about a lens in the way
[00:52:29] SPEAKER_00: they it's not the same thing, but they talk about what
[00:52:31] SPEAKER_00: they're thinking and what they're doing.
[00:52:32] SPEAKER_00: Yes, it is.
[00:52:33] SPEAKER_01: It is.
[00:52:34] SPEAKER_01: It also makes me think about just the matrix.
[00:52:36] SPEAKER_00: It's exactly the matrix experience.
[00:52:39] SPEAKER_00: I don't know if that was your inspiration.
[00:52:41] Well, like I said, a number of engineers
[00:52:44] SPEAKER_01: worked on that.
[00:52:44] SPEAKER_01: It could be their inspiration.
[00:52:46] SPEAKER_01: It's in their subconscious.
[00:52:50] SPEAKER_00: OK, so just for folks that may be on a play around with us,
[00:52:53] SPEAKER_00: maybe use a what's like, what are some applications today
[00:52:55] SPEAKER_00: that folks can start using today?
[00:52:57] SPEAKER_00: What's your goal with this launch?
[00:52:59] Yeah, so we do believe that world modeling is very horizontal,
[00:53:04] SPEAKER_01: but we're already seeing some really exciting use cases,
[00:53:08] SPEAKER_01: virtual production for movies, because what they need
[00:53:12] SPEAKER_01: are 3D worlds that they can align with the camera.
[00:53:18] SPEAKER_01: So when the actors are acting on it,
[00:53:21] SPEAKER_01: they can position the camera and shoot the segments really well.
[00:53:27] SPEAKER_01: And we're already seeing incredible use.
[00:53:31] SPEAKER_01: In fact, I don't know if you have seen our launch video
[00:53:35] SPEAKER_01: showing marble.
[00:53:36] SPEAKER_01: It was produced by a virtual production company.
[00:53:40] SPEAKER_01: We collaborated with Sony.
[00:53:42] SPEAKER_01: And they use marble scenes to shoot those videos.
[00:53:45] SPEAKER_01: So we were collaborating with those technical artists
[00:53:50] SPEAKER_01: and directors, and they were saying this has cut our production
[00:53:54] SPEAKER_01: time by 40X.
[00:53:57] SPEAKER_01: In fact, it has to be.
[00:53:59] SPEAKER_01: Yes, in fact, it has to, because we only had one month
[00:54:03] SPEAKER_01: to work on this project.
[00:54:04] SPEAKER_01: And there were so many scenes they were trying to shoot.
[00:54:08] SPEAKER_01: So using marble really, really significantly
[00:54:13] SPEAKER_01: accelerated the production of virtual production
[00:54:17] SPEAKER_01: for VFX and movies.
[00:54:19] SPEAKER_01: That's one use cases.
[00:54:20] SPEAKER_01: We are already seeing our users taking our marble
[00:54:25] SPEAKER_01: scene and taking the mesh export and putting games,
[00:54:29] SPEAKER_01: whether it's games on VR or games just fun games
[00:54:33] SPEAKER_01: that they have developed.
[00:54:36] SPEAKER_01: We were showing an example of robotic simulation,
[00:54:43] SPEAKER_01: because when I was still a researcher
[00:54:48] SPEAKER_01: doing robotic training, one of the biggest pain
[00:54:52] SPEAKER_01: point is to create synthetic data for training robots.
[00:54:56] SPEAKER_01: And these synthetic data needs to be very diverse.
[00:54:59] SPEAKER_01: They need to come from different environments
[00:55:01] SPEAKER_01: with different objects to manipulate.
[00:55:04] SPEAKER_01: And one path to it is to ask computers to simulate.
[00:55:10] SPEAKER_01: Otherwise, humans have to build every single asset for robots.
[00:55:16] SPEAKER_01: That's just going to take a lot longer.
[00:55:19] SPEAKER_01: So we already have researchers reaching out
[00:55:22] SPEAKER_01: and wanting to use marble to create those synthetic environments.
[00:55:26] SPEAKER_01: We also have unexpected user outreach
[00:55:32] SPEAKER_01: in terms of how they want to use marble.
[00:55:35] SPEAKER_01: For example, a psychologist team called us
[00:55:40] SPEAKER_01: to use marble to do psychology research.
[00:55:43] SPEAKER_01: It turned out some of the psychiatric patients they study,
[00:55:48] SPEAKER_01: they need to understand how their brain responds
[00:55:51] SPEAKER_01: to different immersive scenes of different features.
[00:55:56] SPEAKER_01: For example, messy scenes or clean scenes
[00:55:59] SPEAKER_01: or whatever you name it.
[00:56:01] SPEAKER_01: And it's very hard for researchers to get their hands
[00:56:04] SPEAKER_01: on these kind of immersive scenes.
[00:56:07] SPEAKER_01: And it will take them too long and too much budget
[00:56:11] SPEAKER_01: to create.
[00:56:14] SPEAKER_01: And marble is a really almost instantaneous way
[00:56:18] SPEAKER_01: of getting so many of these experimental environments
[00:56:24] SPEAKER_01: into their hands.
[00:56:25] SPEAKER_01: So we're seeing multiple use cases at this point.
[00:56:30] SPEAKER_01: But the VFX, the game developers, the simulation developers,
[00:56:36] SPEAKER_01: as well as designers are very excited.
[00:56:39] This is very much the way things work in AI
[00:56:41] SPEAKER_00: have had other AI leaders on the podcast.
[00:56:43] SPEAKER_00: And it's always like put things out there early
[00:56:45] SPEAKER_00: as soon as you can to discover where the big use cases are.
[00:56:48] SPEAKER_00: The head of JGPT told me how, when they first put out JGPT,
[00:56:52] SPEAKER_00: he was just scanning TikTok to see how people were using it
[00:56:55] SPEAKER_00: and all the things they were talking about.
[00:56:56] SPEAKER_00: And that's what convinced them where to lean in
[00:56:59] SPEAKER_00: and helped them see how people actually want to use it.
[00:57:02] SPEAKER_00: I love this last use case of like for therapy.
[00:57:04] SPEAKER_00: I'm just imagining like heights,
[00:57:07] SPEAKER_00: people seeing, dealing with heights or snakes or spiders,
[00:57:11] SPEAKER_00: which.
[00:57:11] SPEAKER_00: It's amazing.
[00:57:12] SPEAKER_00: A friend of mine last night literally called me
[00:57:15] SPEAKER_01: and talked about his height scare
[00:57:17] SPEAKER_01: and asked me if marble should be used.
[00:57:20] SPEAKER_01: That's amazing.
[00:57:21] SPEAKER_01: You went straight there.
[00:57:23] That's, you know, because I'm imagining all the exposure
[00:57:25] SPEAKER_00: therapy stuff.
[00:57:27] SPEAKER_00: Like this could be so good for that.
[00:57:29] SPEAKER_00: That is so cool.
[00:57:31] SPEAKER_00: OK, so let me, I should have asked you this before,
[00:57:32] SPEAKER_00: but I think there's going to be a question of just,
[00:57:35] SPEAKER_00: how does this differ from things like VO3
[00:57:37] SPEAKER_00: and other video generation models?
[00:57:40] SPEAKER_00: It's pretty clear to me, but I think it might be helpful
[00:57:42] SPEAKER_00: just to explain how this is different from all the video AI
[00:57:44] SPEAKER_00: tools people have seen.
[00:57:46] SPEAKER_00: Worro apps thesis is that spatial intelligence
[00:57:49] SPEAKER_01: is fundamentally very important.
[00:57:51] SPEAKER_01: And spatial intelligence is not just, it's not just about videos.
[00:57:58] SPEAKER_01: In fact, the world is not passively watching videos passing
[00:58:03] SPEAKER_01: by, right?
[00:58:04] SPEAKER_01: I love Plato has the allegory of the cave analogy
[00:58:11] SPEAKER_01: to describe vision.
[00:58:12] SPEAKER_01: He said that imagine a prisoner tied on his chair, not very
[00:58:19] SPEAKER_01: humane, but in a cave watching a full life theater
[00:58:28] SPEAKER_01: on the in front of him.
[00:58:30] SPEAKER_01: But the actual life theater that actors are acting
[00:58:34] SPEAKER_01: is behind his back.
[00:58:36] SPEAKER_01: It was just lit so that the projection of the action
[00:58:41] SPEAKER_01: is on a wall of the cave.
[00:58:44] SPEAKER_01: And then the goal, the task of this prisoner
[00:58:48] SPEAKER_01: is to figure out what's going on.
[00:58:50] SPEAKER_01: It's a pretty extreme example, but it really
[00:58:53] SPEAKER_01: shows, it describes what vision is about,
[00:58:59] SPEAKER_01: is that to make sense of the 3D world or 4D world
[00:59:04] SPEAKER_01: out of 2D.
[00:59:05] SPEAKER_01: So spatial intelligence to me is deeper
[00:59:09] SPEAKER_01: than only creating that flat 2D world.
[00:59:14] SPEAKER_01: Spatial intelligence to me is the ability
[00:59:18] SPEAKER_01: to create reason, interact, make sense
[00:59:23] SPEAKER_01: of deeply spatial world, whether it's 2D or 3D or 4D,
[00:59:30] SPEAKER_01: including dynamics and all that.
[00:59:32] SPEAKER_01: So world lab is focusing on that.
[00:59:35] SPEAKER_01: And of course, the ability to create videos per se
[00:59:40] SPEAKER_01: could be part of this.
[00:59:41] SPEAKER_01: And in fact, just a couple of weeks ago,
[00:59:44] SPEAKER_01: we rolled out the world's first real-time demoable, real-time
[00:59:50] SPEAKER_01: video generation on a single H100 GPU.
[00:59:54] SPEAKER_01: So we part of our technology includes that.
[00:59:58] SPEAKER_01: But I think Marbo is very different
[01:00:00] SPEAKER_01: because we really want creators, designers, developers
[01:00:07] SPEAKER_01: to having their hands a model that can give them worlds
[01:00:13] SPEAKER_01: with 3D structures so they can use it for their work.
[01:00:17] SPEAKER_01: And that's why Marbo is so different.
[01:00:21] The way you see it is, it's a platform for a ton of opportunity
[01:00:25] SPEAKER_00: to do stuff.
[01:00:26] SPEAKER_00: As you describe videos, here's a one-off video
[01:00:29] SPEAKER_00: that's very fun and cool.
[01:00:30] SPEAKER_00: And you could, and that's it, and you move on.
[01:00:33] SPEAKER_00: By the way, in Marbo, we could allow people
[01:00:36] SPEAKER_01: to explore in video forms.
[01:00:38] SPEAKER_01: So you could actually, like you said,
[01:00:40] SPEAKER_01: you go into a world.
[01:00:42] SPEAKER_01: So let's say it's a Hobbit cave.
[01:00:45] SPEAKER_01: You can actually, especially as a creator,
[01:00:47] SPEAKER_01: you have such a specific way of moving the camera
[01:00:53] SPEAKER_01: in a trajectory in the director's mind.
[01:00:57] SPEAKER_01: And then you can export that from Marbo into a video.
[01:01:02] What does it take to create something like this?
[01:01:03] SPEAKER_00: Just like how big is the team, how many GPUs you work in?
[01:01:07] SPEAKER_00: Like anything you can share there.
[01:01:08] SPEAKER_00: I don't know how much of this is private information,
[01:01:09] SPEAKER_00: but just what does it take to create something like this
[01:01:11] SPEAKER_00: that you've launched here?
[01:01:12] SPEAKER_00: It takes a lot of brain power.
[01:01:16] SPEAKER_01: So we just talk about 20 watts per brain.
[01:01:20] SPEAKER_01: It's so from that point of view, it's a small number,
[01:01:23] SPEAKER_01: but it's actually incredible.
[01:01:26] SPEAKER_01: It's a half billion years of evolution
[01:01:29] SPEAKER_01: to give us those power.
[01:01:32] SPEAKER_01: We have a team of 30-ish people now,
[01:01:36] SPEAKER_01: and we are predominantly researchers,
[01:01:41] SPEAKER_01: or research engineers.
[01:01:44] SPEAKER_01: But we also have designers and product.
[01:01:48] SPEAKER_01: We actually really believe that we
[01:01:50] SPEAKER_01: want to create a company that's anchored
[01:01:53] SPEAKER_01: in the deep tech of spatial intelligence,
[01:01:56] SPEAKER_01: but we are actually building serious products.
[01:02:04] SPEAKER_01: So we have this integration of R&D and productization.
[01:02:11] SPEAKER_01: And of course, we use a ton of GPUs.
[01:02:15] SPEAKER_01: That's a techie too.
[01:02:16] SPEAKER_01: That's a techie too.
[01:02:17] SPEAKER_01: That's a techie too.
[01:02:17] SPEAKER_01: That's a techie too.
[01:02:20] SPEAKER_01: Well, congrats on the launch.
[01:02:21] SPEAKER_00: I know there's a huge milestone.
[01:02:22] SPEAKER_00: I know this took a ton of work.
[01:02:23] SPEAKER_00: I just want to say congrats to you and your team.
[01:02:26] Let me talk about your founder journey for a moment.
[01:02:29] SPEAKER_00: So your founder, this company, started how many years ago?
[01:02:31] SPEAKER_00: A couple of years ago?
[01:02:32] SPEAKER_00: Two, three years ago?
[01:02:33] SPEAKER_00: Oh, a year ago.
[01:02:34] SPEAKER_01: A year ago.
[01:02:35] SPEAKER_01: A year ago.
[01:02:35] SPEAKER_01: A year?
[01:02:36] SPEAKER_01: OK.
[01:02:37] SPEAKER_01: Probably 18 months, yeah.
[01:02:38] SPEAKER_01: OK.
[01:02:39] SPEAKER_00: What's something you wish you knew before you started this,
[01:02:42] SPEAKER_00: that you wish you could whisper into the ear
[01:02:43] SPEAKER_00: faith of 18 months ago?
[01:02:46] Well, I continue to wish I know the future of technology.
[01:02:52] SPEAKER_01: I think actually that's one of our founding advantage
[01:02:55] SPEAKER_01: is that we see the future earlier in general
[01:03:00] SPEAKER_01: than most people.
[01:03:01] SPEAKER_01: But still, man, this is so exciting.
[01:03:03] SPEAKER_01: And so amazing that what's unknown and what's coming.
[01:03:09] But I know the reason you're asking me this question
[01:03:12] SPEAKER_01: is a lot about the future of technology.
[01:03:14] SPEAKER_01: You're probably more, look, I did not
[01:03:18] SPEAKER_01: start a company of this scale at 20-year-old.
[01:03:24] SPEAKER_01: So I started a dry cleaner when I was 19,
[01:03:27] SPEAKER_01: but that's a little smaller scale.
[01:03:30] SPEAKER_01: We got a tablet.
[01:03:31] SPEAKER_01: And then I funded Google Cloud AI,
[01:03:35] SPEAKER_01: and then I funded an InstituS network.
[01:03:37] SPEAKER_01: But those are different beasts.
[01:03:40] SPEAKER_01: I did feel I was a little more prepared
[01:03:43] SPEAKER_01: as a founder of the grinding journey
[01:03:49] that I compared to maybe the 20-year-old founders.
[01:03:57] SPEAKER_01: But I'm still surprised.
[01:04:00] SPEAKER_01: And it puts me into paranoia sometimes
[01:04:06] SPEAKER_01: that how intensely competitive AI landscape
[01:04:11] SPEAKER_01: is from the model, the technology itself, as well as talents.
[01:04:19] SPEAKER_01: And when I founded the company,
[01:04:23] we did not have these incredible stories
[01:04:26] SPEAKER_01: of how much certain talents would cost.
[01:04:32] SPEAKER_01: So these are things that continue to surprise me.
[01:04:36] And I have to be very alert about.
[01:04:39] SPEAKER_01: The competition you're talking about is, yeah,
[01:04:41] SPEAKER_00: the competition for talent, the speed,
[01:04:44] SPEAKER_00: which is how things are moving.
[01:04:45] SPEAKER_00: Yeah.
[01:04:46] SPEAKER_01: Yeah.
[01:04:47] SPEAKER_00: You mentioned this point that I want to come back to that.
[01:04:51] SPEAKER_00: If you just look over the course of your career,
[01:04:53] SPEAKER_00: you're at all of the major collections of humans
[01:04:57] SPEAKER_00: that led to so many of the breakthroughs that are happening
[01:05:01] SPEAKER_00: today.
[01:05:01] SPEAKER_00: Obviously, we talk about ImageNet, also, just sale at Stanford
[01:05:04] SPEAKER_00: is where a lot of the work happened.
[01:05:06] SPEAKER_00: Google Cloud, which a lot of the breakthroughs
[01:05:08] SPEAKER_00: happened, would brought you to those places.
[01:05:12] SPEAKER_00: For people looking for how to advance in their career,
[01:05:16] SPEAKER_00: be at the center of the future, just like,
[01:05:18] SPEAKER_00: is there a through line there of just what
[01:05:20] SPEAKER_00: pulled you from place to place and pulled you
[01:05:22] SPEAKER_00: into those groups that might be helpful for people to hear?
[01:05:25] Yeah, this is actually a great question, Lenny,
[01:05:27] SPEAKER_01: because I do think about it.
[01:05:29] SPEAKER_01: And obviously, we talked about its curiosity
[01:05:35] SPEAKER_01: and passion that brought me to AI.
[01:05:37] SPEAKER_01: That is more a scientific nor start.
[01:05:40] SPEAKER_01: I did not care if AI was a thing or not.
[01:05:44] SPEAKER_01: So that was one part.
[01:05:45] SPEAKER_01: But how did I end up choosing in the particular places
[01:05:51] SPEAKER_01: I work in, including starting world labs?
[01:05:55] SPEAKER_01: I think I'm very grateful to myself,
[01:06:00] SPEAKER_01: or maybe to my parents' genes.
[01:06:04] I'm an intellectually very fearless person.
[01:06:08] SPEAKER_01: And I have to say, when I hire young people,
[01:06:11] SPEAKER_01: I look for that, because I think that's
[01:06:16] a very important quality if one wants to make a difference.
[01:06:21] SPEAKER_01: Is that when you want to make a difference,
[01:06:25] you have to accept that you're creating something new,
[01:06:29] SPEAKER_01: or you're diving into something new.
[01:06:31] SPEAKER_01: People haven't done that.
[01:06:32] SPEAKER_01: And if you have that self-awareness,
[01:06:36] SPEAKER_01: you almost have to allow yourself to be fearless
[01:06:41] SPEAKER_01: and to be courageous.
[01:06:42] SPEAKER_01: So when I, for example, came to Stanford,
[01:06:49] in the world of academia, I was very close to this thing
[01:06:54] SPEAKER_01: called tenure, which is, have the job forever at Princeton.
[01:07:00] SPEAKER_01: But I choose to come to Stanford,
[01:07:05] SPEAKER_01: because I love Princeton, it's my alma mater.
[01:07:09] SPEAKER_01: It's just at that moment, there are people
[01:07:12] SPEAKER_01: who are so amazing at Stanford, and the Silicon Valley ecosystem
[01:07:17] SPEAKER_01: was so amazing that I was OK to take a risk of restarting
[01:07:23] SPEAKER_01: my tenure clock.
[01:07:26] Going to becoming the first female director of sale,
[01:07:33] SPEAKER_01: I was actually relatively speaking of a very young faculty
[01:07:36] SPEAKER_01: at that time.
[01:07:37] SPEAKER_01: And I wanted to do that because I care about that community.
[01:07:41] SPEAKER_01: I didn't spend too much time thinking about all the failure
[01:07:44] SPEAKER_01: cases.
[01:07:46] SPEAKER_01: Obviously, I was very lucky that the more senior faculty
[01:07:50] SPEAKER_01: supported me, but I just wanted to make a difference.
[01:07:54] And then going to Google was similar.
[01:07:56] SPEAKER_01: I wanted to work with people like Jeff Dean, Jeff Hinton,
[01:08:02] SPEAKER_01: and all these incredible demos, the incredible people.
[01:08:11] SPEAKER_01: So the same with world labs.
[01:08:15] SPEAKER_01: I have this passion, and I also believe
[01:08:18] SPEAKER_01: that people with the same mission can do incredible things.
[01:08:22] SPEAKER_01: So that's how I guided my through life.
[01:08:26] SPEAKER_01: I don't overthink of all possible things that can go wrong,
[01:08:31] SPEAKER_01: because that's too many.
[01:08:33] SPEAKER_01: I feel like that's an important element.
[01:08:35] SPEAKER_00: This is not focusing on the downside,
[01:08:37] SPEAKER_00: focusing more on the people, the mission, what
[01:08:40] SPEAKER_00: gets you excited, what do you think?
[01:08:42] SPEAKER_00: I do.
[01:08:43] SPEAKER_00: Yeah, I do want to say one thing to all the young talents
[01:08:47] SPEAKER_01: in AI, the engineers, the researchers out there,
[01:08:49] SPEAKER_01: because some of you apply to world labs.
[01:08:53] SPEAKER_01: I feel very privileged.
[01:08:54] SPEAKER_01: You consider world labs.
[01:08:56] SPEAKER_01: I do find many of the young people today
[01:09:00] think about every single aspect of an equation
[01:09:06] SPEAKER_01: when they decide on jobs.
[01:09:08] SPEAKER_01: At some point, maybe that's the way they want to do it.
[01:09:12] SPEAKER_01: But sometimes I do want to encourage young people
[01:09:15] SPEAKER_01: to focus on what's important, because I
[01:09:19] SPEAKER_01: find myself constantly in mentoring mode
[01:09:24] SPEAKER_01: when I talk to job candidates.
[01:09:27] SPEAKER_01: Not necessarily recruiting or not recruiting,
[01:09:29] SPEAKER_01: but just in mentoring mode when I see an incredible young talent
[01:09:34] SPEAKER_01: who is over-focusing now, every minute dimension
[01:09:39] SPEAKER_01: and aspect of considering a job when maybe the most important
[01:09:46] SPEAKER_01: thing is, where's your passion?
[01:09:50] Do you align with the mission?
[01:09:52] Do you believe it have faith in this team?
[01:09:55] And just focus on the impact and you can make
[01:10:00] SPEAKER_01: and the kind of work and team you can work with.
[01:10:05] Yeah, it's tough.
[01:10:05] It's tougher people in the AI space.
[01:10:07] SPEAKER_00: Now there's so much at them, so much new,
[01:10:09] SPEAKER_00: so much happening, so much FOMO.
[01:10:11] SPEAKER_00: That's true.
[01:10:11] SPEAKER_00: I could see the stress.
[01:10:13] SPEAKER_00: And so I think that advice is really important, just like,
[01:10:15] SPEAKER_00: what will actually make you feel fulfilled
[01:10:18] SPEAKER_00: in what you're doing, not just where's the fastest
[01:10:20] SPEAKER_00: growing company, or who's going to win, I don't know.
[01:10:23] SPEAKER_00: I want to make sure I ask you about the work
[01:10:25] SPEAKER_00: you're doing today at Stanford at the HCI.
[01:10:28] SPEAKER_00: HCI.
[01:10:29] SPEAKER_00: HCI Human Centered AI Institute.
[01:10:32] SPEAKER_00: What are you doing there?
[01:10:33] SPEAKER_00: I know this is the thing you do on the site still.
[01:10:36] So yes, HCI Human Centered AI Institute was co-founded
[01:10:42] SPEAKER_01: by me and the group of faculty like Professor John H. Mendey,
[01:10:46] SPEAKER_01: Professor James Landey, Professor Chris Manning back in 2018.
[01:10:52] SPEAKER_01: I was actually finishing my last, the last,
[01:10:56] SPEAKER_01: the sabbatical at Google.
[01:10:58] SPEAKER_01: And it was a very, very important decision for me
[01:11:03] SPEAKER_01: because I could have stayed in the industry,
[01:11:06] SPEAKER_01: but my time at Google taught me one thing
[01:11:10] SPEAKER_01: is AI is going to be a civilizational technology.
[01:11:13] SPEAKER_01: And it's, it don't know me how important this is to humanity,
[01:11:19] SPEAKER_01: to the point that I actually wrote a piece in New York Times
[01:11:22] SPEAKER_01: that year 2018 to talk about the need for a guiding framework
[01:11:28] SPEAKER_01: to develop and to apply AI.
[01:11:33] SPEAKER_01: And that framework has to be anchored in human benevolence
[01:11:37] SPEAKER_01: is human centeredness.
[01:11:39] SPEAKER_01: And I felt as Stanford, one of the world's top university
[01:11:45] in the heart of Silicon Valley, that gave birth
[01:11:48] SPEAKER_01: to important companies from Nvidia to Google,
[01:11:53] SPEAKER_01: should be a thought leader to create this human centered AI framework
[01:12:00] SPEAKER_01: and to actually embody that in our research education
[01:12:06] SPEAKER_01: and policy and ecosystem work.
[01:12:09] SPEAKER_01: So I founded HAI, it, you know, after, fast forward,
[01:12:15] SPEAKER_01: after six, seven years, it has become the world's largest AI
[01:12:20] SPEAKER_01: institute that does human centered research education,
[01:12:27] SPEAKER_01: ecosystem outreach and policy impact.
[01:12:34] SPEAKER_01: It involves hundreds of faculty across all eight schools,
[01:12:40] SPEAKER_01: Stanford, from medicine to education,
[01:12:42] SPEAKER_01: to sustainability, to business, to engineering,
[01:12:46] SPEAKER_01: to humanities, to more.
[01:12:49] SPEAKER_01: And we, we support researchers, especially
[01:12:54] SPEAKER_01: at the interdisciplinary area from digital economy
[01:12:58] SPEAKER_01: to legal studies, to political science,
[01:13:01] SPEAKER_01: to discovery of new drugs, to new algorithms,
[01:13:07] SPEAKER_01: to let's be young transformers.
[01:13:10] SPEAKER_01: We also actually put a very strong focus on policy
[01:13:15] SPEAKER_01: because when we started HAI, I realized
[01:13:19] SPEAKER_01: that Silicon Valley did not talk to Washington DC
[01:13:23] and or Brussels or other parts of the world.
[01:13:27] SPEAKER_01: And it's given how important this,
[01:13:31] SPEAKER_01: this technology is, we need to bring everybody on board.
[01:13:34] SPEAKER_01: So we created multiple programs from congressional bootcamp
[01:13:39] SPEAKER_01: to AI index report, to policy briefing.
[01:13:45] SPEAKER_01: And we especially participated in policy making,
[01:13:51] SPEAKER_01: including advocating for a national AI research cloud
[01:13:57] SPEAKER_01: bill that was passed in the first Trump administration
[01:14:01] SPEAKER_01: and participating in state level regulatory AI discussions.
[01:14:08] SPEAKER_01: So there's a lot we did.
[01:14:10] SPEAKER_01: And I continue to be one of the leaders,
[01:14:15] SPEAKER_01: even though I'm much less involved operationally,
[01:14:18] SPEAKER_01: because I care not only we create this technology,
[01:14:22] SPEAKER_01: but we use it in the right way.
[01:14:24] Wow, I was not aware of all that other work you were doing.
[01:14:27] SPEAKER_00: As you're talking, I was reminded Charlie Munger
[01:14:30] SPEAKER_00: had this quote, take a simple idea and take it very seriously.
[01:14:35] SPEAKER_00: I feel like you've done that in so many different ways
[01:14:37] SPEAKER_00: and stayed with it.
[01:14:39] SPEAKER_00: And it's unbelievable the impact that you've had
[01:14:41] SPEAKER_00: in so many ways over the years.
[01:14:44] SPEAKER_00: I'm going to skip the lightning round.
[01:14:45] SPEAKER_00: And I'm just going to ask you one last question.
[01:14:47] SPEAKER_00: Is there anything else that you wanted to share
[01:14:49] SPEAKER_00: anything else you want to leave a list niche with?
[01:14:52] I'm very excited by AI Lenny.
[01:14:56] SPEAKER_01: I want to answer one question that when I travel around the world,
[01:15:01] SPEAKER_01: everybody asks me is that if I'm a musician,
[01:15:05] SPEAKER_01: if I'm a teacher, middle school teacher, if I'm a nurse,
[01:15:11] SPEAKER_01: if I'm a accountant, if I'm a farmer,
[01:15:14] SPEAKER_01: do I have a role in AI?
[01:15:16] SPEAKER_01: Or is AI just going to take over my life or my work?
[01:15:21] SPEAKER_01: And I think this is the most important question of AI.
[01:15:26] SPEAKER_01: And I find that in Silicon Valley,
[01:15:29] SPEAKER_01: we tend not to speak hard to hard with people.
[01:15:34] SPEAKER_01: With people like us, and not like us in Silicon Valley,
[01:15:37] SPEAKER_01: but like all of us, we tend to just toss around words
[01:15:42] SPEAKER_01: like infinite productivity or infinite leisure time
[01:15:47] SPEAKER_01: or infinite power or whatever.
[01:15:53] SPEAKER_01: But at the end of the day, AI is about people.
[01:15:56] SPEAKER_01: And when people ask me that question,
[01:15:59] SPEAKER_01: it's a resounding yes.
[01:16:01] SPEAKER_01: Everybody has a role in AI.
[01:16:03] SPEAKER_01: It depends on what you do and what you want.
[01:16:07] SPEAKER_01: But no technology should take away human dignity.
[01:16:11] SPEAKER_01: And the human dignity and agency should be at the heart of
[01:16:16] the development, the deployment, as well as the governance
[01:16:20] SPEAKER_01: of every technology.
[01:16:22] SPEAKER_01: So if you are a young artist, and your passion is storytelling,
[01:16:30] embrace AI as a tool.
[01:16:32] SPEAKER_01: In fact, embrace Marvel, I hope it becomes a tool for you.
[01:16:38] SPEAKER_01: Because the way you tell your story is unique
[01:16:42] SPEAKER_01: and the world still needs it.
[01:16:44] SPEAKER_01: But how you tell your story?
[01:16:46] SPEAKER_01: How do you use the most incredible tool
[01:16:50] SPEAKER_01: to tell your story in the most unique way is important?
[01:16:54] SPEAKER_01: And that voice needs to be heard.
[01:16:57] If you are a farmer, near retirement,
[01:17:01] SPEAKER_01: AI still matters because you're a citizen.
[01:17:05] SPEAKER_01: You can participate in your community.
[01:17:07] SPEAKER_01: You should have a voice in how AI is used,
[01:17:11] SPEAKER_01: how AI is applied.
[01:17:13] SPEAKER_01: You work with people that you can encourage all of you
[01:17:20] SPEAKER_01: to use AI to make life easier for you.
[01:17:25] SPEAKER_01: If you're a nurse, I hope you know that,
[01:17:28] SPEAKER_01: at least in my career, I have worked so much in healthcare
[01:17:34] SPEAKER_01: research because I feel our healthcare workers
[01:17:37] SPEAKER_01: should be greatly augmented and helped by AI technology.
[01:17:43] SPEAKER_01: Whether it's smart cameras to feed more information
[01:17:48] SPEAKER_01: or robotic assistance, because our nurses are overworked,
[01:17:53] SPEAKER_01: overfarteeced, and as our society ages,
[01:17:57] SPEAKER_01: we need more help for people to be taken care of.
[01:18:01] SPEAKER_01: So AI can play that role.
[01:18:03] SPEAKER_01: So I just want to say that it's so important
[01:18:06] SPEAKER_01: that even a technologist like me
[01:18:11] SPEAKER_01: are sincere about that everybody has a role in AI.
[01:18:16] SPEAKER_01: What a beautiful way to end it.
[01:18:18] SPEAKER_00: Such a tie back to where we started about how it's up to us
[01:18:21] SPEAKER_00: and taking individual responsibility
[01:18:24] SPEAKER_00: for what AI will do in our lives.
[01:18:27] SPEAKER_00: Final question, we're gonna find marble,
[01:18:29] SPEAKER_00: we're gonna go maybe try to join world labs if they want to.
[01:18:32] SPEAKER_00: What's the website, where do people get?
[01:18:34] SPEAKER_00: Well, world labs website is www.worldlaps.ai
[01:18:41] SPEAKER_01: and you can find our research progress there.
[01:18:45] SPEAKER_01: We have technical blogs.
[01:18:48] SPEAKER_01: You can find marble, the product there.
[01:18:50] SPEAKER_01: You can sign in there.
[01:18:51] SPEAKER_01: You can find our job posts, a link there.
[01:18:55] SPEAKER_01: You can, you know, we're in San Francisco.
[01:18:58] SPEAKER_01: We love to work with the world's best talents.
[01:19:02] Amazing, Feifei, thank you so much for being here.
[01:19:04] SPEAKER_00: Thank you, Lenny.
[01:19:06] Bye, everyone.
[01:19:09] Thank you so much for listening.
[01:19:11] SPEAKER_00: If you found this valuable,
[01:19:12] SPEAKER_00: you can subscribe to the show on Apple Podcasts, Spotify,
[01:19:15] SPEAKER_00: or your favorite podcast app.
[01:19:17] SPEAKER_00: Also, please consider giving us a rating or a leaving review
[01:19:20] SPEAKER_00: as that really helps other listeners find the podcast.
[01:19:23] SPEAKER_00: You can find all past episodes
[01:19:25] SPEAKER_00: or learn more about the show at Lenny'spodcast.com.
[01:19:29] SPEAKER_00: See you in the next episode.