# [Why humans are AGI's biggest bottleneck (and what's coming in 2026) | Alexander Embiricos](https://www.youtube.com/watch?v=z1ISq9Ty4Cg)

**Podcast:** Lenny's
**Date:** 2025-12-14
**Participants:** Lenny Rachitsky, Alexander Embiricos
**Region:** Western
**Video ID:** z1ISq9Ty4Cg
**Video URL:** https://www.youtube.com/watch?v=z1ISq9Ty4Cg
**Transcript:** [View Transcript](./transcript.md)

---

# Podcast Summary: Alexander Embiricos on Codex and Building AI Agents at OpenAI

## 1. Key Themes

### The Speed and Ambition Unlock at OpenAI

OpenAI operates at a fundamentally different pace than typical tech companies, even ambitious startups. Alexander describes the company's growth as transformative beyond what most founders imagine possible. "The speed and ambition of working at OpenAI are just dramatically more than what I can imagine. And I guess it's kind of an embarrassing thing to say because everyone who's a startup founder thinks like, oh, yeah, my startup moves super fast. But I have to say, working at OpenAI just made me reimagine what that even means." [[00:05:49]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=5m39s)

The evidence is concrete: Codex experienced "well over 10x since August. In fact, it's been like 20x since then" [[00:16:06]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=15m56s). The Sora Android app was built in just 18 days from zero to employee launch, and 28 days total to public release, with "two or three possibly" engineers [[00:47:41]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=47m31s). This became the number one app in the App Store. Similarly, the Atlas browser team reported that tasks "previously would have taken two to three weeks for two to three engineers. And now it's like one engineer one week" [[00:49:00]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=48m50s).

### From IDE Extension to Proactive Teammate

Codex represents a fundamental shift in how we think about coding tools—from passive assistants to proactive teammates. Alexander frames it as "just the beginning of a software engineering teammate" rather than merely a coding tool [[00:12:22]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=12m12s). The vision extends beyond writing code to participating in "ideation and planning phases of writing software and then further downstream in terms of like validation, deploying, and like maintaining code" [[00:12:38]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=12m28s).

The current limitation? "It's a bit like this really smart intern that refuses to read Slack. It doesn't check data dog, unless you ask it to" [[00:12:49]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=12m39s). The future vision involves an agent that doesn't just respond to prompts but proactively identifies work that needs doing: "You tell me what you think makes sense to be done, right?" [[00:14:02]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=13m52s). This shift from reactive to proactive represents the difference between a tool and a true teammate.

### Coding as the Universal Agent Primitive

One of the most non-obvious insights: if you want to build any kind of agent, you should probably build a coding agent. Alexander explains the logic: "One of the learnings over the past year is that for models to do stuff, they are much more effective when they can use a computer. It turns out the best way for models to use computers is simply to write code. And so we're kind of getting to this idea where if you want to build any agent, maybe you should be building a coding agent" [[00:56:59]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=56m49s).

This explains why Codex's models are becoming "the most served coding model in the API as well" [[00:16:47]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=16m37s)—not just for first-party use but across the entire ecosystem. The implications are profound: coding isn't just for software engineers anymore; it's becoming the fundamental way AI agents interact with computers and accomplish tasks.

## 2. Contrarian Perspectives

### Ready, Fire, Aim: The Value of Bottom-Up Chaos at Scale

Most companies pay lip service to being "bottom-up," but OpenAI operates with genuine radical decentralization that would terrify most executives. Alexander admits: "OpenAI is truly, truly bottomed up, and that's like been a learning experience for me" [[00:08:48]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=8m38s). This works because "very few companies have the talent caliber to be able to do that. So it might need to be like adjusted if you were gonna implement this" [[00:11:23]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=11m13s).

The approach involves maintaining clarity on the distant future ("we can have really good conversations about something that's like a year plus from now") while accepting massive ambiguity in the near term [[00:09:57]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=9m47s). This is counterintuitive because most product teams obsess over quarterly roadmaps, but OpenAI intentionally avoids that middle ground of planning.

### Living Too Far in the Future: The Codex Cloud Lesson

The initial version of Codex Cloud was actually *too advanced* for most users. Alexander explains: "That was basically a product that had its own computer. It lives in the Cloud. You can delegate to it. And the coolest part about that was you could run many, many tasks in parallel. But some of the challenges that we saw are that it's a little bit harder to set that up" [[00:17:56]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=17m46s).

The insight? "This was one of those places where the signal we got from dog fooding is a little bit different from the signal you get from the general market. Because at OpenAI, we train reasoning models all day. And so we're very used to this kind of prompting" [[00:20:40]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=20m30s). Even living at the bleeding edge, you can be *too* bleeding edge. The unlock came from stepping back to meet users where they are with IDE extensions and CLI tools before enabling the async, parallel future.

### Human Validation Speed as the AGI Bottleneck

While others focus on model capabilities, Alexander identifies a completely different limiting factor: "A current underappreciated limiting factor is like literally human typing speed or human multitasking speed" [[01:11:09]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h10m59s). The issue isn't what AI can do—it's our ability to review and validate its work.

This leads to a radically different AGI timeline perspective: "Starting next year, we're gonna see like early adopters, like starting to like hockey stick their productivity. And then over the years that follow, we're gonna see larger and larger companies like hockey stick and that productivity" [[01:12:25]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h12m15s). AGI isn't a single moment but a gradual unlocking as we solve the validation problem across different domains and company types.

### Ideas Are Still Not Worth Much (Even With AI)

Counter to the common belief that AI makes ideas more valuable since execution is easier, Alexander maintains: "I still don't think ideas are worth as much as maybe a lot of people think. I think still think execution is really hard, right? Like you can build something fast that you still need to execute well on it" [[00:53:56]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=53m46s).

The new competitive advantage isn't having ideas or even building fast—it's "really meaningful understanding of the problems that a certain customer has" [[00:54:42]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=54m32s). Distribution and deep customer knowledge matter more than ever, not less.

### The Review Problem > The Writing Problem

While everyone celebrates AI's ability to write code, Alexander identifies the emerging bottleneck: "It turns out writing code is actually one of the most fun parts of software engineering for many software engineers. It's the new and end up reviewing AI code, right? And that's often a less fun part of the job" [[00:34:38]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=34m28s).

This is why the Codex team is now "focused on just coding for now because there's so much more work to do" around validation and review [[00:52:47]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=52m37s). The next frontier isn't making AI write *more* code—it's making AI-written code *easier to trust*.

## 3. Companies Identified

### Codex (OpenAI)
**Description:** OpenAI's coding agent, available as an IDE extension and terminal tool that can write, execute, and debug code autonomously.

**Why mentioned:** As the core product Alexander leads, demonstrating 20x growth since August and becoming OpenAI's most-served coding model both internally and via API.

**Quote:** "We bumped our external number. But the 10xing of Codex's scale was just super fast in a matter of months. And it's well more since then" [[00:16:32]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=16m22s). "The codex models are serving many trillions of tokens a week now. And it's basically like our most served coding model" [[00:16:11]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=16m1s).

### GitHub Copilot
**Description:** The pioneering AI code completion tool, originally powered by OpenAI's first Codex model.

**Why mentioned:** As an example of the most successful AI product to date and the original use of the "Codex" brand.

**Quote:** "The first time we used the brand codex at OpenAI was actually the model powering GitHub Copilot. This is like way back in the day years ago. So we decided to reuse that brand recently, because it's just so good, you know, codex, code execution" [[00:39:33]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=39m23s).

### Cursor
**Description:** AI-powered code editor competing in the coding agent space.

**Mentioned as:** A key competitor in the coding agent ecosystem, with different architectural choices around tool harnesses.

### Tesla
**Description:** Electric vehicle manufacturer known for self-driving technology.

**Why mentioned:** As a masterclass in building mixed-initiative AI systems that keep humans feeling maximally empowered and in control.

**Quote:** "I think they did a really good job with enabling the car to drive itself. But all these different ways that you can adjust what it's doing without turning off the self-driving... I think it's actually a masterclass in building an agent that still leaves the human in control" [[01:20:00]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h19m50s).

## 4. People Identified

### Andrej Karpathy
**Description:** Former OpenAI researcher and Tesla AI director, known for deep technical expertise in AI.

**Why mentioned:** As an example of a power user who uses Codex for the hardest debugging problems.

**Quote:** "I remember Carpote that he tweeted, the gnarlyest bugs that he runs into, that he just spends hours trying to figure out nothing else assault he gives it to Codex. Let's run for an hour and it solves it" [[00:14:14]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=14m4s).

### Nick Turley
**Description:** Head of ChatGPT at OpenAI and former podcast guest.

**Why mentioned:** For his endorsement and the philosophy of "maximal acceleration" that permeates OpenAI.

**Quote from Nick:** "Alex is one of my all-time favorite humans I've ever worked with and bringing him and his company into OpenAI ended up being one of the best decisions we've ever made" [[00:01:44]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1m34s).

### Kevin Weil
**Description:** OpenAI's Chief Product Officer.

**Why mentioned:** For his endorsement of Alexander.

**Quote from Kevin:** "Alex is simply the best" [[00:01:57]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1m47s).

### Scott Belsky
**Description:** Adobe CPO and product thought leader.

**Why mentioned:** For his concept of "compressing the talent stack" as AI enables individuals to span multiple roles.

**Quote:** "Scott Beltsky talks about this idea of compressing the talent stack... this idea that maybe the boundaries between these roles are a little bit less needed than before because people can just do much more" [[00:44:43]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=44m33s).

## 5. Operating Insights

### Give Codex Your Hardest Problems First

Unlike other tools where you start simple, Codex performs best when given genuinely difficult tasks. "The best way to try codecs is to give it your hardest tasks, which is a little different than some of the other coding agents... We're really building codecs to be the professional tool that you can give your hardest problems to" [[01:03:11]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h3m1s). Start with a hard bug you don't understand, not a trivial task, to properly evaluate the tool.

### Build Trust Like Onboarding a New Teammate

The most effective way to use Codex mirrors how you'd onboard a human engineer: "You wouldn't go to a new teammate and just give them like, hey, do this thing. Here's the real context. You would start by like first making sure they understand the codebase and then you would like maybe align on a plan approach and then you would have them go off and do bit by bit" [[01:05:15]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h5m5s). This gradual approach naturally teaches you optimal prompting patterns.

### Designers Who Code Create Tighter Feedback Loops

OpenAI's designers "have like an entire like vibe coded sort of side prototype of the Codex app, and so a lot of how we talk about things is like, we'll have like a really quick jam... and then the design will like go think about how this should work, but instead of like talking about it again, I'll just like vibe code a prototype" [[00:46:45]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=46m35s). This eliminates entire communication rounds and allows design iteration at unprecedented speed.

### Reddit Over Twitter for Real Product Signal

While Twitter is "a little bit more hypey," Reddit provides more authentic feedback: "Reddit is a little more negative but real actually. So I've started increasingly paying attention to like how people are talking about using Codex on Reddit" [[00:57:28]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=57m18s). The upvoting mechanics help surface what truly matters versus individual complaints.

### Dogfood Across Career Stages, Not Just Power Users

Alexander maintains multiple ChatGPT Pro accounts paid out of pocket to "maximally correctly dog food, like sign up for my Gmail" [[00:56:18]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=56m8s) and experience the new user journey. When building tools that naturally create power users, it's critical to constantly return to the day 1 experience rather than only optimizing for advanced workflows.

## 6. Overlooked Insights

### Codex is Already On-Call for Its Own Training

Buried in the conversation is a remarkable glimpse of the future already happening: "We're starting to see glimpses of the future where we're actually starting to have Codex even like the on call for its own training" [[01:09:28]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h9m18s). Codex writes code for its training infrastructure, reviews that code for mistakes, and is beginning to monitor training runs autonomously. "Having codex like run on a loop to like evaluate how those charts are moving over time, this sort of this idea that we have to like how to enable us to like train like way more efficiently" [[01:10:18]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h10m8s).

This creates a recursive improvement loop where Codex accelerates its own development—a microcosm of the broader AGI feedback loop Alexander describes. Most people focus on Codex helping external developers, but the fact that it's already helping train better versions of itself suggests the hockey stick acceleration may come sooner than expected.

### Atlas Browser as Contextual Action Platform

While most coverage focuses on Atlas as "OpenAI's browser," Alexander reveals a deeper strategic insight. The browser isn't primarily about search—it's about enabling contextual actions: "Part of why I'm excited for us to have a browser is that I think we have then like much more context around like what we should help with" [[01:01:29]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=1h1m19s).

The key insight: "Imagine this world that we reach, right? Where we have agents that are helping you thousands of times per day. Imagine if the only way we could tell you that we helped you was if we could like push, notify you. So you get a thousand push notifications a day... It'd be super annoying, right?" [[00:57:51]](https://www.youtube.com/watch?v=z1ISq9Ty4Cg&t=57m41s). Instead, Atlas enables contextual interventions—like auto-complete for your entire web workflow. This positions OpenAI to capture value across all knowledge work, not just coding, by owning the surface where contextual AI can be delivered without notification fatigue.

---

This podcast reveals OpenAI's product philosophy: bet on the future but meet users where they are, prioritize making humans feel accelerated over raw capability, and recognize that the biggest unlock isn't smarter models but better human-AI collaboration patterns. The most valuable insight may be that we're limited less by AI capability than by our own typing speed and validation bandwidth—suggesting the next frontier is designing systems where AI can safely act without constant human approval.