# [How this secret data company is powering the AI revolution | Edwin Chen](https://www.youtube.com/watch?v=dduQeaqmpnI)

**Podcast:** Lenny's
**Date:** 2025-12-07
**Participants:** Lenny Rachitsky, Edwin Chen
**Region:** Western
**Video ID:** dduQeaqmpnI
**Video URL:** https://www.youtube.com/watch?v=dduQeaqmpnI
**Transcript:** [View Transcript](./transcript.md)

---

# Podcast Summary: Edwin Chen, Founder & CEO of Surge AI

## 1. Key Themes

### The Anti-Silicon Valley Playbook: Building a Billion-Dollar Company Without VC Money

Edwin Chen built Surge AI to over $1 billion in revenue in under 4 years with fewer than 100 people, completely bootstrapped. His contrarian approach rejected traditional Silicon Valley wisdom: "We basically never wanted to play this Silicon Valley game. I always started as a ridiculous. What did you dream of doing when you were a kid? Was it building a company from scratch yourself and getting in the weeds of your code and your product every day? Or was it explaining all your decisions to VCs and getting on this giant PR and fundraising hamster wheel?" [[00:00:27]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=17s)

Chen emphasizes that staying focused on mission over metrics enabled better customer alignment: "I always thought it was really important for us to have customers, early customers, who were really aligned with what we were building and who really cared about having really high quality data... because they were the ones helping us. They were giving us feedback on what we're producing." [[00:00:41]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=31s)

### Quality Over Scale: Why Data Quality is AI's Most Underestimated Challenge

Chen argues that most people fundamentally misunderstand quality in AI training: "I think most people don't understand what quality even means in this space. They think you could just throw bodies at a problem and get good data and that's completely wrong." [[00:09:47]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=9m37s)

He uses poetry as an example: "Imagine you wanted to train a model to write a poem about the moon. What makes it a good high quality poem? If you don't think deeply about quality, you'll be like, is this a poem? Does it contain eight lines? Does it contain a word moon?... But that's completely different from what we want. We are looking for Nobel Prize winning poetry." [[00:09:59]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=9m49s)

Surge implements thousands of signals to measure quality: "We essentially gather thousands of the signals about everything that you're doing when you're working on platform. So we are looking at your keyboard strokes. We are looking how fast you answer things. We are using reviews. We are using code standards... And we're seeing whether they improve the models performance." [[00:12:02]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=11m52s)

### The Dangerous Direction of AI: Optimizing for Engagement Instead of Truth

Chen has a stark warning about current AI development trends: "I'm worried that instead of building AI that will actually advance us as a species, curing cancer, solving poverty, understanding universe, we are optimizing for AI slop instead. We're basically teaching models to chase dopamine instead of truth." [[00:01:18]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=1m8s)

He criticizes popular benchmarks like LM Arena: "It's this popular online leaderboard where random people from around the world vote on which AI response is better. But the thing is, they're not carefully reading or fact-checking. They're skimming through responses for two seconds and picking whatever looks fanciest... It's literally optimizing your models for the types of people who buy tablets at the grocery store." [[00:23:38]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=23m28s)

He also warns about engagement optimization: "I used to work on social media. And every time we optimize for engagement, terrible things happened. You'd get clickbait and pictures of bikinis and big food and horrifying skin diseases just filling your feeds. And I think the same things happening with AI." [[00:25:06]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=24m56s)

## 2. Contrarian Perspectives

### Small Teams Outperform Massive Organizations

Chen's most radical belief stems from his Big Tech experience: "I used to work in a bunch of big tech companies and I always felt that we could fire 90% of people and we would move faster because the best people would have all these distractions. And so when we started Surge, we wanted to build it completely differently with a super small, super elite team." [[00:00:14]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=4s)

He believes this will become the norm: "I think we're going to see companies with even crazier ratios, like 100 billion per employee in the next few years. AI is just going to get better and better and make things more efficient. So that ratio just becomes inevitable." [[00:05:42]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=5m32s)

### Don't Pivot: The Anti-Startup Advice

Directly contradicting conventional startup wisdom, Chen advocates against pivoting: "The standard playbook is to get product market fit by pivoting every two weeks and to chase growth and chase engagement with all of these dark patterns and to blitz scale by hiring as fast as possible. And I've always disagreed. So yeah, I would say don't pivot, don't blitz scale." [[00:29:04]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=28m54s)

He explains his philosophy: "Startups is supposed to be about taking big risks to build something that you really believe in. But if you're constantly pivoting, you're not taking risks. You're just trying to make a quick buck... I think the only way you build something that matters is if you find a big idea you believe in and you say no to everything else." [[00:30:23]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=30m13s)

### Benchmarks Are Misleading and Often Wrong

Chen has little faith in academic benchmarks: "I don't trust the benchmarks at all... I think a lot of people don't realize even researchers within the community, they don't realize that the benchmarks themselves are often honestly just wrong. Like they have wrong answers. They're full of all this kind of messiness." [[00:18:03]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=17m53s)

He provides a striking example: "It's kind of crazy that these models can win IMO gold medals, but they still have trouble parsing PDFs. And that's because yeah, even though IMO gold medals seem hard to average person, they have this notion of objectivity that parsing PDFs sometimes doesn't have." [[00:18:49]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=18m39s)

### Vibe Coding Is Overhyped and Dangerous

Against the trend of celebrating AI-generated code, Chen warns: "I definitely think that vibe coding is overhyped. I think people don't realize how much it's going to make your systems unmaintainable in the long term... You're just dumping this code into your code bases. You've seen it work right now. So I kind of worry about vibe coding." [[00:52:13]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=52m3s)

### The Values of AI Labs Will Create Fundamentally Different Models

Chen predicts differentiation, not commoditization: "A year or so ago, I thought that all the AI models would essentially become very, very commoditized... But I think over the past year, I've realized that the values that the companies have will shape the model." [[00:48:41]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=48m31s)

His personal example illustrates this: "I was asking Claude to help me draft an email the other day and it went through 30 different versions. And after 30 minutes, I realized I spent 30 minutes doing something that didn't matter at all... Do you want a model that says, you're absolutely right. There are definitely 20 more ways to improve this email and it continues for 50 more iterations? Or do you want a model that's optimizing for your time and productivity and just says, no, you need to stop. Your email is great. Just send it and move on." [[00:48:48]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=48m38s)

## 3. Companies Identified

### Anthropic
**Description:** Frontier AI lab developing Claude AI models  
**Why mentioned:** Praised for principled approach to AI development  
**Quotes:** "I would say I've always been very, very impressed by Anthropic. Like, I think Anthropic takes a very principled view about what they do and don't care about and how they want their models to behave in a way that feels a lot more principled to me." [[00:26:22]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=26m12s)

### DeepMind
**Description:** Google's AI research lab  
**Why mentioned:** Cited as Chen's inspiration for combining research excellence with company building  
**Quotes:** "I was actually always a huge fan of DeepMind because they were this amazing research company that got bought and still managed to keep on doing amazing science. But I always thought that they were this magical unicorn." [[01:01:23]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=1h1m13s)

### Waymo
**Description:** Autonomous vehicle company  
**Why mentioned:** Example of exceeding hype expectations  
**Quotes:** "I was in SF earlier this week, and I finally took a Waymo for the first time. Honestly, it was magical and it really felt like living in the future." [[01:05:35]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=1h5m25s)

## 4. People Identified

### Terence Tao
**Description:** Renowned mathematician  
**Why mentioned:** Represents Chen's aspirational model of impact over wealth  
**Quotes:** "I've always said, I would rather be Terence Tao than Warren Buffett. So that notion of creating research that pushes the field forward and not just getting some valuation, like that's always been what drives me." [[00:47:12]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=47m2s)

### Richard Sutton
**Description:** Famous AI researcher known for "the bitter lesson"  
**Why mentioned:** His podcast with Dwarkesh discussed potential limitations of LLMs  
**Quotes:** "Imagine you watched the Dwarkesh and Richard Sutton podcast episode... they basically had this conversation with Richard Sutton... And he talked about how LLMs almost are kind of a dead end." [[00:33:12]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=33m2s)

### Ted Chiang
**Description:** Science fiction author  
**Why mentioned:** Author of Chen's favorite short story about linguistics and alien communication  
**Quotes:** "Three books I often recommend are first Story of Your Life by Ted Chiang. It's my all-time favorite short story. And it's about a linguist deciphering an alien language. And I obviously reread it every couple years." [[01:03:45]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=1h3m35s)

## 5. Operating Insights

### Build Internal Research Teams as a Competitive Moat

Surge maintains its own research team, which is unusual for a services company: "We almost have two types of researchers at our company. One is our deployed researchers who are often working hand in hand with our customers to help them understand their models... And then we also have our internal researchers... focused on building better benchmarks and better leaderboards." [[00:45:12]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=45m2s)

This creates a virtuous cycle where Surge helps labs improve while building proprietary knowledge: "What our research team is focused on is, really, we have really focused really heavily on right now. So they're working a lot on that. And they're also working on these other things, like, OK, we need to train our models to see what types of data performs the best." [[00:46:18]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=46m8s)

### Signal-Based Quality Control at Massive Scale

Rather than simplistic pass/fail metrics, Surge uses sophisticated multi-dimensional quality assessment: "We essentially gather thousands of signals about everything that you're doing when you're working on platform... And so in a very similar way to how Google search, when Google search is trying to determine what is a good web page, there's almost two aspects of it. One is you want to remove all the worst web pages... But then you also want to discover the best of the best." [[00:12:02]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=11m52s)

### Hands-On CEO Involvement in Core Product

Despite leading a billion-dollar company, Chen remains deeply involved in technical work: "What I love doing most is every time a new model is released, I'll actually do a really deep dive into the model itself. I'll play around with it, I'll run evals, I'll compare where it's improved, where it's regressed. I'll create this really deep dive analysis that we send our customers." [[00:55:34]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=55m24s)

This creates authentic expertise and customer trust: "It's kind of funny, because a lot of times, we will say it's from our data science team, but often it's actually just from me. And I think I could do this all day." [[00:55:50]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=55m40s)

### Hire for Deep Subject Matter Obsession, Not Credentials

Surge's hiring philosophy emphasizes intrinsic motivation: "We look for people who are just fundamentally interested in datasets all day. So types of people who could literally spend 10 hours digging through a dataset and playing around with models and thinking, okay, yeah, this is where I think the model is failing. This is kind of the behavior you want the model to have instead." [[00:47:36]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=47m26s)

### Think of Post-Training as Raising a Child

Chen reframes data labeling with a profound analogy: "I think a lot of people think of data labeling as really simplistic work, like labeling cat photos and drawing bounding boxes around cars. And so I've actually always hated the word data labeling... I think a lot about what we're doing as a lot more like raising a child. You don't just feed a child information. You're teaching them values and creativity and what's beautiful. And these infinite subtle things about what makes somebody a good person. And that's what we're doing for AI." [[01:02:38]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=1h2m28s)

## 6. Overlooked Insights

### Trajectories Matter More Than Final Outcomes in RL

While discussing reinforcement learning environments, Chen revealed a subtle but crucial insight: "I think one of the things that people don't realize is that sometimes even though the model reaches the correct answer, it does so in all these crazy ways... It may have tried 50 different times and failed, but eventually it just randomly lands on a correct number or maybe it just does things very inefficiently or it almost brute forces a way to get at the correct answer." [[00:39:57]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=39m47s)

This suggests that simply rewarding correct final answers misses critical learning opportunities about efficiency, reasoning quality, and process. The implication is that current RL approaches may be creating models that succeed for the wrong reasons, which could explain unexpected failure modes.

### Taste and Sophistication in Model Training Is Art, Not Science

Chen briefly mentioned something profound about the post-training process: "When you're deciding what kind of model you're trying to create and what it's good at, there's this notion of taste and sophistication... Maybe you have a different notion of visual design than what I do. Like maybe you care more about minimalism and I care more about 3D animations than I do. Maybe you personally prefer things that look a little bit more pro." [[00:16:01]](https://www.youtube.com/watch?v=dduQeaqmpnI&t=15m51s)

This reveals that the supposed objectivity of AI development is partially an illusionâ€”the aesthetic and philosophical preferences of the teams building these systems are being encoded into models at a fundamental level. This has enormous implications for AI safety and alignment that go far beyond technical considerations into questions of whose values shape humanity's AI future.