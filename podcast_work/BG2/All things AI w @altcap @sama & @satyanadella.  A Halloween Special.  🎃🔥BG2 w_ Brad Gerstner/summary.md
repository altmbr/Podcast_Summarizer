# [All things AI w @altcap @sama & @satyanadella.  A Halloween Special.  ðŸŽƒðŸ”¥BG2 w/ Brad Gerstner](https://www.youtube.com/watch?v=Gnl833wXRz0)

**Podcast:** BG2
**Date:** October 31, 2025
**Region:** Western
**Video ID:** Gnl833wXRz0
**Video URL:** https://www.youtube.com/watch?v=Gnl833wXRz0
**Transcript:** [View Transcript](./transcript.md)

---

# Summary: All Things AI with Brad Gerstner, Sam Altman & Satya Nadella

## 1. Key Themes

### Microsoft-OpenAI Partnership Creates Unprecedented Value Distribution
The restructuring of the Microsoft-OpenAI partnership represents one of the most significant tech partnerships in history. Microsoft invested approximately $13-14 billion for 27% ownership on a fully diluted basis, but more importantly, the deal created a $130 billion nonprofit foundation - already one of the largest in the world.

**"I think this has really been an amazing partnership through every phase. We had no idea where it was going to go when we started, as Satya said. But I don't think this is one of the great tech partnerships ever. And certainly without Microsoft and particularly Satya's early conviction, we would not have been able to do that."** - Sam Altman [[00:00:05]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=0s)

**"It's not what we thought. And as I said to somebody, it's not like when we first invested our billion dollars, that this is going to be the 100-bagger that I'm going to be talking about to VCs about. There we are, but we are very thrilled to be an investor and an early backer."** - Satya Nadella [[00:03:37]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=3m27s)

The deal structure includes: (1) Microsoft gets exclusive distribution of OpenAI's stateless APIs on Azure until 2032 or AGI verification, (2) A revenue share agreement on all OpenAI revenues running until the same timeframe, (3) OpenAI committed $250 billion to Azure over multiple years, and (4) OpenAI can distribute open source models, devices, and other products on other platforms.

### Compute Scarcity as the Defining Constraint of the AI Era
Both leaders emphasized that compute constraints - not demand - are the primary limitation on growth. The bottleneck has evolved from GPU availability to power infrastructure and "warm shelves" to plug systems into.

**"The secular trend is what Sam said which is at the end of the day because quite frankly the biggest issue we are now having is not a compute glut but it's a power and it's sort of the ability to get the bills done fast enough close to power. So if you can't do that you may actually have a bunch of chips sitting in inventory that I can't plug in in fact that is my problem today right it's not a supply issue of chips it's actually the fact that I don't have warm shelves to plug into."** - Satya Nadella [[00:18:36]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=18m26s)

**"I just look at how much we are held back and in many ways we have you know we've scaled our compute probably 10X over the past year. But if we had 10X more compute I don't know if we'd have 10X more revenue but I don't think of you that far."** - Greg Brockman (quoted) [[00:15:06]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=14m56s)

OpenAI announced $1.4 trillion in compute commitments over the next 4-5 years, including $500 million to Nvidia, $300 million to AMD and Oracle, and $250 billion to Azure - commitments that initially raised questions but reflect forward-looking revenue confidence.

### The Fundamental Architecture of Software is Being Rebuilt
The conversation revealed that the entire SaaS application layer is being reconstructed around AI agents replacing traditional business logic tiers. This represents the most significant change to enterprise software architecture in decades.

**"The last time we talked about this my point really there was the architecture of SaaS applications is changing because this agent here is replacing the old business logic tier and so because if you think about it the way we build SaaS applications in the past was you had the data the logic tier and the UI all tightly coupled and AI quite frankly doesn't respect that coupling."** - Satya Nadella [[00:54:25]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=54m15s)

**"The next generation of SaaS applications will have to sort of if you are high RPU low usage then you have a little bit of a problem but if you are we are the exact opposite we are low RPU high usage and I think that anyone who can structure that and then use this AI as in fact an accelerant."** - Satya Nadella [[00:55:46]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=55m36s)

The new model separates into two factories: the "token factory" (efficient inference infrastructure) and the "agent factory" (intelligent applications optimized for specific business outcomes and evaluations).

## 2. Contrarian Perspectives

### AI Will Create Supply-Side Deflation, Not Just Demand Growth
While most focus on AI driving demand, both leaders emphasized the deflationary pressure AI creates through exponential efficiency improvements - averaging 40X cost reduction per unit of intelligence annually.

**"If a very cheap form of energy comes online soon at mass scale and a lot of people are going to be extremely burned with existing contracts they've signed. If we can continue this unbelievable reduction in cost per unit of intelligence let's say it's been averaging like 40X for a given level per year you know that's like a very scary exponent from an infrastructure build out standpoint."** - Sam Altman [[00:20:16]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=20m6s)

**"The optimizations that open AI's done on the inference stack for a given GPU I mean it's kind of like it's you know we talk about the Moore's law improvement on one end. Software improvements are much more exponential than that."** - Satya Nadella [[01:21:09]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h20m59s)

This suggests infrastructure investors face significant risk if efficiency improvements accelerate faster than demand growth, potentially creating cycles of oversupply.

### Consumer AI Economics Remain Fundamentally Unclear
Contrary to the narrative that AI economics are well-understood, both leaders admitted the consumer monetization model for AI is "murky" and fundamentally different from search economics.

**"Search was pretty magical in terms of its ad unit and its cost economics because there was the index which was a fixed cost that you could then amortize in a much more efficient way. Whereas this one, you know, each chat to your point, you have to burn a lot more GPU cycles both with the intent and the retrieval. So the economics are different."** - Satya Nadella [[01:01:02]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h0m52s)

**"So we are yet to discover whether it's agentic commerce or whatever is the ad unit, how it's going to be litigated... I think that is going to be a real litigation. Just like that we talked about the SaaS disruption, we're in the beginning of the cheese being a little moved in consumer economics of that category."** - Satya Nadella [[01:02:08]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h1m58s)

This challenges the assumption that AI simply replaces search with better economics - the reality may be more complex and less immediately profitable.

### State-Level AI Regulation Poses Greater Risk Than Federal Oversight
While much attention focuses on federal AI regulation, the real threat comes from state patchwork laws that create impossible compliance burdens, particularly for startups.

**"I don't know how we're supposed to comply with that California it's sorry Colorado law I would love them to tell us and you know we'd like to be able to do it but that's just from what I read of that that's like I literally don't know what we're supposed to do I'm very worried about a 50 state patchwork I think it's a big mistake."** - Sam Altman [[00:25:28]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=25m18s)

**"The fundamental problem of you know this patchwork approaches quite frankly I mean between open AI and Microsoft will figure out a way to navigate this right I mean we can figure this out the problem is anyone starting a startup and trying to kind of this is sort of it just goes to the exact opposite or I think what the intent here is."** - Satya Nadella [[00:25:57]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=25m47s)

This suggests the regulatory environment could inadvertently create winner-take-all dynamics by raising barriers to entry for new AI companies.

### Microsoft's Search Business Will Be Disrupted Despite Being Highly Profitable
Nadella openly acknowledged that the shift from search to agentic AI will fundamentally change - and potentially reduce - the extraordinary unit economics of the search business, one of the most profitable in history.

**"I kind of know, in fact I use search for very, very specific navigational queries. I used to say I use it a lot for commerce, but that's also shifting to my, you know, Copilot, look, I look at the Copilot mode in edge and being or Copilot."** - Satya Nadella [[01:01:54]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h1m44s)

This is contrarian because most companies wouldn't openly discuss the disruption of their highest-margin businesses.

### The "Getting Fit" Narrative Masks Fundamental Productivity Shifts
While media attributes recent tech layoffs to post-COVID correction, the leaders suggested this actually reflects the beginning of AI-driven productivity gains that allow revenue growth with proportionally less headcount growth.

**"If you are question, I will say we will grow a head count. But the way I look at it is that head count we grow will grow with a lot more leverage than the head count we had pre-AI. And that's the adjustment, I think structurally or seen first."** - Satya Nadella [[01:08:06]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h7m56s)

**"I caught the golden age of margin expansion. I'm a firm believer that the productivity curve does and will bend or in the sense that we will start seeing some of what is the work and the work flowing particular change."** - Satya Nadella [[01:04:50]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h4m40s)

## 3. Companies Identified

### OpenAI
Leading AI research and deployment company, now structured with a Public Benefit Corporation underneath a nonprofit foundation.

**"We carefully plan we understand where the technology where the capability is going to grow go and how the products we can build around that in the revenue we can generate... there is not be the single business plan that I've seen from open AI that they're put in and not beaten it."** - Satya Nadella [[00:14:08]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=13m58s)

**"Open AI everyone talks about all the success in the usage and what have you. But even I would say all up the business execution is being just pretty unbelievable."** - Satya Nadella [[00:14:37]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=14m27s)

Revenue: ~$13 billion in 2025, targeting excess of $100 billion by 2028-29. Considering IPO potentially in 2027, could be valued at ~$1 trillion at 10x revenue multiple.

### GitHub (Microsoft-owned)
Code repository and development platform, showing unprecedented growth due to AI coding assistants.

**"What GitHub did in first or no 15 years of its existence or 10 years of its existence it was basically done in the last year just because coding is no longer a tool it's more a substitute for wages and so it's a very different type of business model."** - Satya Nadella [[00:56:38]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=56m28s)

**"Codex has been in a very cool thing to watch this year and as these go from multi hour tasks to multi day tasks which I expect to happen next year what people be able to do to create software unprecedented rate and really in fundamentally new ways I'm very excited for that."** - Sam Altman [[00:28:39]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=28m29s)

### Nvidia
Dominant GPU provider for AI infrastructure, maintaining pricing power through rapid innovation cycles.

**"One of the things I like is the speed of light right we now have GB 300 is bringing you know that we're bringing up. You don't want to have ordered a bunch of GB 200s that are getting plugged in only to find the GB 200s are in full production so you kind of have to make sure you're continuously modernizing."** - Satya Nadella [[00:43:15]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=43m5s)

OpenAI committed $500 million to Nvidia as part of its $1.4 trillion compute commitment.

### AMD
Secondary GPU provider gaining traction in AI infrastructure.

OpenAI committed $300 million to AMD and Oracle as part of diversification strategy.

### TSMC
Semiconductor manufacturing, building fabs in Arizona as part of U.S. reindustrialization.

**"Even before you get to what is happening in Arizona with the TSMC plans or what was happening with micron and their investments in memory or Intel and their fabs."** - Satya Nadella [[01:12:00]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h11m50s)

## 4. Operating Insights

### Build Fungible Fleet Architecture for Maximum Utilization
Microsoft's key operational decision was prioritizing fleet fungibility across workloads, geographies, and chip generations over dedicated single-purpose infrastructure.

**"The concept of building a fleet that truly was fungible fungible for all the parts of the life cycle of AI fungible across geographies and fungible across generations... You don't want to have ordered a bunch of GB 200s that are getting plugged in only to find the GB 200s are in full production so you kind of have to make sure you're continuously modernizing you're spreading the fleet all over you are really truly fungible by workload."** - Satya Nadella [[00:42:56]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=42m46s)

This approach sometimes means saying no to customer demand (including OpenAI's) to optimize long-term infrastructure value. The tradeoff: slower near-term growth for better long-term economics and flexibility.

### Democratize AI Tools Internally Before External Deployment
Microsoft made all employees "standard issue" for full AI tool access, treating internal deployment as both a productivity driver and a learning laboratory.

**"We want to make sure that everybody at Microsoft's standard issue, right? All of them have Microsoft 365 to the tilt in the most unlimited way and have GitHub co-pilot so that they can really be more productive. But here is the other interesting thing that we're learning is there's a new way to even learn, which is how to work with agents."** - Satya Nadella [[01:05:25]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=1h5m15s)

The network operations leader example: Rather than requesting more headcount for fiber operations across 400 global operators, she built agents to automate DevOps pipelines - a pattern of empowering employees to solve constraints through AI rather than traditional resource allocation.

### Optimize for "Auto Mode" - Let AI Choose the Right Model
GitHub Copilot's "auto mode" intelligently selects which model to use based on the specific task, optimizing for cost and performance rather than defaulting to the most powerful model.

**"The auto mode of get up co pilot is the smartest thing we've done right so it chooses based on the problem which modern tools are going to be done based on the prompt, which model to use for a code completion or a task handoff... you do that, not just by choosing in some round-drop in fashion, you're doing because of the feedback cycle you have, you have the e-vals, the data loops and so on."** - Satya Nadella [[00:59:13]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=59m3s)

This creates the "agent factory" concept - applications that optimize token usage for specific business outcomes rather than maximizing model capability.

### Measure Success by Data Creation, Not Just Usage
Counter-intuitively, AI is driving all-time highs in data creation (code, documents, conversations) rather than reducing it, creating a flywheel for future AI improvements.

**"One of the fascinating things that's happened Brad with both GitHub and Microsoft 365 is thanks to AI we are seeing all time highs in terms of data that's going into the graph or the repo... more code that gets generated whether it is codex or clad or wherever where is it going GitHub... all these artifacts... are all going into the graph."** - Satya Nadella [[00:55:20]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=55m10s)

This data becomes the forward index and embeddings for grounding future agent requests, creating compounding value.

### Shape Demand When Supply Constrained
Rather than simply trying to meet all demand, Microsoft actively shapes demand to match optimal supply allocation across customer segments and use cases.

**"We're shaping the demand here you know we are in a supply you know you know we're not demand constraint we're supply constraint so we're shaping the demand such that it matches the supply in the optimal way with the long term view."** - Satya Nadella [[00:46:09]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=45m59s)

This includes balancing first-party needs (Copilot, security) against third-party Azure growth, and diversifying beyond any single large customer.

## 5. Overlooked Insights

### The RPO-to-Duration Ratio Reveals Hidden Demand Certainty
While Microsoft's $400 billion in remaining performance obligations got headlines, the critical overlooked detail is the short two-year average duration, indicating this is highly certain near-term revenue, not speculative long-term bookings.

**"That 400 billion has a very short duration as Amy explained it's the two-year duration on average so that's definitely our intent that's one of the reasons why we're spending the capital out clear with high certainty that we just need to clear right backlog."** - Satya Nadella [[00:47:06]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=46m56s)

This suggests Azure's growth trajectory is far more locked-in than typical enterprise software, where long-term contracts create revenue smoothing but less certainty. The $250 billion OpenAI commitment isn't even included in this number and will have longer duration. This data point fundamentally changes the risk profile of Microsoft's AI infrastructure investment.

### The Nonprofit Structure May Enable Unlimited Capital Formation
Sam's comment about the nonprofit growing in value "while the PBC is able to get the capital that it needs to keep scaling" hints at a potentially revolutionary capital structure that was barely explored in the conversation.

**"I really like this structure because it lets the nonprofit grow in value while the PBC is able to get the capital that it needs to keep scaling. I don't think the nonprofit would be able to be this valuable if we didn't come up with the structure."** - Sam Altman [[00:05:04]](https://www.youtube.com/watch?v=Gnl833wXRz0&t=4m54s)

This structure could allow OpenAI to raise theoretically unlimited capital through the PBC (which can issue equity and debt) while the nonprofit stake ($130 billion currently, potentially much more) grows passively. This may be the blueprint for funding extremely capital-intensive long-term research missions - a model that could be replicated for other grand challenges like fusion energy, longevity research, or space exploration. The brief mention deserves much deeper analysis as a potential innovation in organizational design for funding moonshots.