# Lindon Gao,  Dyna Robotics, Sebastian Spitzer, AI Infra, HPE - F50 Physical AI Summit

**Podcast:** One-off Episodes
**Date:** 2025-11-11
**Video ID:** v1Gdle61Bho
**Video URL:** https://www.youtube.com/watch?v=v1Gdle61Bho

---

[00:00:00] Who came for the robots today?
[00:00:02] SPEAKER_01: Everyone.
[00:00:03] SPEAKER_01: Who came for the humans?
[00:00:06] Okay.
[00:00:07] Let's go ahead.
[00:00:08] SPEAKER_00: I'm going to go to Jennifer Purpose-Jay-Auts.
[00:00:10] SPEAKER_00: More specifically, we leverage existing foundation models,
[00:00:15] SPEAKER_00: and general models to deploy production in production environments.
[00:00:19] SPEAKER_00: Our clients are mostly in hospitality space,
[00:00:24] SPEAKER_00: longer mask hotels, hospitals,
[00:00:28] SPEAKER_00: also manufacturing, and group yellow space as well.
[00:00:32] SPEAKER_00: And since we found the last year, we raised $120 plus $100.
[00:00:39] SPEAKER_00: And we're one of the frontier labs in downtown World War Research.
[00:00:46] Perfect.
[00:00:47] SPEAKER_01: Maybe I'm quick and from us out of this well.
[00:00:49] SPEAKER_01: So spending a decade in the old motor industry, we've cropped up in the CDC work.
[00:00:54] SPEAKER_01: When you're looking at manufacturing technologies, robotics,
[00:00:57] SPEAKER_01: one of the last investments we did was agility robotics,
[00:01:00] SPEAKER_01: one of the unit companies.
[00:01:02] SPEAKER_01: After that, we're in the cybersecurity program here,
[00:01:05] SPEAKER_01: and now with HPE working on the infrastructure layer.
[00:01:08] SPEAKER_01: So anything with GPUs and compute on them, off-prem, on the edge.
[00:01:14] SPEAKER_01: And as such, we're also working with robotics companies and physically I startups.
[00:01:19] SPEAKER_01: And we're not being said.
[00:01:21] SPEAKER_01: We already gave a good segue into this chat.
[00:01:24] SPEAKER_01: So you work with hospitality companies and some of you's cases
[00:01:29] SPEAKER_01: that are not that covered yet with robotics solutions,
[00:01:33] SPEAKER_01: everyone's like going for manufacturing environments with people
[00:01:36] SPEAKER_01: starting the other motor industry.
[00:01:38] SPEAKER_01: So what excites you about those application areas
[00:01:42] SPEAKER_01: and what are specific challenges anyway,
[00:01:44] SPEAKER_01: in countering those compared to traditional manufacturing models?
[00:01:49] SPEAKER_00: So you probably want to break all the variation down to a couple of layers.
[00:01:53] SPEAKER_00: So first layer is structure environment.
[00:01:55] SPEAKER_00: Structure environment is our traditional manufacturing.
[00:01:57] SPEAKER_00: So where you have machines that goes into wavelength XYZ.
[00:02:01] SPEAKER_00: And it doesn't necessarily know exactly what it was doing,
[00:02:04] SPEAKER_00: but it has to be human-cricized and it actually moves really, really fast
[00:02:08] SPEAKER_00: as they can have what it cleanses the cars on daily basis.
[00:02:11] SPEAKER_00: The second piece is semi-structure.
[00:02:14] SPEAKER_00: A semi-structure where is it in the environment that we were human
[00:02:17] SPEAKER_00: and used to do some of what says, this could be some body manipulation.
[00:02:20] SPEAKER_00: These could be manipulation that requires high amount of variables
[00:02:25] SPEAKER_00: like being in place in the warehouse and so forth.
[00:02:27] SPEAKER_00: Those are not something that you could program.
[00:02:30] SPEAKER_00: And it cannot fall with a predefined trajectory.
[00:02:32] SPEAKER_00: But rather, you should make determinations on how to graph the workplace
[00:02:36] SPEAKER_00: and how you manage to get the end of the influence of the outlets.
[00:02:40] SPEAKER_00: And then going from semi-structure to on-structure environment,
[00:02:43] SPEAKER_00: this is like where you are thinking about how you potentially augment human capacity
[00:02:49] SPEAKER_00: with robots that can actually prevent end tasks such as making a longer scenario
[00:02:54] SPEAKER_00: in those how to put the laundry into the washer, transfer into a dryer,
[00:02:58] SPEAKER_00: take it out, fold it and put it on the shelf.
[00:03:00] SPEAKER_00: And then the chaotic environment is something that's as vulnerable to homes.
[00:03:04] SPEAKER_00: So the really, really exciting part of our automation is that combination models
[00:03:08] SPEAKER_00: right now, so this similar transformer architecture models now are able
[00:03:12] SPEAKER_00: to start automating end work from semi-structure all the way to chaotic.
[00:03:17] SPEAKER_00: And that's the part that's really, really exciting.
[00:03:20] SPEAKER_00: And those are the automation areas that we know.
[00:03:24] I love that.
[00:03:25] Coming from the manufacturing world, right?
[00:03:28] SPEAKER_01: You said the right, the automotive industry has been highly automated
[00:03:32] SPEAKER_01: and institutionalized, industrialized for the last five decades almost.
[00:03:39] SPEAKER_01: So we mainly operate in very structural environments.
[00:03:42] SPEAKER_01: And as such, it's just a different scenario to bring a robot into
[00:03:47] SPEAKER_01: and most of it already uses robots.
[00:03:49] SPEAKER_01: So when you comment on environments that do not necessarily use robots right now,
[00:03:54] SPEAKER_01: what are the biggest challenges that you see in those environments
[00:03:57] SPEAKER_01: and how do you work with data?
[00:03:59] SPEAKER_01: What's more important, my data quantity, quality, can you like Shesland's,
[00:04:03] SPEAKER_01: as well?
[00:04:04] SPEAKER_00: Well, I think one of the biggest challenges to move into a environment where it has not been automated
[00:04:08] SPEAKER_00: is actually registering your robots into your existing environment
[00:04:11] SPEAKER_00: and staying away from it matches your existing workflow.
[00:04:14] SPEAKER_00: Because typically in manufacturing environment your workflow has already been
[00:04:17] SPEAKER_00: a purpose for a target with line of work.
[00:04:20] SPEAKER_00: But in areas where it hasn't been, it's matching your existing workflow enough.
[00:04:25] SPEAKER_00: This is where some argument or a humanoid will loss a company because they can actually work
[00:04:29] SPEAKER_00: what they can be in sort of a complement or existing workflows.
[00:04:33] SPEAKER_00: Now with regards to our research side, which is like what is missing in the research?
[00:04:38] N-Tem models has a lot of great promises, they're used to strategy PT
[00:04:42] SPEAKER_00: and the language model is vision high for the models and the two wonders.
[00:04:45] SPEAKER_00: But the problem in embodied AI is that there's a general lack of data in this little space today.
[00:04:51] SPEAKER_00: Right?
[00:04:52] SPEAKER_00: So, and on top of the general lack of data, the N-Tem models does not perform at human level yet.
[00:04:58] SPEAKER_00: So, a lot of the research that we have been doing and how we systematically draw about
[00:05:02] SPEAKER_00: the quality of execution, the throughput of execution, the robustness of execution
[00:05:06] SPEAKER_00: such that it will minimize the amount of human interventions within actual plus the plus or plus.
[00:05:11] I love that.
[00:05:13] SPEAKER_01: Double tapping on that.
[00:05:15] SPEAKER_01: So, when you have a structure in my room and it's fairly easy to get training data.
[00:05:21] SPEAKER_01: Well, not always easy, but at least you know exactly what kind of data you would need
[00:05:25] SPEAKER_01: to train by accuracy at the time.
[00:05:28] SPEAKER_01: That is unnecessary, the case of your chaotic or unstructured environment.
[00:05:32] SPEAKER_01: So, how do you solve the data-to-mode and do you think like you know synthetic data might be helpful?
[00:05:37] SPEAKER_01: Might be helpful to you generally whether you solve synthetic data and how do you embody data and execution?
[00:05:45] SPEAKER_00: So, when you think about like general purpose or a lot of work or going to develop in a language model,
[00:05:51] SPEAKER_00: a language model, a language model, the one of the most important thing you have to think about is
[00:05:56] SPEAKER_00: not just data quantity, a lot of people think about the data scale or data and this, either.
[00:06:01] SPEAKER_00: It's not necessarily so, it's actually stealing the right quality of data.
[00:06:05] SPEAKER_00: And that presents one of the most challenging pieces for a robot training today.
[00:06:12] SPEAKER_00: And this is where we focus a lot of our time to really focus a lot on the frequency data through
[00:06:17] SPEAKER_00: several models, through simulations and so forth.
[00:06:20] SPEAKER_00: You really match and actually create additional scenarios for how to distribute the data that we need to collect.
[00:06:27] SPEAKER_00: So, to your point I think real world data is the highest quality of data and government.
[00:06:34] SPEAKER_00: And then it really comes out to you know potentially like world models and simulations.
[00:06:39] SPEAKER_00: Simulations obviously is potentially promising in terms of creating the quantity of data.
[00:06:44] SPEAKER_00: And those are the highest quality of data.
[00:06:48] SPEAKER_00: In fact, there's a lot of simulation through real world barming up.
[00:06:52] SPEAKER_00: Even in the self-driving scenario where you see that the car is contacting with the road,
[00:06:57] SPEAKER_00: it doesn't change the road as it drives through the road.
[00:07:00] SPEAKER_00: It already still creates a lot of gaps. That's why you haven't seen simulation data even working too well.
[00:07:05] SPEAKER_00: So, it works a little bit for the self-driving environment, but even for the now for sick manipulation,
[00:07:11] SPEAKER_00: you're actually interacting with the physical world where you're achieving the state of the object as you're grasping.
[00:07:16] SPEAKER_00: And that, in fact, even more challenging environment for manipulation to work with in simulation.
[00:07:24] SPEAKER_00: So, this is the area where I can research what in the meantime,
[00:07:27] SPEAKER_00: how real world data is the most kind of world piece to solve that puzzle.
[00:07:32] SPEAKER_00: I love that. And I mean also from context, I think the consequences of let's say a robot or a self-driving car hallucinating,
[00:07:41] SPEAKER_01: or severe then let's say judging a team, misinterpreting the request and running the Romino.
[00:07:47] SPEAKER_01: How do you handle those catastrophic scenarios knowing that you need the highest level accuracy in safe cars in place?
[00:07:55] SPEAKER_01: And in that conjunction, what roles and the current AI architecture actually play in your solution?
[00:08:02] SPEAKER_01: What I mean with that is most of them were trained by one word, Internet data, structure data, visual data.
[00:08:10] SPEAKER_01: But usually what's missing is textarity, tech alpha, tech alpha, tech alpha,
[00:08:14] SPEAKER_01: but sensors that you are using in robots. So, how do you add that to the AI to assist in AI technology?
[00:08:21] SPEAKER_00: So, I think the first most respected is that humans will only have two eyes and we're able to interact very well with the physical environment around us.
[00:08:30] SPEAKER_00: Robots typically are at a website, different modality, and it's actually very difficult to say that, hey, the future of humanoid is going to end with humans exactly.
[00:08:39] SPEAKER_00: Right, we actually think about the history of technology and automation advancement.
[00:08:44] SPEAKER_00: You know, airplanes are supposed to emulate birds, but then airplanes will look, what's worth does not work anything like birds.
[00:08:50] SPEAKER_00: And what is the color of those rules of the place horses, but it doesn't look anything like that either.
[00:08:55] SPEAKER_00: So, I mean the raw stroke's answer is the general central modality, modality is that we think theme is necessary, such as hot-hot, such as visuals, such as force feedback, and so forth, or generally very very promising.
[00:09:10] SPEAKER_00: But the most important thing is still the classical experimentation of what we could really finalize on the central modality, is that it's really ultimately going to be a hot, the future state of our relies.
[00:09:23] So, what you're saying is that if a company on the other side, Tesla always was a day Apple can just use a camera, that's basically the ultimate layer of truth versus all the other manufacturers in that company Germany's with the German manufacturers always believed in sensor redundancy,
[00:09:39] SPEAKER_01: right, so they added like radar sensors, light sensors, and basically tried to get the same data input through five different forms of one false truth, they still have another one for icon.
[00:09:49] SPEAKER_01: So, right now you're saying visual is probably the leading indicator and then we layer a couple of them and we do forward.
[00:09:56] SPEAKER_00: Yeah, I think the difference between cars and humans is that, and cars we use two eyes to drive, and actions, we need eyes, we also need hot-hot feedback as well, on the same time.
[00:10:07] SPEAKER_00: So, these are the two fundamental layers, as we think about solving some structure, all structure environments where it actually replace human parts.
[00:10:17] So, looking at the current technology stack, holistic, you know, I don't know if the model layer or the I layer, what's the biggest role for up right now, or what would be the biggest unlock, let's say, Chatchy Pt, key moment for relies moving forward.
[00:10:31] SPEAKER_00: I think going back to this, so I think about the general purpose robots and two dimensions to focus on.
[00:10:39] SPEAKER_00: One dimension is generalization. Generalization really caught up a great down into environment generalization of generalization, past generalization.
[00:10:49] SPEAKER_00: Really, putting being able to place a robot in any new environments, if we handle any new objects, and if we do any types of tasks with language command, where some sort of prompt is one area of generalization we need to tackle.
[00:11:04] SPEAKER_00: The second piece is performance, which is the robot needs to work at human level group, but human level group, human level ball, and human level robotness.
[00:11:14] SPEAKER_00: It's missing any of one of these three traits that's not able to deliver kind of authorized for people in the industry as well.
[00:11:23] SPEAKER_00: So, in these two areas, I mean, both presents its own challenges in that common generalization indexes, we need to drastically still up the amount of data that we need.
[00:11:34] SPEAKER_00: So, this is learning through human videos, learning through, and in case you're learning, that's one area of the environment.
[00:11:43] SPEAKER_00: And the second piece is how do we collect the highest quality of data such that is able to perform a human level performance, and that's going to be the second piece.
[00:11:52] SPEAKER_00: And piece all of us together for a massive amount of pre-training that could put an understanding of the 3D world and 3D space around us is also another really big challenge.
[00:12:04] SPEAKER_00: But I'll say that, you know, the industry has really made a really strong progress.
[00:12:12] SPEAKER_00: I decided to start this company. I kind of gave a conservative estimate that will probably take us about two or three years before the audition production.
[00:12:19] SPEAKER_00: But now, you know, it's like six to nine months into the company who have a relationship production.
[00:12:24] SPEAKER_00: And the foundation all of those are really working production for some of our existing customers.
[00:12:28] SPEAKER_00: And find out if you really are composing and fascinating as that kind of momentum will only accelerate in the next few years.
[00:12:36] SPEAKER_01: Super exciting. And one last point about the current state of the art.
[00:12:41] SPEAKER_01: How do we, like we've all seen those videos where we're humanoid, move from the goofy and slow rise and take some a lot longer for a cast and human one.
[00:12:52] SPEAKER_01: What's the current state of the art when it comes to like inferiorism actually being able to process all of that on the edge and like enable reasoning and situational awareness and decisions?
[00:13:02] SPEAKER_01: Do you see any real close to that? Well, how do you solve it right now?
[00:13:06] SPEAKER_01: So I think in terms of so I think we're like in the context of what I talked about earlier structure, semi structure, and on structure, yeah, I think at every stage, you want a lot of additional capabilities right instruction environments.
[00:13:20] SPEAKER_00: You probably just need raw indication learning of where the role I was able to perform the cast in the stationary environment.
[00:13:27] SPEAKER_00: So my structure environment you need to robots be able to move to a certain degree is able to reach the right example that word word.
[00:13:36] SPEAKER_00: What one of our hospitality clients were we're holding their towels for them typically in patient learning as I was told that the towels are now stacking.
[00:13:45] SPEAKER_00: But after you stack the towels for like you know you have the pile of 10 towels.
[00:13:49] SPEAKER_00: Getting a little too close as hard to pop it over the model needs to understand how to sort of do stack right and that's the reason people are behind which has already gone along and then the next step is like mobility within mobility, we mentioned using and urgent reason and those are the.
[00:14:08] So just in we've come to an end let me just finish one question about future out so everyone I think is aware of the quote I want AI to write by he has been with creative work that more time doing my laundry and cleaning my house.
[00:14:22] SPEAKER_01: There should be the other way around so in a way sense what is the use case of the application area that you are most excited about where you know robots actually augment humanity and actually help us versus replacing us.
[00:14:37] SPEAKER_01: So I think it's actually mostly on the things that humans don't want to do. I think those are those tend to be the most mechanic those tend to be the most repetitive doll a dress.
[00:14:46] SPEAKER_00: So what the three he's a doll in the wrist and 30 30 and year right.
[00:14:52] SPEAKER_00: So I think that's the most promising part of the future of our lives which is where we're going to create the world where it's you know gets to sit and can pod like like those people in wally and and and and and and and and and and and be plug into the you know the situation world.
[00:15:12] SPEAKER_00: But we're not being said thank you so much and I hope you all get any one.